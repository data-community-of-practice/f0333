TY  - JOUR
TI  - Automatic International Classification of Diseases Coding via Note-Code Interaction Network with Denoising Mechanism.
AU  - Xiaobo Li
AU  - Yijia Zhang
AU  - Xingwang Li
AU  - Xianwei Pan
AU  - Jian Wang
AU  - Mingyu Lu
SN  - 1557-8666
AB  - Clinical notes are comprehensive files containing explicit information about a patient's visit. However, accurately assigning medical codes from clinical documents can be a persistent challenge due to the complexity of clinical data and the vast range of medical codes. Moreover, the large volume of medical records, the noisy medical records, and the uneven quality of coders all negatively impact the quality of the final codes. Deep learning technology has recently been integrated into automatic International Classification of Diseases (ICD) coding tasks to improve accuracy. Nevertheless, the imbalanced class problem, the complexness of code associations, and the noise in lengthy records still restrict the advancement of ICD coding tasks in deep learning. Thus, we present the Note-code Interaction Denoising Network (NIDN) that employs the self-attention mechanism to pull critical semantic features in electronic medical records (EMRs). Our model utilizes the label attention mechanism for retaining code-specific text expression. We introduce Clinical Classifications Software coding for multitask learning, capturing the functional relationships of medical coding to oblige in model prediction. To minimize the impact of noise on model prediction and improve the label distribution imbalance, a denoising module is introduced to filter noise. Our practical consequences indicate that the model NIDN exceeds competitive models on a third version of Medical Information Mart for Intensive Care data set.
DO  - 10.1089/cmb.2023.0079
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automatic International Classification of Diseases Coding System: Deep Contextualized Language Model With Rule-Based Approaches.
AU  - Pei-Fu Chen
AU  - Kuan-Chih Chen
AU  - Wei-Chih Liao
AU  - Feipei Lai
AU  - Tai-Liang He
AU  - Sheng-Che Lin
AU  - Wei-Jen Chen
AU  - Chi-Yu Yang
AU  - Yu-Cheng Lin
AU  - I-Chang Tsai
AU  - Chi-Hao Chiu
AU  - Shu-Chih Chang
AU  - Fang-Ming Hung
SN  - 2291-9694
AB  - BACKGROUND: The tenth revision of the International Classification of Diseases (ICD-10) is widely used for epidemiological research and health management. The clinical modification (CM) and procedure coding system (PCS) of ICD-10 were developed to describe more clinical details with increasing diagnosis and procedure codes and applied in disease-related groups for reimbursement. The expansion of codes made the coding time-consuming and less accurate. The state-of-the-art model using deep contextual word embeddings was used for automatic multilabel text classification of ICD-10. In addition to input discharge diagnoses (DD), the performance can be improved by appropriate preprocessing methods for the text from other document types, such as medical history, comorbidity and complication, surgical method, and special examination. OBJECTIVE: This study aims to establish a contextual language model with rule-based preprocessing methods to develop the model for ICD-10 multilabel classification. METHODS: We retrieved electronic health records from a medical center. We first compared different word embedding methods. Second, we compared the preprocessing methods using the best-performing embeddings. We compared biomedical bidirectional encoder representations from transformers (BioBERT), clinical generalized autoregressive pretraining for language understanding (Clinical XLNet), label tree-based attention-aware deep model for high-performance extreme multilabel text classification (AttentionXLM), and word-to-vector (Word2Vec) to predict ICD-10-CM. To compare different preprocessing methods for ICD-10-CM, we included DD, medical history, and comorbidity and complication as inputs. We compared the performance of ICD-10-CM prediction using different preprocesses, including definition training, external cause code removal, number conversion, and combination code filtering. For the ICD-10 PCS, the model was trained using different combinations of DD, surgical method, and key words of special examination. The micro F RESULTS: BioBERT had an F CONCLUSIONS: The performance of our model with the pretrained contextualized language model and rule-based preprocessing method is better than that of the state-of-the-art model for ICD-10-CM or ICD-10-PCS. This study highlights the importance of rule-based preprocessing methods based on coder coding rules.
DO  - 10.2196/37557
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Multigranularity Label Prediction Model for Automatic International Classification of Diseases Coding in Clinical Text.
AU  - Ying Yu
AU  - Tian Qiu
AU  - Junwen Duan
AU  - Jianxin Wang
SN  - 1557-8666
AB  - International Classification of Diseases (ICD) serves as the foundation for generating comparable global disease statistics across regions and over time. The process of ICD coding involves assigning codes to diseases based on clinical notes, which can describe a patient's condition in a standard way. However, this process is complicated by the vast number of codes and the intricate taxonomy of ICD codes, which are hierarchically organized into various levels, including chapter, category, subcategory, and its subdivisions. Many existing studies focus solely on predicting subcategory codes, ignoring the hierarchical relationships among codes. To address this limitation, we propose a multitask learning model that trains multiple classifiers for different code levels, while also capturing the relations between coarser and finer-grained labels through a reinforcement mechanism. Our approach is evaluated on both English and Chinese benchmark dataset, and we demonstrate that our method achieves competitive performance with baseline models, particularly in terms of macro-F1 results. These findings suggest that our approach effectively leverages the hierarchical structure of ICD codes to improve disease code prediction accuracy. Analysis of attention mechanism shows that multigranularity attention of our model captures crucial feature of input text on different granularity levels, which can provide reasonable explanations for the prediction results.
DO  - 10.1089/cmb.2023.0096
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Learning from undercoded clinical records for automated International Classification of Diseases (ICD) coding.
AU  - Yucheng Jin
AU  - Yun Xiong
AU  - Dan Shi
AU  - Yifei Lin
AU  - Lifang He
AU  - Yao Zhang
AU  - Joseph M Plasek
AU  - Li Zhou
AU  - David W Bates
AU  - Chunlei Tang
SN  - 1527-974X
AB  - OBJECTIVES: To develop an unbiased objective for learning automatic coding algorithms from clinical records annotated with only partial relevant International Classification of Diseases codes, as annotation noise in undercoded clinical records used as training data can mislead the learning process of deep neural networks. MATERIALS AND METHODS: We use Medical Information Mart for Intensive Care III as our dataset. We employ positive-unlabeled learning to achieve unbiased loss estimation, which is free of misleading training signal. We then utilize reweighting mechanism to compensate for the imbalance between positive and negative samples. To further close the performance gap caused by poor quality annotation, we integrate the supervision provided by the automatic annotation tool Medical Concept Annotation Toolkit which can ease the heavy burden of manual validation. RESULTS: Our benchmarking results show that positive-unlabeled learning with reweighting outperforms competitive baseline methods over a range of missing label ratios. Integrating supervision provided by annotation tool further boosted the performance. DISCUSSION: Considering the annotation noise and severe imbalance, unbiased loss estimation and reweighting mechanism are both important for learning from undercoded clinical records. Unbiased loss requires the estimation of false negative ratios and estimation through trained models is practical and competitive. CONCLUSIONS: The combination of positive-unlabeled learning with reweighting and supervision provided by the annotation tool is a promising solution to learn from undercoded clinical records.
DO  - 10.1093/jamia/ocac230
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Manual Evaluation of the Automatic Mapping of International Classification of Diseases (ICD)-11 (in French).
AU  - Julien Grosjean
AU  - Kévin Billey
AU  - Jean Charlet
AU  - Stefan J Darmoni
SN  - 1879-8365
AB  - A lexical method was used to map ICD-11 to the terminologies included in the HeTOP server. About half of ICD-11 codes (47.76%) were mapped to at least one concept. The developed tool reached a global precision of 0.98 and a recall of 0.66. Lexical methods are powerful methods to map health terminologies. Supervised and manual mapping is still necessary to complete the mapping.
DO  - 10.3233/SHTI200429
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Evaluating a Natural Language Processing-Driven, AI-Assisted International Classification of Diseases, 10th Revision, Clinical Modification, Coding System for Diagnosis Related Groups in a Real Hospital Environment: Algorithm Development and Validation Study.
AU  - Hong-Jie Dai
AU  - Chen-Kai Wang
AU  - Chien-Chang Chen
AU  - Chong-Sin Liou
AU  - An-Tai Lu
AU  - Chia-Hsin Lai
AU  - Bo-Tsz Shain
AU  - Cheng-Rong Ke
AU  - William Yu Chung Wang
AU  - Tatheer Hussain Mir
AU  - Mutiara Simanjuntak
AU  - Hao-Yun Kao
AU  - Ming-Ju Tsai
AU  - Vincent S Tseng
SN  - 1438-8871
AB  - BACKGROUND: International Classification of Diseases codes are widely used to describe diagnosis information, but manual coding relies heavily on human interpretation, which can be expensive, time consuming, and prone to errors. With the transition from the International Classification of Diseases, Ninth Revision, to the International Classification of Diseases, Tenth Revision (ICD-10), the coding process has become more complex, highlighting the need for automated approaches to enhance coding efficiency and accuracy. Inaccurate coding can result in substantial financial losses for hospitals, and a precise assessment of outcomes generated by a natural language processing (NLP)-driven autocoding system thus assumes a critical role in safeguarding the accuracy of the Taiwan diagnosis related groups (Tw-DRGs). OBJECTIVE: This study aims to evaluate the feasibility of applying an International Classification of Diseases, Tenth Revision, Clinical Modification (ICD-10-CM), autocoding system that can automatically determine diagnoses and codes based on free-text discharge summaries to facilitate the assessment of Tw-DRGs, specifically principal diagnosis and major diagnostic categories (MDCs). METHODS: By using the patient discharge summaries from Kaohsiung Medical University Chung-Ho Memorial Hospital (KMUCHH) from April 2019 to December 2020 as a reference data set we developed artificial intelligence (AI)-assisted ICD-10-CM coding systems based on deep learning models. We constructed a web-based user interface for the AI-assisted coding system and deployed the system to the workflow of the certified coding specialists (CCSs) of KMUCHH. The data used for the assessment of Tw-DRGs were manually curated by a CCS with the principal diagnosis and MDC was determined from discharge summaries collected at KMUCHH from February 2023 to April 2023. RESULTS: Both the reference data set and real hospital data were used to assess performance in determining ICD-10-CM coding, principal diagnosis, and MDC for Tw-DRGs. Among all methods, the GPT-2 (OpenAI)-based model achieved the highest F CONCLUSIONS: An NLP-driven AI-assisted coding system can assist CCSs in ICD-10-CM coding by offering coding references via a user interface, demonstrating the potential to reduce the manual workload and expedite Tw-DRG assessment. Consistency in performance affirmed the effectiveness of the system in supporting CCSs in ICD-10-CM coding and the judgment of Tw-DRGs.
DO  - 10.2196/58278
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Toward Reliable Symptom Coding in Electronic Health Records for Symptom Assessment and Research: Identification and Categorization of International Classification of Diseases, Ninth Revision, Clinical Modification Symptom Codes.
AU  - Tru Cao
AU  - Veronica Brady
AU  - Meagan Whisenant
AU  - Xueying Wang
AU  - Yuxuan Gu
AU  - Hulin Wu
SN  - 1538-9774
AB  - To date, symptom documentation has mostly relied on clinical notes in electronic health records or patient-reported outcomes using disease-specific symptom inventories. To provide a common and precise language for symptom recording, assessment, and research, a comprehensive list of symptom codes is needed. The International Classification of Diseases, Ninth Revision or its clinical modification ( International Classification of Diseases, Ninth Revision, Clinical Modification ) has a range of codes designated for symptoms, but it does not contain codes for all possible symptoms, and not all codes in that range are symptom related. This study aimed to identify and categorize the first list of International Classification of Diseases, Ninth Revision, Clinical Modification symptom codes for a general population and demonstrate their use to characterize symptoms of patients with type 2 diabetes mellitus in the Cerner database. A list of potential symptom codes was automatically extracted from the Unified Medical Language System Metathesaurus. Two clinical experts in symptom science and diabetes manually reviewed this list to identify and categorize codes as symptoms. A total of 1888 International Classification of Diseases, Ninth Revision, Clinical Modification symptom codes were identified and categorized into 65 categories. The symptom characterization using the newly obtained symptom codes and categories was found to be more reasonable than that using the previous symptom codes and categories on the same Cerner diabetes cohort.
DO  - 10.1097/CIN.0000000000001146
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Artificial Intelligence-based Automated International Classification of Diseases Coding: A Systematic Review.
AU  - Seyyedeh Fatemeh Mousavi Baigi
AU  - Masoumeh Sarbaz
AU  - Ali Darroudi
AU  - Fatemeh Dahmardeh Kemmak
AU  - Reyhane Norouzi Aval
AU  - Khalil Kimiafar
SN  - 2228-7477
AB  - Automated clinical coding, facilitated by artificial intelligence (AI) techniques like natural language processing and machine learning, has emerged as a promising approach to enhance coding efficiency and accuracy in healthcare. This review synthesizes current knowledge about AI-based automated coding of the International Classification of Diseases (ICD), with a focus on its challenges, benefits, and future research directions. Following Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines, a systematic search was conducted across PubMed, Embase, Scopus, and Web of Science databases on January 1, 2024. Studies discussing challenges, advantages, and research gaps in AI-driven ICD coding were included. Out of 12,641 identified records, eight studies met the inclusion criteria. These studies highlighted six key challenges: extensive label space, imbalanced label distribution, lengthy documents, coding interpretability issues, ethical concerns, and lack of transparency. Ten major benefits of AI-based ICD coding were identified, including improved decision-making, data standardization, and increased coding accuracy. In addition, eight future directions were proposed, emphasizing interdisciplinary collaboration, transfer learning, transparency enhancement, and active learning techniques. Despite significant challenges, AI-based ICD coding holds substantial potential to revolutionize clinical coding by improving efficiency and accuracy. This review provides a comprehensive synthesis of current evidence and actionable insights for advancing research and practical implementation of automated ICD coding systems.
DO  - 10.4103/jmss.jmss_76_24
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Autonomous International Classification of Diseases Coding Using Pretrained Language Models and Advanced Prompt Learning Techniques: Evaluation of an Automated Analysis System Using Medical Text.
AU  - Yan Zhuang
AU  - Junyan Zhang
AU  - Xiuxing Li
AU  - Chao Liu
AU  - Yue Yu
AU  - Wei Dong
AU  - Kunlun He
SN  - 2291-9694
AB  - BACKGROUND: Machine learning models can reduce the burden on doctors by converting medical records into International Classification of Diseases (ICD) codes in real time, thereby enhancing the efficiency of diagnosis and treatment. However, it faces challenges such as small datasets, diverse writing styles, unstructured records, and the need for semimanual preprocessing. Existing approaches, such as naive Bayes, Word2Vec, and convolutional neural networks, have limitations in handling missing values and understanding the context of medical texts, leading to a high error rate. We developed a fully automated pipeline based on the Key-bidirectional encoder representations from transformers (BERT) approach and large-scale medical records for continued pretraining, which effectively converts long free text into standard ICD codes. By adjusting parameter settings, such as mixed templates and soft verbalizers, the model can adapt flexibly to different requirements, enabling task-specific prompt learning. OBJECTIVE: This study aims to propose a prompt learning real-time framework based on pretrained language models that can automatically label long free-text data with ICD-10 codes for cardiovascular diseases without the need for semiautomatic preprocessing. METHODS: We integrated 4 components into our framework: a medical pretrained BERT, a keyword filtration BERT in a functional order, a fine-tuning phase, and task-specific prompt learning utilizing mixed templates and soft verbalizers. This framework was validated on a multicenter medical dataset for the automated ICD coding of 13 common cardiovascular diseases (584,969 records). Its performance was compared against robustly optimized BERT pretraining approach, extreme language network, and various BERT-based fine-tuning pipelines. Additionally, we evaluated the framework's performance under different prompt learning and fine-tuning settings. Furthermore, few-shot learning experiments were conducted to assess the feasibility and efficacy of our framework in scenarios involving small- to mid-sized datasets. RESULTS: Compared with traditional pretraining and fine-tuning pipelines, our approach achieved a higher micro-F1-score of 0.838 and a macro-area under the receiver operating characteristic curve (macro-AUC) of 0.958, which is 10% higher than other methods. Among different prompt learning setups, the combination of mixed templates and soft verbalizers yielded the best performance. Few-shot experiments showed that performance stabilized and the AUC peaked at 500 shots. CONCLUSIONS: These findings underscore the effectiveness and superior performance of prompt learning and fine-tuning for subtasks within pretrained language models in medical practice. Our real-time ICD coding pipeline efficiently converts detailed medical free text into standardized labels, offering promising applications in clinical decision-making. It can assist doctors unfamiliar with the ICD coding system in organizing medical record information, thereby accelerating the medical process and enhancing the efficiency of diagnosis and treatment.
DO  - 10.2196/63020
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Global burden of 292 causes of death in 204 countries and territories and 660 subnational locations, 1990-2023: a systematic analysis for the Global Burden of Disease Study 2023.
SN  - 1474-547X
AB  - BACKGROUND: Timely and comprehensive analyses of causes of death stratified by age, sex, and location are essential for shaping effective health policies aimed at reducing global mortality. The Global Burden of Diseases, Injuries, and Risk Factors Study (GBD) 2023 provides cause-specific mortality estimates measured in counts, rates, and years of life lost (YLLs). GBD 2023 aimed to enhance our understanding of the relationship between age and cause of death by quantifying the probability of dying before age 70 years (70q0) and the mean age at death by cause and sex. This study enables comparisons of the impact of causes of death over time, offering a deeper understanding of how these causes affect global populations. METHODS: GBD 2023 produced estimates for 292 causes of death disaggregated by age-sex-location-year in 204 countries and territories and 660 subnational locations for each year from 1990 until 2023. We used a modelling tool developed for GBD, the Cause of Death Ensemble model (CODEm), to estimate cause-specific death rates for most causes. We computed YLLs as the product of the number of deaths for each cause-age-sex-location-year and the standard life expectancy at each age. Probability of death was calculated as the chance of dying from a given cause in a specific age period, for a specific population. Mean age at death was calculated by first assigning the midpoint age of each age group for every death, followed by computing the mean of all midpoint ages across all deaths attributed to a given cause. We used GBD death estimates to calculate the observed mean age at death and to model the expected mean age across causes, sexes, years, and locations. The expected mean age reflects the expected mean age at death for individuals within a population, based on global mortality rates and the population's age structure. Comparatively, the observed mean age represents the actual mean age at death, influenced by all factors unique to a location-specific population, including its age structure. As part of the modelling process, uncertainty intervals (UIs) were generated using the 2·5th and 97·5th percentiles from a 250-draw distribution for each metric. Findings are reported as counts and age-standardised rates. Methodological improvements for cause-of-death estimates in GBD 2023 include a correction for the misclassification of deaths due to COVID-19, updates to the method used to estimate COVID-19, and updates to the CODEm modelling framework. This analysis used 55 761 data sources, including vital registration and verbal autopsy data as well as data from surveys, censuses, surveillance systems, and cancer registries, among others. For GBD 2023, there were 312 new country-years of vital registration cause-of-death data, 3 country-years of surveillance data, 51 country-years of verbal autopsy data, and 144 country-years of other data types that were added to those used in previous GBD rounds. FINDINGS: The initial years of the COVID-19 pandemic caused shifts in long-standing rankings of the leading causes of global deaths: it ranked as the number one age-standardised cause of death at Level 3 of the GBD cause classification hierarchy in 2021. By 2023, COVID-19 dropped to the 20th place among the leading global causes, returning the rankings of the leading two causes to those typical across the time series (ie, ischaemic heart disease and stroke). While ischaemic heart disease and stroke persist as leading causes of death, there has been progress in reducing their age-standardised mortality rates globally. Four other leading causes have also shown large declines in global age-standardised mortality rates across the study period: diarrhoeal diseases, tuberculosis, stomach cancer, and measles. Other causes of death showed disparate patterns between sexes, notably for deaths from conflict and terrorism in some locations. A large reduction in age-standardised rates of YLLs occurred for neonatal disorders. Despite this, neonatal disorders remained the leading cause of global YLLs over the period studied, except in 2021, when COVID-19 was temporarily the leading cause. Compared to 1990, there has been a considerable reduction in total YLLs in many vaccine-preventable diseases, most notably diphtheria, pertussis, tetanus, and measles. In addition, this study quantified the mean age at death for all-cause mortality and cause-specific mortality and found noticeable variation by sex and location. The global all-cause mean age at death increased from 46·8 years (95% UI 46·6-47·0) in 1990 to 63·4 years (63·1-63·7) in 2023. For males, mean age increased from 45·4 years (45·1-45·7) to 61·2 years (60·7-61·6), and for females it increased from 48·5 years (48·1-48·8) to 65·9 years (65·5-66·3), from 1990 to 2023. The highest all-cause mean age at death in 2023 was found in the high-income super-region, where the mean age for females reached 80·9 years (80·9-81·0) and for males 74·8 years (74·8-74·9). By comparison, the lowest all-cause mean age at death occurred in sub-Saharan Africa, where it was 38·0 years (37·5-38·4) for females and 35·6 years (35·2-35·9) for males in 2023. Lastly, our study found that all-cause 70q0 decreased across each GBD super-region and region from 2000 to 2023, although with large variability between them. For females, we found that 70q0 notably increased from drug use disorders and conflict and terrorism. Leading causes that increased 70q0 for males also included drug use disorders, as well as diabetes. In sub-Saharan Africa, there was an increase in 70q0 for many non-communicable diseases (NCDs). Additionally, the mean age at death from NCDs was lower than the expected mean age at death for this super-region. By comparison, there was an increase in 70q0 for drug use disorders in the high-income super-region, which also had an observed mean age at death lower than the expected value. INTERPRETATION: We examined global mortality patterns over the past three decades, highlighting-with enhanced estimation methods-the impacts of major events such as the COVID-19 pandemic, in addition to broader trends such as increasing NCDs in low-income regions that reflect ongoing shifts in the global epidemiological transition. This study also delves into premature mortality patterns, exploring the interplay between age and causes of death and deepening our understanding of where targeted resources could be applied to further reduce preventable sources of mortality. We provide essential insights into global and regional health disparities, identifying locations in need of targeted interventions to address both communicable and non-communicable diseases. There is an ever-present need for strengthened health-care systems that are resilient to future pandemics and the shifting burden of disease, particularly among ageing populations in regions with high mortality rates. Robust estimates of causes of death are increasingly essential to inform health priorities and guide efforts toward achieving global health equity. The need for global collaboration to reduce preventable mortality is more important than ever, as shifting burdens of disease are affecting all nations, albeit at different paces and scales. FUNDING: Gates Foundation.
DO  - 10.1016/S0140-6736(25)01917-8
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - FasTag: Automatic text classification of unstructured medical narratives.
AU  - Guhan Ram Venkataraman
AU  - Arturo Lopez Pineda
AU  - Oliver J Bear Don't Walk Iv
AU  - Ashley M Zehnder
AU  - Sandeep Ayyar
AU  - Rodney L Page
AU  - Carlos D Bustamante
AU  - Manuel A Rivas
SN  - 1932-6203
AB  - Unstructured clinical narratives are continuously being recorded as part of delivery of care in electronic health records, and dedicated tagging staff spend considerable effort manually assigning clinical codes for billing purposes. Despite these efforts, however, label availability and accuracy are both suboptimal. In this retrospective study, we aimed to automate the assignment of top-level International Classification of Diseases version 9 (ICD-9) codes to clinical records from human and veterinary data stores using minimal manual labor and feature curation. Automating top-level annotations could in turn enable rapid cohort identification, especially in a veterinary setting. To this end, we trained long short-term memory (LSTM) recurrent neural networks (RNNs) on 52,722 human and 89,591 veterinary records. We investigated the accuracy of both separate-domain and combined-domain models and probed model portability. We established relevant baseline classification performances by training Decision Trees (DT) and Random Forests (RF). We also investigated whether transforming the data using MetaMap Lite, a clinical natural language processing tool, affected classification performance. We showed that the LSTM-RNNs accurately classify veterinary and human text narratives into top-level categories with an average weighted macro F1 score of 0.74 and 0.68 respectively. In the "neoplasia" category, the model trained on veterinary data had a high validation accuracy in veterinary data and moderate accuracy in human data, with F1 scores of 0.91 and 0.70 respectively. Our LSTM method scored slightly higher than that of the DT and RF models. The use of LSTM-RNN models represents a scalable structure that could prove useful in cohort identification for comparative oncology studies. Digitization of human and veterinary health information will continue to be a reality, particularly in the form of unstructured narratives. Our approach is a step forward for these two domains to learn from and inform one another.
DO  - 10.1371/journal.pone.0234647
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Construction of a semi-automatic ICD-10 coding system.
AU  - Lingling Zhou
AU  - Cheng Cheng
AU  - Dong Ou
AU  - Hao Huang
SN  - 1472-6947
AB  - BACKGROUND: The International Classification of Diseases, 10th Revision (ICD-10) has been widely used to describe the diagnosis information of patients. Automatic ICD-10 coding is important because manually assigning codes is expensive, time consuming and error prone. Although numerous approaches have been developed to explore automatic coding, few of them have been applied in practice. Our aim is to construct a practical, automatic ICD-10 coding machine to improve coding efficiency and quality in daily work. METHODS: In this study, we propose the use of regular expressions (regexps) to establish a correspondence between diagnosis codes and diagnosis descriptions in outpatient settings and at admission and discharge. The description models of the regexps were embedded in our upgraded coding system, which queries a diagnosis description and assigns a unique diagnosis code. Like most studies, the precision (P), recall (R), F-measure (F) and overall accuracy (A) were used to evaluate the system performance. Our study had two stages. The datasets were obtained from the diagnosis information on the homepage of the discharge medical record. The testing sets were from October 1, 2017 to April 30, 2018 and from July 1, 2018 to January 31, 2019. RESULTS: The values of P were 89.27 and 88.38% in the first testing phase and the second testing phase, respectively, which demonstrate high precision. The automatic ICD-10 coding system completed more than 160,000 codes in 16 months, which reduced the workload of the coders. In addition, a comparison between the amount of time needed for manual coding and automatic coding indicated the effectiveness of the system-the time needed for automatic coding takes nearly 100 times less than manual coding. CONCLUSIONS: Our automatic coding system is well suited for the coding task. Further studies are warranted to perfect the description models of the regexps and to develop synthetic approaches to improve system performance.
DO  - 10.1186/s12911-020-1085-4
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - [Electronic coding of death certificates].
AU  - Olaf Eckert
SN  - 1437-1588
AB  - About half of all German death certificates are processed electronically by regional statistical offices to select the underlying cause of death in accordance with the instructions from the World Health Organization. This paper illustrates electronic coding and its importance for cause of death statistics.The electronic coding kernel MUSE was added a few years ago to the international coding system Iris, which is maintained by the Iris Core Group.A new module assigns, as far as possible, ICD-10 codes to medical terms documented in death certificates. It takes into account syntactical specifics of the German language. In addition, automatic text correction is implemented. Unrecognised text parts are highlighted and coded manually.Despite these efforts, improvement of data quality is the greatest challenge of German cause-of-death statistics. All involved stakeholders (physicians, local health authorities, and regional statistical offices) can cope with this task by a common effort.The process of electronic coding provides valuable hints for improving the quality of death certificates. In future, the coding system could generate feedback to local health authorities indicating medical documentation problems.
DO  - 10.1007/s00103-019-03045-2
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Training a Deep Contextualized Language Model for International Classification of Diseases, 10th Revision Classification via Federated Learning: Model Development and Validation Study.
AU  - Pei-Fu Chen
AU  - Tai-Liang He
AU  - Sheng-Che Lin
AU  - Yuan-Chia Chu
AU  - Chen-Tsung Kuo
AU  - Feipei Lai
AU  - Ssu-Ming Wang
AU  - Wan-Xuan Zhu
AU  - Kuan-Chih Chen
AU  - Lu-Cheng Kuo
AU  - Fang-Ming Hung
AU  - Yu-Cheng Lin
AU  - I-Chang Tsai
AU  - Chi-Hao Chiu
AU  - Shu-Chih Chang
AU  - Chi-Yu Yang
SN  - 2291-9694
AB  - BACKGROUND: The automatic coding of clinical text documents by using the International Classification of Diseases, 10th Revision (ICD-10) can be performed for statistical analyses and reimbursements. With the development of natural language processing models, new transformer architectures with attention mechanisms have outperformed previous models. Although multicenter training may increase a model's performance and external validity, the privacy of clinical documents should be protected. We used federated learning to train a model with multicenter data, without sharing data per se. OBJECTIVE: This study aims to train a classification model via federated learning for ICD-10 multilabel classification. METHODS: Text data from discharge notes in electronic medical records were collected from the following three medical centers: Far Eastern Memorial Hospital, National Taiwan University Hospital, and Taipei Veterans General Hospital. After comparing the performance of different variants of bidirectional encoder representations from transformers (BERT), PubMedBERT was chosen for the word embeddings. With regard to preprocessing, the nonalphanumeric characters were retained because the model's performance decreased after the removal of these characters. To explain the outputs of our model, we added a label attention mechanism to the model architecture. The model was trained with data from each of the three hospitals separately and via federated learning. The models trained via federated learning and the models trained with local data were compared on a testing set that was composed of data from the three hospitals. The micro F RESULTS: The F CONCLUSIONS: Federated learning was used to train the ICD-10 classification model on multicenter clinical text while protecting data privacy. The model's performance was better than that of models that were trained locally.
DO  - 10.2196/41342
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automatic coding and selection of causes of death: an adaptation of Iris software for using in Brazil.
AU  - Renata Cristófani Martins
AU  - Cassia Maria Buchalla
SN  - 1980-5497
AB  - OBJECTIVE: To prepare a dictionary in Portuguese for using in Iris and to evaluate its completeness for coding causes of death. METHODS: Iniatially, a dictionary with all illness and injuries was created based on the International Classification of Diseases - tenth revision (ICD-10) codes. This dictionary was based on two sources: the electronic file of ICD-10 volume 1 and the data from Thesaurus of the International Classification of Primary Care (ICPC-2). Then, a death certificate sample from the Program of Improvement of Mortality Information in São Paulo (PRO-AIM) was coded manually and by Iris version V4.0.34, and the causes of death were compared. Whenever Iris was not able to code the causes of death, adjustments were made in the dictionary. RESULTS: Iris was able to code all causes of death in 94.4% death certificates, but only 50.6% were directly coded, without adjustments. Among death certificates that the software was unable to fully code, 89.2% had a diagnosis of external causes (chapter XX of ICD-10). This group of causes of death showed less agreement when comparing the coding by Iris to the manual one. CONCLUSION: The software performed well, but it needs adjustments and improvement in its dictionary. In the upcoming versions of the software, its developers are trying to solve the external causes of death problem.
DO  - 10.1590/1980-5497201500040016
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - A Curriculum Batching Strategy for Automatic ICD Coding with Deep Multi-Label Classification Models.
AU  - Yaqiang Wang
AU  - Xu Han
AU  - Xuechao Hao
AU  - Tao Zhu
AU  - Hongping Shu
SN  - 2227-9032
AB  - The International Classification of Diseases (ICD) has an important role in building applications for clinical medicine. Extremely large ICD coding label sets and imbalanced label distribution bring the problem of inconsistency between the local batch data distribution and the global training data distribution into the minibatch gradient descent (MBGD)-based training procedure for deep multi-label classification models for automatic ICD coding. The problem further leads to an overfitting issue. In order to improve the performance and generalization ability of the deep learning automatic ICD coding model, we proposed a simple and effective curriculum batching strategy in this paper for improving the MBGD-based training procedure. This strategy generates three batch sets offline through applying three predefined sampling algorithms. These batch sets satisfy a uniform data distribution, a shuffling data distribution and the original training data distribution, respectively, and the learning tasks corresponding to these batch sets range from simple to complex. Experiments show that, after replacing the original shuffling algorithm-based batching strategy with the proposed curriculum batching strategy, the performance of the three investigated deep multi-label classification models for automatic ICD coding all have dramatic improvements. At the same time, the models avoid the overfitting issue and all show better ability to learn the long-tailed label information. The performance is also better than a SOTA label set reconstruction model.
DO  - 10.3390/healthcare10122397
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automatic construction of rule-based ICD-9-CM coding systems.
AU  - Richárd Farkas
AU  - György Szarvas
SN  - 1471-2105
AB  - BACKGROUND: In this paper we focus on the problem of automatically constructing ICD-9-CM coding systems for radiology reports. ICD-9-CM codes are used for billing purposes by health institutes and are assigned to clinical records manually following clinical treatment. Since this labeling task requires expert knowledge in the field of medicine, the process itself is costly and is prone to errors as human annotators have to consider thousands of possible codes when assigning the right ICD-9-CM labels to a document. In this study we use the datasets made available for training and testing automated ICD-9-CM coding systems by the organisers of an International Challenge on Classifying Clinical Free Text Using Natural Language Processing in spring 2007. The challenge itself was dominated by entirely or partly rule-based systems that solve the coding task using a set of hand crafted expert rules. Since the feasibility of the construction of such systems for thousands of ICD codes is indeed questionable, we decided to examine the problem of automatically constructing similar rule sets that turned out to achieve a remarkable accuracy in the shared task challenge. RESULTS: Our results are very promising in the sense that we managed to achieve comparable results with purely hand-crafted ICD-9-CM classifiers. Our best model got a 90.26% F measure on the training dataset and an 88.93% F measure on the challenge test dataset, using the micro-averaged F beta=1 measure, the official evaluation metric of the International Challenge on Classifying Clinical Free Text Using Natural Language Processing. This result would have placed second in the challenge, with a hand-crafted system achieving slightly better results. CONCLUSIONS: Our results demonstrate that hand-crafted systems - which proved to be successful in ICD-9-CM coding - can be reproduced by replacing several laborious steps in their construction with machine learning models. These hybrid systems preserve the favourable aspects of rule-based classifiers like good performance, and their development can be achieved rapidly and requires less human effort. Hence the construction of such hybrid systems can be feasible for a set of labels one magnitude bigger, and with more labeled data.
DO  - 10.1186/1471-2105-9-S3-S10
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automatic ICD-10-CM coding via Lambda-Scaled attention based deep learning model.
AU  - Sajida Raz Bhutto
AU  - Min Zeng
AU  - Kunying Niu
AU  - Sirajuddin Khoso
AU  - Muhammad Umar
AU  - Gul Lalley
AU  - Min Li
SN  - 1095-9130
AB  - The International Classification of Diseases (ICD) serves as a global healthcare administration standard, with one of its editions being ICD-10-CM, an enhanced diagnostic classification system featuring numerous new codes for specific anatomic sites, co-morbidities, and causes. These additions facilitate conveying the complexities of various diseases. Currently, ICD-10 coding is widely adopted worldwide. However, public hospitals in Pakistan have yet to implement it and automate the coding process. In this research, we implemented ICD-10-CM coding for a private database and named it Clinical Pool of Liver Transplant (CPLT). Additionally, we proposed a novel deep learning model called Deep Recurrent-Convolution Neural Network with a lambda-scaled Attention module (DRCNN-ATT) using the CPLT database to achieve automatic ICD-10-CM coding. DRCNN-ATT combines a bi-directional long short-term memory network (bi-LSTM), a multi-scale convolutional neural network (MS-CNN), and a lambda-scaled attention module. Experimental results demonstrate that deep recurrent convolutional neural network (DRCNN) faces attention score vanishing problem with a standard attention module for automatic ICD coding. However, adding a lambda-scaled attention module resolves this issue. We evaluated DRCNN-ATT model using two distinct datasets: a private CPLT dataset and a public MIMIC III top 50 dataset. The results indicate that the DRCNN-ATT model outperformed various baselines by generating 0.862 micro F1 and 0.25 macro F1 scores on CPLT dataset and 0.705 micro F1 and 0.655 macro F1 scores on MIMIC III top 50 dataset. Furthermore, we also deployed our model for automatic ICD-10-CM coding using ngrok and the Flask APIs, which receives input, processes it, and then returns the results.
DO  - 10.1016/j.ymeth.2023.11.017
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - A Pseudo Label-Wise Attention Network for Automatic ICD Coding.
AU  - Yifan Wu
AU  - Min Zeng
AU  - Ying Yu
AU  - Yaohang Li
AU  - Min Li
SN  - 2168-2208
AB  - Automatic International Classification of Diseases (ICD) coding is defined as a kind of text multi-label classification problem, which is difficult because the number of labels is very large and the distribution of labels is unbalanced. The label-wise attention mechanism is widely used in automatic ICD coding because it can assign weights to every word in full Electronic Medical Records (EMR) for different ICD codes. However, the label-wise attention mechanism is redundant and costly in computing. In this paper, we propose a pseudo label-wise attention mechanism to tackle the problem. Instead of computing different attention modes for different ICD codes, the pseudo label-wise attention mechanism automatically merges similar ICD codes and computes only one attention mode for the similar ICD codes, which greatly compresses the number of attention modes and improves the predicted accuracy. In addition, we apply a more convenient and effective way to obtain the ICD vectors, and thus our model can predict new ICD codes by calculating the similarities between EMR vectors and ICD vectors. Our model demonstrates effectiveness in extensive computational experiments. On the public MIMIC-III dataset and private Xiangya dataset, our model achieves the best performance on micro F1 (0.583 and 0.806), micro AUC (0.986 and 0.994), P@8 (0.756 and 0.413), and costs much smaller GPU memory (about 26.1% of the models with label-wise attention). Furthermore, we verify the ability of our model in predicting new ICD codes. The interpretablility analysis and case study show the effectiveness and reliability of the patterns obtained by the pseudo label-wise attention mechanism.
DO  - 10.1109/JBHI.2022.3193291
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - JAN: Joint Attention Networks for Automatic ICD Coding.
AU  - Yuzhou Wu
AU  - Zhigang Chen
AU  - Xin Yao
AU  - Xuechen Chen
AU  - Zeren Zhou
AU  - Jinkai Xue
SN  - 2168-2208
AB  - The International Classification of Diseases (ICD) code is a disease classification method formulated by the World Health Organization(WHO). ICD coding usually requires clinicians to manually allocate ICD codes to clinical documents, which is labor-intensive, expensive, and error-prone. Therefore, many methods have been introduced for automatic ICD coding. However, most of the methods have ignored or cannot combine two essential features well: long-tailed label distribution and label correlation. In this paper, we propose a novel end-to-end Joint Attention Network (JAN) to solve these two problems. JAN includes Document-based attention and Label-based attention to capture semantic information from clinical document text and label description, respectively, which helps solve the classification of dense and sparse data in long-tailed label distribution. Besides, an Adaptive fusion layer and CorNet block are presented to adaptively adjust the weight of these two attentions and exploit label co-occurrence relations, respectively. Experiments on the MIMIC-III and MIMIC-II datasets demonstrate that our proposed JAN outperformed previous state-of-art methods achieving Micro-F1 of 0.553, Micro-AUC of 0.989 and precision at top 8(P@8) of 0.735. Finally, we also provide attention and label correlation visualization to verify the effectiveness of our model and improve the interpretation of our deep learning-based method.
DO  - 10.1109/JBHI.2022.3189404
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - A cross-lingual approach to automatic ICD-10 coding of death certificates by exploring machine translation.
AU  - Mario Almagro
AU  - Raquel Martínez
AU  - Soto Montalvo
AU  - Víctor Fresno
SN  - 1532-0480
AB  - Automatic ICD-10 coding is an unresolved challenge in terms of Machine Learning tasks. Despite hospitals generating an enormous amount of clinical documents, data is considerably sparse, associated with a very skewed and unbalanced code distribution, what entails reduced interoperability. In addition, in some languages the availability of coded documents is very limited. This paper proposes a cross-lingual approach based on Machine Translation methods to code death certificates with ICD-10 using supervised learning. The aim of this approach is to increase the availability of coded documents by combining collections of different languages, which may also contribute to reduce their possible bias in the ICD distribution, i.e. to avoid the promotion of a subset of codes due to service or environmental factors. A significant improvement in system performance is achieved for those labels with few occurrences.
DO  - 10.1016/j.jbi.2019.103207
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Deep learning for automatic ICD coding: Review, opportunities and challenges.
AU  - Xiaobo Li
AU  - Yijia Zhang
AU  - Xiaodi Hou
AU  - Shilong Wang
AU  - Hongfei Lin
SN  - 1873-2860
AB  - BACKGROUND: The automatic International Classification of Diseases (ICD) coding task assigns unique medical codes to diseases in clinical texts for further data statistics, quality control, billing and other tasks. The efficiency and accuracy of medical code assignment is a significant challenge affecting healthcare. However, in clinical practice, Electronic Health Records (EHRs) data are usually complex, heterogeneous, non-standard and unstructured, and the manual coding process is time-consuming, laborious and error-prone. Traditional machine learning methods struggle to extract significant semantic information from clinical texts accurately, but the latest progress in Deep Learning (DL) has shown promising results to address these issues. OBJECTIVE: This paper comprehensively reviewed recent advancements in utilizing deep learning for automatic ICD coding, which aimed to reveal prominent challenges and emerging development trends by summarizing and analyzing the model's year, design motivation, deep neural networks, and auxiliary data. METHODS: This review introduced systematic literature on automatic ICD coding methods based on deep learning. We screened 5 online databases, including Web of Science, SpringerLink, PubMed, ACM, and IEEE digital library, and collected 53 published articles related to deep learning-based ICD coding from 2017 to 2023. RESULTS: These deep neural network methods aimed to overcome some challenges, such as lengthy and noisy clinical text, high dimensionality and functional relationships of medical codes, and long-tail label distribution. The Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), attention mechanisms, Transformers, Pre-trained Language Models (PLMs), etc, have become popular to address prominent issues in ICD coding. Meanwhile, introducing medical ontology within the ICD coding system (code description and code hierarchy) and external knowledge (Wikipedia articles, tabular data, Clinical Classification Software (CCS), fine-tuning PLMs based on biomedical corpus, entity recognition and concept extraction) has become an emerging trend for automatic ICD coding. CONCLUSION: This paper provided a comprehensive review of recent literature on applying deep learning technology to improve medical code assignment from a unique perspective. Multiple neural network methods (CNNs, RNNs, Transformers, PLMs, especially attention mechanisms) have been successfully applied in ICD tasks and achieved excellent performance. Various medical auxiliary data has also proven valuable in enhancing model feature representation and classification performance. Our in-depth and systematic analysis suggested that the automatic ICD coding method based on deep learning has a bright future in healthcare. Finally, we discussed some major challenges and outlined future development directions.
DO  - 10.1016/j.artmed.2025.103187
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Challenges of Integrating ICD 11 into Automatic Alerting Systems.
AU  - Masresha Derese Tegegne
AU  - Maike Krips
AU  - Islam Ibrahim
AU  - Thomas M Deserno
SN  - 1879-8365
AB  - Automatic alerting systems (AASs) can identify adverse health events but emergency communication relies on human operators and natural languages. For complete automation, we need to code the diversity of adverse events in a granularity that supports optimal dispatches. Hence, AAs shall integrate with the International Classification of Diseases (ICD). The ICD-11 coding system includes chapters for external causes of injury. However, ICD-11 supports coding injury incidents in electronic health records (EHRs) after they have occurred, while disregarding integrating real-time injury reporting within its framework. We explore the potential challenges associated with integrating ICD-11 into AAS by analyzing external causes of morbidity or mortality and the dimensions of external causes as potential areas of integration. We recognize the themes: (i) incident of injury, (ii) mode of transport, (iii) indoor location, (iv) outdoor location, and (v) type of building, and identify four challenges: (i) conceptual differences between the two systems, (ii) injury identification, (iii) presence of entities below the shoreline in ICD-11, and (iv) lack of specificity in certain ICD-11 codes related to AASs. For easy integration of ICD-11 into AASs, we recommend an AAS data dictionary and propose ICD-11 updates related to external causes of injury.
DO  - 10.3233/SHTI240395
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Czech medical coding assistant based on transformer networks.
AU  - Ladislav Lenc
AU  - Jiří Martínek
AU  - Josef Baloun
AU  - Pavel Přibáň
AU  - Martin Prantl
AU  - Stephen Eugene Taylor
AU  - Pavel Král
AU  - Jiří Kyliš
SN  - 1879-0534
AB  - The International Classification of Diseases (ICD) hierarchical taxonomy is used for so-called clinical coding of medical reports, typically presented in unstructured text. In the Czech Republic, it is currently carried out manually by a so-called clinical coder. However, due to the human factor, this process is error-prone and expensive. The coder needs to be properly trained and spends significant effort on each report, leading to occasional mistakes. The main goal of this paper is to propose and implement a system that serves as an assistant to the coder and automatically predicts diagnosis codes. These predictions are then presented to the coder for approval or correction, aiming to enhance efficiency and accuracy. We consider two classification tasks: main (principal) diagnosis; and all diagnoses. Crucial requirements for the implementation include minimal memory consumption, generality, ease of portability, and sustainability. The main contribution lies in the proposal and evaluation of ICD classification models for the Czech language with relatively few training parameters, allowing swift utilisation on the prevalent computer systems within Czech hospitals and enabling easy retraining or fine-tuning with newly available data. First, we introduce a small transformer-based model for each task followed by the design of a transformer-based "Four-headed" model incorporating four distinct classification heads. This model achieves comparable, sometimes even better results, against four individual models. Moreover this novel model significantly economises memory usage and learning time. We also show that our models achieve comparable results against state-of-the-art English models on the Mimic IV dataset even though our models are significantly smaller.
DO  - 10.1016/j.compbiomed.2024.108672
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - An Information Retrieval Approach to ICD-10 Classification.
AU  - Hee Park
AU  - José Castaño
AU  - Pilar Ávila
AU  - David Pérez
AU  - Hernán Berinsky
AU  - Laura Gambarte
AU  - Daniel Luna
AU  - Carlos Otero
SN  - 1879-8365
AB  - ICD-10 (International Classification of Diseases 10th revision) is a classification code for diseases, signs and symptoms, abnormal findings, complaints, social circumstances, and external causes of injury or diseases. This paper describes an automatic information retrieval approach to map free-text disease descriptions to ICD-10 codes. We use the Hospital Italiano de Buenos Aires (HIBA) terminology data mapped to ICD-10 codes as indexed data to find an appropriate ICD-10 code using search engine similarity metrics.
DO  - 10.3233/SHTI190536
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - [The International Classification of Functioning, Disability and Health (ICF) : The implementation of the ICF Core Sets for Hand Conditions in clinical routine as an example of application].
AU  - Michaela Coenen
AU  - Klaus-Dieter Rudolf
AU  - Sandra Kus
AU  - Caroline Dereskewitz
SN  - 1437-1588
AB  - The International Classification of Functioning, Disability and Health (ICF) provides a standardized language of almost 1500 ICF categories for coding information about functioning and contextual factors. Short lists (ICF Core Sets) are helpful tools to support the implementation of the ICF in clinical routine. In this paper we report on the implementation of ICF Core Sets in clinical routine using the "ICF Core Sets for Hand Conditions" and the "Lighthouse Project Hand" as an example. Based on the ICF categories of the "Brief ICF Core Set for Hand Conditions", the ICF-based assessment tool (ICF Hand
DO  - 10.1007/s00103-018-2748-5
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Enhanced ICD-10 code assignment of clinical texts: A summarization-based approach.
AU  - Yaoqian Sun
AU  - Lei Sang
AU  - Dan Wu
AU  - Shilin He
AU  - Yani Chen
AU  - Huilong Duan
AU  - Han Chen
AU  - Xudong Lu
SN  - 1873-2860
AB  - BACKGROUND: Assigning International Classification of Diseases (ICD) codes to clinical texts is a common and crucial practice in patient classification, hospital management, and further statistics analysis. Current auto-coding methods mainly transfer this task to a multi-label classification problem. Such solutions are suffering from high-dimensional mapping space and excessive redundant information in long clinical texts. To alleviate such a situation, we introduce text summarization methods to the ICD coding regime and apply text matching to select ICD codes. METHOD: We focus on the tenth revision of the ICD (ICD-10) coding and design a novel summarization-based approach (SuM) with an end-to-end strategy to efficiently assign ICD-10 code to clinical texts. In this approach, a knowledge-guided pointer network is purposed to distill and summarize key information in clinical texts precisely. Then a matching model with matching-aggregation architecture follows to align the summary result with code, tuning the one-vs-all scenario to one-vs-one matching so that the large-label-space obstacle laid in classification approaches would be avoided. RESULT: The 12,788 ICD-10 coded discharge summaries from a Chinese hospital were collected to evaluate the proposed approach. Compared with existing methods, the purposed model achieves the greatest coding results with Micro AUC of 0.9548, MRR@10 of 0.7977, Precision@10 of 0.0944, and Recall@10 of 0.9439 for the TOP-50 Dataset. Results on the FULL-Dataset remain consistent. Also, the proposed knowledge encoder and applied end-to-end strategy are proven to facilitate the whole model to gain efficacy in selecting the most suitable code. CONCLUSION: The proposed automatic ICD-10 code assignment approach via text summarization can effectively capture critical messages in long clinical texts and improve the performance of ICD-10 coding of clinical texts.
DO  - 10.1016/j.artmed.2024.102967
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automated ICD coding via unsupervised knowledge integration (UNITE).
AU  - Aaron Sonabend W
AU  - Winston Cai
AU  - Yuri Ahuja
AU  - Ashwin Ananthakrishnan
AU  - Zongqi Xia
AU  - Sheng Yu
AU  - Chuan Hong
SN  - 1872-8243
AB  - OBJECTIVE: Accurate coding is critical for medical billing and electronic medical record (EMR)-based research. Recent research has been focused on developing supervised methods to automatically assign International Classification of Diseases (ICD) codes from clinical notes. However, supervised approaches rely on ICD code data stored in the hospital EMR system and is subject to bias rising from the practice and coding behavior. Consequently, portability of trained supervised algorithms to external EMR systems may suffer. METHOD: We developed an unsupervised knowledge integration (UNITE) algorithm to automatically assign ICD codes for a specific disease by analyzing clinical narrative notes via semantic relevance assessment. The algorithm was validated using coded ICD data for 6 diseases from Partners HealthCare (PHS) Biobank and Medical Information Mart for Intensive Care (MIMIC-III). We compared the performance of UNITE against penalized logistic regression (LR), topic modeling, and neural network models within each EMR system. We additionally evaluated the portability of UNITE by training at PHS Biobank and validating at MIMIC-III, and vice versa. RESULTS: UNITE achieved an averaged AUC of 0.91 at PHS and 0.92 at MIMIC over 6 diseases, comparable to LR and MLP. It had substantially better performance than topic models. In regards to portability, the performance of UNITE was consistent across different EMR systems, superior to LR, topic models and neural network models. CONCLUSION: UNITE accurately assigns ICD code in EMR without requiring human labor, and has major advantages over commonly used machine learning approaches. In addition, the UNITE attained stable performance and high portability across EMRs in different institutions.
DO  - 10.1016/j.ijmedinf.2020.104135
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Trends and opportunities in computable clinical phenotyping: A scoping review.
AU  - Ting He
AU  - Anas Belouali
AU  - Jessica Patricoski
AU  - Harold Lehmann
AU  - Robert Ball
AU  - Valsamo Anagnostou
AU  - Kory Kreimeyer
AU  - Taxiarchis Botsis
SN  - 1532-0480
AB  - Identifying patient cohorts meeting the criteria of specific phenotypes is essential in biomedicine and particularly timely in precision medicine. Many research groups deliver pipelines that automatically retrieve and analyze data elements from one or more sources to automate this task and deliver high-performing computable phenotypes. We applied a systematic approach based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines to conduct a thorough scoping review on computable clinical phenotyping. Five databases were searched using a query that combined the concepts of automation, clinical context, and phenotyping. Subsequently, four reviewers screened 7960 records (after removing over 4000 duplicates) and selected 139 that satisfied the inclusion criteria. This dataset was analyzed to extract information on target use cases, data-related topics, phenotyping methodologies, evaluation strategies, and portability of developed solutions. Most studies supported patient cohort selection without discussing the application to specific use cases, such as precision medicine. Electronic Health Records were the primary source in 87.1 % (N = 121) of all studies, and International Classification of Diseases codes were heavily used in 55.4 % (N = 77) of all studies, however, only 25.9 % (N = 36) of the records described compliance with a common data model. In terms of the presented methods, traditional Machine Learning (ML) was the dominant method, often combined with natural language processing and other approaches, while external validation and portability of computable phenotypes were pursued in many cases. These findings revealed that defining target use cases precisely, moving away from sole ML strategies, and evaluating the proposed solutions in the real setting are essential opportunities for future work. There is also momentum and an emerging need for computable phenotyping to support clinical and epidemiological research and precision medicine.
DO  - 10.1016/j.jbi.2023.104335
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automatically identifying opioid use disorder in non-cancer patients on chronic opioid therapy.
AU  - Vivienne J Zhu
AU  - Leslie A Lenert
AU  - Kelly S Barth
AU  - Kit N Simpson
AU  - Hong Li
AU  - Michael Kopscik
AU  - Kathleen T Brady
SN  - 1741-2811
DO  - 10.1177/14604582221107808
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Combining deep neural networks, a rule-based expert system and targeted manual coding for ICD-10 coding causes of death of French death certificates from 2018 to 2019.
AU  - Elisa Zambetta
AU  - Nirintsoa Razakamanana
AU  - Aude Robert
AU  - François Clanché
AU  - Cecilia Rivera
AU  - Diane Martin
AU  - Zina Hebbache
AU  - Rémi Flicoteaux
AU  - Elise Coudin
SN  - 1872-8243
AB  - OBJECTIVE: For ICD-10 coding causes of death in France in 2018 and 2019, predictions by deep neural networks (DNNs) are employed in addition to fully automatic batch coding by a rule-based expert system and to interactive coding by the coding team focused on certificates with a special public health interest and those for which DNNs have a low confidence index. METHODS: Supervised seq-to-seq DNNs are trained on previously coded data to ICD-10 code multiple causes and underlying causes of death. The DNNs are then used to target death certificates to be sent to the coding team and to predict multiple causes and underlying causes of death for part of the certificates. Hence, the coding campaign for 2018 and 2019 combines three modes of coding and a loop of interaction between the three. FINDINGS: In this campaign, 62% of the certificates are automatically batch coded by the expert system, 3% by the coding team, and the remainder by DNNs. Compared to a traditional campaign that would have relied on automatic batch coding and manual coding, the present campaign reaches an accuracy of 93.4% for ICD-10 coding of the underlying cause (95.6% at the European shortlist level). Some limitations (risks of under- or overestimation) appear for certain ICD categories, with the advantage of being quantifiable. CONCLUSION: The combination of the three coding methods illustrates how artificial intelligence, automated and human codings are mutually enriching. Quantified limitations on some chapters of ICD codes encourage an increase in the volume of certificates sent for manual coding from 2021 onward.
DO  - 10.1016/j.ijmedinf.2024.105462
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Development of a Method for Automatic Matching of Unstructured Medical Data to ICD-10 Codes.
AU  - Bogdan Volkov
AU  - Georgy Kopanitsa
SN  - 1879-8365
AB  - Inconsistent disease coding standards in medicine create hurdles in data exchange and analysis. This paper proposes a machine learning system to address this challenge. The system automatically matches unstructured medical text (doctor notes, complaints) to ICD-10 codes. It leverages a unique architecture featuring a training layer for model development and a knowledge base that captures relationships between symptoms and diseases. Experiments using data from a large medical research center demonstrated the system's effectiveness in disease classification prediction. Logistic regression emerged as the optimal model due to its superior processing speed, achieving an accuracy of 81.07% with acceptable error rates during high-load testing. This approach offers a promising solution to improve healthcare informatics by overcoming coding standard incompatibility and automating code prediction from unstructured medical text.
DO  - 10.3233/SHTI240065
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Hyperbolic graph convolutional neural network with contrastive learning for automated ICD coding.
AU  - Yuzhou Wu
AU  - Xuechen Chen
AU  - Xin Yao
AU  - Yongang Yu
AU  - Zhigang Chen
SN  - 1879-0534
AB  - The International Classification of Diseases (ICD) is a widely used criterion for disease classification, health monitoring, and medical data analysis. Deep learning-based automated ICD coding has gained attention due to the time-consuming and costly nature of manual coding. The main challenges of automated ICD coding include imbalanced label distribution, code hierarchy and noisy texts. Recent works have considered using code hierarchy or description for better label representation to solve the problem of imbalanced label distribution. However, these methods are still ineffective and redundant since they only interact with a constant label representation. In this work, we introduce a novel Hyperbolic Graph Convolutional Network with Contrastive Learning (HGCN-CL) to solve the above problems and the shortcomings of the previous methods. We adopt a Hyperbolic graph convolutional network on ICD coding to capture the hierarchical structure of codes, which can solve the problem of large distortions when embedding hierarchical structure with graph convolutional network. Besides, we introduce contrastive learning for automatic ICD coding by injecting code features into text encoder to generate hierarchical-aware positive samples to solve the problem of interacting with constant code features. We conduct experiments on the public MIMIC-III and MIMIC-II datasets. The results on MIMIC III show that HGCN-CL outperforms previous state-of-art methods for automatic ICD coding, which achieves a 2.7% and 3.6% improvement respectively compared to previous best results (Hypercore). We also provide ablation experiments and hierarchy visualization to verify the effectiveness of components in our model.
DO  - 10.1016/j.compbiomed.2023.107797
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - AUTOMATIC ICD-10 CODING USING PRESCRIBED DRUGS DATA.
AU  - Alexander Dokumentov
AU  - Yassien Shaalan
AU  - Piyapong Khumrin
AU  - Krit Khwanngern
AU  - Anawat Wisetborisut
AU  - Thanakom Hatsadeang
AU  - Nattapat Karaket
AU  - Witthawin Achariyaviriya
AU  - Sansanee Auephanwiriyakul
AU  - Nipon Theera-Umpon
AU  - Terence Siganakis
SN  - 1559-4122
AB  - This article discusses the emerging trends and challenges related to automatic clinical coding. We introduce an automatic coding system, which assigns short ICD-10 codes (restricted to the first three symbols, which define the category of the disease) based only on drugs prescribed to patients. We show that even with limited input data, the accuracy levels are comparable to those achieved by entry-level clinical coders as depicted by Seyed Nouraei et al.
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Mapping of UK Biobank clinical codes: Challenges and possible solutions.
AU  - Oleg Stroganov
AU  - Alena Fedarovich
AU  - Emily Wong
AU  - Yulia Skovpen
AU  - Elena Pakhomova
AU  - Ivan Grishagin
AU  - Dzmitry Fedarovich
AU  - Tania Khasanova
AU  - David Merberg
AU  - Sándor Szalma
AU  - Julie Bryant
SN  - 1932-6203
AB  - OBJECTIVE: The UK Biobank provides a rich collection of longitudinal clinical data coming from different healthcare providers and sources in England, Wales, and Scotland. Although extremely valuable and available to a wide research community, the heterogeneous dataset contains inconsistent medical terminology that is either aligned to several ontologies within the same category or unprocessed. To make these data useful to a research community, data cleaning, curation, and standardization are needed. Significant efforts to perform data reformatting, mapping to any selected ontologies (such as SNOMED-CT) and harmonization are required from any data user to integrate UK Biobank hospital inpatient and self-reported data, data from various registers with primary care (GP) data. The integrated clinical data would provide a more comprehensive picture of one's medical history. MATERIALS AND METHODS: We evaluated several approaches to map GP clinical Read codes to International Classification of Diseases (ICD) and Systematized Nomenclature of Medicine Clinical Terms (SNOMED CT) terminologies. The results were compared, mapping inconsistencies were flagged, a quality category was assigned to each mapping to evaluate overall mapping quality. RESULTS: We propose a curation and data integration pipeline for harmonizing diagnosis. We also report challenges identified in mapping Read codes from UK Biobank GP tables to ICD and SNOMED CT. DISCUSSION AND CONCLUSION: Some of the challenges-the lack of precise one-to-one mapping between ontologies or the need for additional ontology to fully map terms-are general reflecting trade-offs to be made at different steps. Other challenges are due to automatic mapping and can be overcome by leveraging existing mappings, supplemented with automated and manual curation.
DO  - 10.1371/journal.pone.0275816
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automated identification of diagnostic labelling errors in medicine.
AU  - Wolf E Hautz
AU  - Moritz M Kündig
AU  - Roger Tschanz
AU  - Tanja Birrenbach
AU  - Alexander Schuster
AU  - Thomas Bürkle
AU  - Stefanie C Hautz
AU  - Thomas C Sauter
AU  - Gert Krummrey
SN  - 2194-802X
AB  - OBJECTIVES: Identification of diagnostic error is complex and mostly relies on expert ratings, a severely limited procedure. We developed a system that allows to automatically identify diagnostic labelling error from diagnoses coded according to the international classification of diseases (ICD), often available as routine health care data. METHODS: The system developed (index test) was validated against rater based classifications taken from three previous studies of diagnostic labeling error (reference standard). The system compares pairs of diagnoses through calculation of their distance within the ICD taxonomy. Calculation is based on four different algorithms. To assess the concordance between index test and reference standard, we calculated the area under the receiver operating characteristics curve (AUROC) and corresponding confidence intervals. Analysis were conducted overall and separately per algorithm and type of available dataset. RESULTS: Diagnoses of 1,127 cases were analyzed. Raters previously classified 24.58% of cases as diagnostic labelling errors (ranging from 12.3 to 87.2% in the three datasets). AUROC ranged between 0.821 and 0.837 overall, depending on the algorithm used to calculate the index test (95% CIs ranging from 0.8 to 0.86). Analyzed per type of dataset separately, the highest AUROC was 0.924 (95% CI 0.887-0.962). CONCLUSIONS: The trigger system to automatically identify diagnostic labeling error from routine health care data performs excellent, and is unaffected by the reference standards' limitations. It is however only applicable to cases with pairs of diagnoses, of which one must be more accurate or otherwise superior than the other, reflecting a prevalent definition of a diagnostic labeling error.
DO  - 10.1515/dx-2021-0039
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automatic multilabel detection of ICD10 codes in Dutch cardiology discharge letters using neural networks.
AU  - Arjan Sammani
AU  - Ayoub Bagheri
AU  - Peter G M van der Heijden
AU  - Anneline S J M Te Riele
AU  - Annette F Baas
AU  - C A J Oosters
AU  - Daniel Oberski
AU  - Folkert W Asselbergs
SN  - 2398-6352
AB  - Standard reference terminology of diagnoses and risk factors is crucial for billing, epidemiological studies, and inter/intranational comparisons of diseases. The International Classification of Disease (ICD) is a standardized and widely used method, but the manual classification is an enormously time-consuming endeavor. Natural language processing together with machine learning allows automated structuring of diagnoses using ICD-10 codes, but the limited performance of machine learning models, the necessity of gigantic datasets, and poor reliability of terminal parts of these codes restricted clinical usability. We aimed to create a high performing pipeline for automated classification of reliable ICD-10 codes in the free medical text in cardiology. We focussed on frequently used and well-defined three- and four-digit ICD-10 codes that still have enough granularity to be clinically relevant such as atrial fibrillation (I48), acute myocardial infarction (I21), or dilated cardiomyopathy (I42.0). Our pipeline uses a deep neural network known as a Bidirectional Gated Recurrent Unit Neural Network and was trained and tested with 5548 discharge letters and validated in 5089 discharge and procedural letters. As in clinical practice discharge letters may be labeled with more than one code, we assessed the single- and multilabel performance of main diagnoses and cardiovascular risk factors. We investigated using both the entire body of text and only the summary paragraph, supplemented by age and sex. Given the privacy-sensitive information included in discharge letters, we added a de-identification step. The performance was high, with F1 scores of 0.76-0.99 for three-character and 0.87-0.98 for four-character ICD-10 codes, and was best when using complete discharge letters. Adding variables age/sex did not affect results. For model interpretability, word coefficients were provided and qualitative assessment of classification was manually performed. Because of its high performance, this pipeline can be useful to decrease the administrative burden of classifying discharge diagnoses and may serve as a scaffold for reimbursement and research applications.
DO  - 10.1038/s41746-021-00404-9
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - [Automatic ICD-10 coding : Natural language processing for German MRI reports].
AU  - Andreas Mittermeier
AU  - Matthias Aßenmacher
AU  - Balthasar Schachtner
AU  - Sergio Grosu
AU  - Vladana Dakovic
AU  - Viktar Kandratovich
AU  - Bastian Sabel
AU  - Michael Ingrisch
SN  - 2731-7056
AB  - BACKGROUND: The medical coding of radiology reports is essential for a good quality of care and correct billing, but at the same time a complex and error-prone task. OBJECTIVE: To assess the performance of natural language processing (NLP) for ICD-10 coding of German radiology reports using fine tuning of suitable language models. MATERIAL AND METHODS: This retrospective study included all magnetic resonance imaging (MRI) radiology reports acquired at our institution between 2010 and 2020. The codes on discharge ICD-10 were matched to the corresponding reports to construct a dataset for multiclass classification. Fine tuning of GermanBERT and flanT5 was carried out on the total dataset (ds RESULTS: The total dataset consisted of 100,672 radiology reports, the reduced subsets ds CONCLUSION: Finely tuned language models can reliably predict ICD-10 codes of German magnetic resonance imaging (MRI) radiology reports across various settings. As a coding assistant flanT5 can guide medical coders to make informed decisions and potentially reduce the workload.
DO  - 10.1007/s00117-024-01349-2
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - AnEMIC: A Framework for Benchmarking ICD Coding Models.
AU  - Juyong Kim
AU  - Abheesht Sharma
AU  - Suhas Shanbhogue
AU  - Pradeep Ravikumar
AU  - Jeremy C Weiss
AB  - Diagnostic coding, or ICD coding, is the task of assigning diagnosis codes defined by the ICD (International Classification of Diseases) standard to patient visits based on clinical notes. The current process of manual ICD coding is time-consuming and often error-prone, which suggests the need for automatic ICD coding. However, despite the long history of automatic ICD coding, there have been no standardized frameworks for benchmarking ICD coding models. We open-source an easy-to-use tool named 
DO  - 10.18653/v1/2022.emnlp-demos.11
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automatic ICD-10 Coding and Training System: Deep Neural Network Based on Supervised Learning.
AU  - Pei-Fu Chen
AU  - Ssu-Ming Wang
AU  - Wei-Chih Liao
AU  - Lu-Cheng Kuo
AU  - Kuan-Chih Chen
AU  - Yu-Cheng Lin
AU  - Chi-Yu Yang
AU  - Chi-Hao Chiu
AU  - Shu-Chih Chang
AU  - Feipei Lai
SN  - 2291-9694
AB  - BACKGROUND: The International Classification of Diseases (ICD) code is widely used as the reference in medical system and billing purposes. However, classifying diseases into ICD codes still mainly relies on humans reading a large amount of written material as the basis for coding. Coding is both laborious and time-consuming. Since the conversion of ICD-9 to ICD-10, the coding task became much more complicated, and deep learning- and natural language processing-related approaches have been studied to assist disease coders. OBJECTIVE: This paper aims at constructing a deep learning model for ICD-10 coding, where the model is meant to automatically determine the corresponding diagnosis and procedure codes based solely on free-text medical notes to improve accuracy and reduce human effort. METHODS: We used diagnosis records of the National Taiwan University Hospital as resources and apply natural language processing techniques, including global vectors, word to vectors, embeddings from language models, bidirectional encoder representations from transformers, and single head attention recurrent neural network, on the deep neural network architecture to implement ICD-10 auto-coding. Besides, we introduced the attention mechanism into the classification model to extract the keywords from diagnoses and visualize the coding reference for training freshmen in ICD-10. Sixty discharge notes were randomly selected to examine the change in the F RESULTS: In experiments on the medical data set of National Taiwan University Hospital, our prediction results revealed F CONCLUSIONS: The proposed model significantly improved the F
DO  - 10.2196/23230
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - [First biennium of mortality statistics with, the automatic system Iris for coding multiple causes of death].
AU  - Lluís Cirera Suárez
SN  - 1578-1283
DO  - 10.1016/j.gaceta.2016.11.009
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - EHR coding with hybrid attention and features propagation on disease knowledge graph.
AU  - Tianhan Xu
AU  - Bin Li
AU  - Ling Chen
AU  - Chao Yang
AU  - Yixun Gu
AU  - Xiang Gu
SN  - 1873-2860
AB  - And sentences associated with these attributes and relationships have been neglected. in this paper ►We propose an end-to-end model called Knowledge Graph Enhanced neural network (KGENet) to address the above shortcomings. specifically ►We first construct a disease knowledge graph that focuses on the multi-view disease attributes of ICD codes and the disease relationships between these codes. we also use a long sequence encoder to get EHR document representation. most importantly ►KGENet leverages multi-view disease attributes and structured disease relationships for knowledge enhancement through hybrid attention and graph propagation ►Respectively. furthermore ►The above processes can provide attribute-aware and relationship-augmented explainability for the model prediction results based on our disease knowledge graph. experiments conducted on the MIMIC-III benchmark dataset show that KGENet outperforms state-of-the-art models in both model effectiveness and explainability Electronic health record (EHR) coding assigns International Classification of Diseases (ICD) codes to each EHR document. These standard medical codes represent diagnoses or procedures and play a critical role in medical applications. However, EHR is a long medical text that is difficult to represent, the ICD code label space is large, and the labels have an extremely unbalanced distribution. These factors pose challenges to automatic EHR coding. Previous studies have not explored the disease attributes (e.g., symptoms, tests, medications) of ICD codes and the disease relationships (e.g., causes, risk factors, comorbidities) between them. In addition, the important roles of medical.
DO  - 10.1016/j.artmed.2024.102916
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Multi-label Few-shot ICD Coding as Autoregressive Generation with Prompt.
AU  - Zhichao Yang
AU  - Sunjae Kwon
AU  - Zonghai Yao
AU  - Hong Yu
SN  - 2374-3468
AB  - Automatic International Classification of Diseases (ICD) coding aims to assign multiple ICD codes to a medical note with an average of 3,000+ tokens. This task is challenging due to the high-dimensional space of multi-label assignment (155,000+ ICD code candidates) and the long-tail challenge - Many ICD codes are infrequently assigned yet infrequent ICD codes are important clinically. This study addresses the long-tail challenge by transforming this multi-label classification task into an autoregressive generation task. Specifically, we first introduce a novel pretraining objective to generate free text diagnoses and procedures using the SOAP structure, the medical logic physicians use for note documentation. Second, instead of directly predicting the high dimensional space of ICD codes, our model generates the lower dimension of text descriptions, which then infers ICD codes. Third, we designed a novel prompt template for multi-label classification. We evaluate our Generation with Prompt (GP
DO  - 10.1609/aaai.v37i4.25668
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - PEMT: a patent enrichment tool for drug discovery.
AU  - Yojana Gadiya
AU  - Andrea Zaliani
AU  - Philip Gribbon
AU  - Martin Hofmann-Apitius
SN  - 1367-4811
AB  - MOTIVATION: Drug discovery practitioners in industry and academia use semantic tools to extract information from online scientific literature to generate new insights into targets, therapeutics and diseases. However, due to complexities in access and analysis, patent-based literature is often overlooked as a source of information. As drug discovery is a highly competitive field, naturally, tools that tap into patent literature can provide any actor in the field an advantage in terms of better informed decision-making. Hence, we aim to facilitate access to patent literature through the creation of an automatic tool for extracting information from patents described in existing public resources. RESULTS: Here, we present PEMT, a novel patent enrichment tool, that takes advantage of public databases like ChEMBL and SureChEMBL to extract relevant patent information linked to chemical structures and/or gene names described through FAIR principles and metadata annotations. PEMT aims at supporting drug discovery and research by establishing a patent landscape around genes of interest. The pharmaceutical focus of the tool is mainly due to the subselection of International Patent Classification codes, but in principle, it can be used for other patent fields, provided that a link between a concept and chemical structure is investigated. Finally, we demonstrate a use-case in rare diseases by generating a gene-patent list based on the epidemiological prevalence of these diseases and exploring their underlying patent landscapes. AVAILABILITY AND IMPLEMENTATION: PEMT is an open-source Python tool and its source code and PyPi package are available at https://github.com/Fraunhofer-ITMP/PEMT and https://pypi.org/project/PEMT/, respectively. SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics online.
DO  - 10.1093/bioinformatics/btac716
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automatic ICD code assignment of Chinese clinical notes based on multilayer attention BiRNN.
AU  - Ying Yu
AU  - Min Li
AU  - Liangliang Liu
AU  - Zhihui Fei
AU  - Fang-Xiang Wu
AU  - Jianxin Wang
SN  - 1532-0480
AB  - International Classification of Diseases (ICD) code is an important label of electronic health record. The automatic ICD code assignment based on the narrative of clinical documents is an essential task which has drawn much attention recently. When Chinese clinical notes are the input corpus, the nature of Chinese brings some issues that need to be considered, such as the accuracy of word segmentation and the representation of single Chinese characters which contain semantics. Taking the lengthy text of patient notes and the representation of Chinese words into account, we present a multilayer attention bidirectional recurrent neural network (MA-BiRNN) model to implement the assignment of disease codes. A hierarchical approach is used to represent the feature of discharge summaries without manual feature engineering. The combination of character level embedding and word level embedding can improve the representation of words. Attention mechanism is introduced into bidirectional long short term memory networks, which helps to solve the performance dropping problem when plain recurrent neural networks encounter long text sequences. The experiment is carried out on a real-world dataset containing 7732 admission records in Chinese and 1177 unique ICD-10 labels. The proposed model achieves 0.639 and 0.766 in F1-score on full-level code and block-level code, respectively. It outperforms the baseline neural network models and achieves the lowest Hamming loss value. Ablation analysis indicates that the multilevel attention mechanism plays a decisive role in the system for dealing with Chinese clinical notes.
DO  - 10.1016/j.jbi.2019.103114
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automatic Identification of Individual Drugs in Death Certificates.
AU  - Soon Jye Kho
AU  - Amit Sheth
AU  - Olivier Bodenreider
SN  - 1879-8365
AB  - BACKGROUND: Establishing trends of drug overdoses requires the identification of individual drugs in death certificates, not supported by coding with the International Classification of Diseases. However, identifying drug mentions from the literal portion of death certificates remains challenging due to the variability of drug names. OBJECTIVES: To automatically identify individual drugs in death certificates. METHODS: We use RxNorm to collect variants for drug names (generic names, synonyms, brand names) and we algorithmically generate common misspellings. We use this automatically compiled list to identify drug mentions from 703,106 death certificates and compare the performance of our automated approach to that of a manually curated list of drug names. RESULTS: Our automated approach shows a slight loss in recall (4.3%) compared to the manual approach (for individual drugs), due in part to acronyms. CONCLUSIONS: Maintenance of a manually curated list of drugs is not sustainable and our approach offers a viable alternative.
DO  - 10.3233/SHTI190208
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Identification of patients with epilepsy using automated electronic health records phenotyping.
AU  - Marta Fernandes
AU  - Aidan Cardall
AU  - Jin Jing
AU  - Wendong Ge
AU  - Lidia M V R Moura
AU  - Claire Jacobs
AU  - Christopher McGraw
AU  - Sahar F Zafar
AU  - M Brandon Westover
SN  - 1528-1167
AB  - OBJECTIVE: Unstructured data present in electronic health records (EHR) are a rich source of medical information; however, their abstraction is labor intensive. Automated EHR phenotyping (AEP) can reduce the need for manual chart review. We present an AEP model that is designed to automatically identify patients diagnosed with epilepsy. METHODS: The ground truth for model training and evaluation was captured from a combination of structured questionnaires filled out by physicians for a subset of patients and manual chart review using customized software. Modeling features included indicators of the presence of keywords and phrases in unstructured clinical notes, prescriptions for antiseizure medications (ASMs), International Classification of Diseases (ICD) codes for seizures and epilepsy, number of ASMs and epilepsy-related ICD codes, age, and sex. Data were randomly divided into training (70%) and hold-out testing (30%) sets, with distinct patients in each set. We trained regularized logistic regression and an extreme gradient boosting models. Model performance was measured using area under the receiver operating curve (AUROC) and area under the precision-recall curve (AUPRC), with 95% confidence intervals (CI) estimated via bootstrapping. RESULTS: Our study cohort included 3903 adults drawn from outpatient departments of nine hospitals between February 2015 and June 2022 (mean age = 47 ± 18 years, 57% women, 82% White, 84% non-Hispanic, 70% with epilepsy). The final models included 285 features, including 246 keywords and phrases captured from 8415 encounters. Both models achieved AUROC and AUPRC of 1 (95% CI = .99-1.00) in the hold-out testing set. SIGNIFICANCE: A machine learning-based AEP approach accurately identifies patients with epilepsy from notes, ICD codes, and ASMs. This model can enable large-scale epilepsy research using EHR databases.
DO  - 10.1111/epi.17589
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Mapping of ICD-O Tuples to OncoTree Codes Using SNOMED CT Post-Coordination.
AU  - Tessa Ohlsen
AU  - Valerie Kruse
AU  - Rosemarie Krupar
AU  - Alexandra Banach
AU  - Josef Ingenerf
AU  - Cora Drenkhahn
SN  - 1879-8365
AB  - Around 500,000 oncological diseases are diagnosed in Germany every year which are documented using the International Classification of Diseases for Oncology (ICD-O). Apart from this, another classification for oncology, OncoTree, is often used for the integration of new research findings in oncology. For this purpose, a semi-automatic mapping of ICD-O tuples to OncoTree codes was developed. The implementation uses a FHIR terminology server, pre-coordinated or post-coordinated SNOMED CT expressions, and subsumption testing. Various validations have been applied. The results were compared with reference data of scientific papers and manually evaluated by a senior pathologist, confirming the applicability of SNOMED CT in general and its post-coordinated expressions in particular as a viable intermediate mapping step. Resulting in an agreement of 84,00 % between the newly developed approach and the manual mapping, it becomes obvious that the present approach has the potential to be used in everyday medical practice.
DO  - 10.3233/SHTI220464
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - An explainable CNN approach for medical codes prediction from clinical text.
AU  - Shuyuan Hu
AU  - Fei Teng
AU  - Lufei Huang
AU  - Jun Yan
AU  - Haibo Zhang
SN  - 1472-6947
AB  - BACKGROUND: Clinical notes are unstructured text documents generated by clinicians during patient encounters, generally are annotated with International Classification of Diseases (ICD) codes, which give formatted information about the diagnosis and treatment. ICD code has shown its potentials in many fields, but manual coding is labor-intensive and error-prone, lead to researches of automatic coding. Two specific challenges of this task are (1) given an annotated clinical notes, the reasons behind specific diagnoses and treatments are  implicit; (2) explainability is important for practical automatic coding method, the method should not only explain its prediction output but also have explainable internal mechanics. This study aims to develop an explainable CNN approach to address these two challenges. METHOD: Our key idea is that for the automatic ICD coding task, the presence of informative snippets in the clinical text that correlated with each code plays an important role in the prediction of codes, and an informative snippet can be considered as a local and low-level feature. We infer that there exists a correspondence between a convolution filter and a local and low-level feature. Base on the inference, we come up with the Shallow and Wide Attention convolutional Mechanism (SWAM) to improve the CNN-based models' ability to learn local and low-level features for each label. RESULTS: We evaluate our approach on MIMIC-III, an open-access dataset of ICU medical records. Our approach substantially outperforms previous results on top-50 medical code prediction on MIMIC-III dataset, the precision of the worst-performing 10% labels in previous works is increased from 0% to 53% on average. We attribute this improvement to SWAM, by which the wide architecture with attention mechanism gives the model ability to more extensively learn the unique features of different codes, and we prove it by an ablation experiment. Besides, we perform manual analysis of the performance imbalance between different codes, and preliminary conclude the characteristics that determine the difficulty of learning specific codes. CONCLUSIONS: Our main contributions can be summarized into the following three: (1) We present local and low-level features, a.k.a. informative snippets play an important role in the automatic ICD coding task, and the informative snippets extracted from the clinical text provide explanations for each code. (2) We propose that there exists a correspondence between a convolution filter and a local and low-level feature. A combination of wide and shallow convolutional layer and attention layer can help the CNN-based models better learn local and low-level features. (3) We improved the precision of the worst-performing 10% labels from 0 to 53% on average.
DO  - 10.1186/s12911-021-01615-6
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Feasibility of coding-based Charlson comorbidity index for hospitalized patients in China, a representative developing country.
AU  - Liyi Mo
AU  - Zhen Xie
AU  - Guohui Liu
AU  - Qiang He
AU  - Zhiming Mo
AU  - Yanhua Wu
AU  - Wenji Wang
AU  - Feng Ding
AU  - Yuanjiang Liao
AU  - Li Hao
AU  - Chen Lu
AU  - Jin Sun
AU  - Libin Xu
AU  - Yusheng Zhang
AU  - Rizwangul Ghappar
AU  - Hongwei Peng
AU  - Xiaohong Wei
AU  - Jinglie Xie
AU  - Yuanhan Chen
AU  - Xinling Liang
SN  - 1472-6963
AB  - BACKGROUND: The Charlson Comorbidity Index (CCI) can be automatically calculated from the International Classification of Disease (ICD) code. However, the feasibility of this transformation has not been acknowledged, particularly in hospitals without a qualified ICD coding system. Here, we investigated the utility of coding-based CCI in China. METHODS: A multi-center, population-based, retrospective observational study was conducted, using a dataset incorporating 2,464,395 adult subjects from 15 hospitals. CCI was calculated using both ICD-10-based and diagnosis-based method, according to the transformation rule reported previously and to the literal description from discharge diagnosis, respectively. A κ coefficient of variation was used as a measure of agreement between the above two methods for each hospital. The discriminative abilities of the two methods were compared using the receiver-of-operating characteristic curve (ROC) for prediction of in-hospital mortality. RESULTS: Total agreement between the ICD-based and diagnosis-based CCI for each index ranged from 86.1 to 100%, with κ coefficients from 0.210 [95% confidence interval (CI) 0.208-0.212] to 0.932 (95% CI 0.924-0.940). None of the 19 indices of CCI had a κ coefficient > 0.75 in all the hospitals included for study. The area under the curve of ROC for in-hospital mortality of all 15 hospitals was significantly lower for ICD-based than diagnosis-based CCI [0.735 (0.732, 0.739) vs 0.760 (0.757, 0.764)], indicative of more limited discriminative ability of the ICD-based calculation. CONCLUSIONS: CCI calculated using ICD-10 coding did not agree with diagnosis-based CCI. ICD-based CCI displayed diminished discrimination performance in terms of in-hospital mortality, indicating that this method is not promising for CCI scoring in China under the present circumstances.
DO  - 10.1186/s12913-020-05273-8
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automated ICD-9 Coding via A Deep Learning Approach.
AU  - Min Li
AU  - Zhihui Fei
AU  - Min Zeng
AU  - Fang-Xiang Wu
AU  - Yaohang Li
AU  - Yi Pan
AU  - Jianxin Wang
SN  - 1557-9964
AB  - ICD-9 (the Ninth Revision of International Classification of Diseases) is widely used to describe a patient's diagnosis. Accurate automated ICD-9 coding is important because manual coding is expensive, time-consuming, and inefficient. Inspired by the recent successes of deep learning, in this study, we present a deep learning framework called DeepLabeler to automatically assign ICD-9 codes. DeepLabeler combines the convolutional neural network with the 'Document to Vector' technique to extract and encode local and global features. Our proposed DeepLabeler demonstrates its effectiveness by achieving state-of-the-art performance, i.e., 0.335 micro F-measure on MIMIC-II dataset and 0.408 micro F-measure on MIMIC-III dataset. It outperforms classical hierarchy-based SVM and flat-SVM both on these two datasets by at least 14 percent. Furthermore, we analyze the deep neural network structure to discover the vital elements in the success of DeepLabeler. We find that the convolutional neural network is the most effective component in our network and the 'Document to Vector' technique is also necessary for enhancing classification performance since it extracts well-recognized global features. Extensive experimental results demonstrate that the great promise of deep learning techniques in the field of text multi-label classification and automated medical coding.
DO  - 10.1109/TCBB.2018.2817488
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Creating a computer assisted ICD coding system: Performance metric choice and use of the ICD hierarchy.
AU  - Quentin Marcou
AU  - Laure Berti-Equille
AU  - Noël Novelli
SN  - 1532-0480
AB  - OBJECTIVE: Machine learning methods hold the promise of leveraging available data and generating higher-quality data while alleviating the data collection burden on healthcare professionals. International Classification of Diseases (ICD) diagnoses data, collected globally for billing and epidemiological purposes, represents a valuable source of structured information. However, ICD coding is a challenging task. While numerous previous studies reported promising results in automatic ICD classification, they often describe input data specific model architectures, that are heterogeneously evaluated with different performance metrics and ICD code subsets. This study aims to explore the evaluation and construction of more effective Computer Assisted Coding (CAC) systems using generic approaches, focusing on the use of ICD hierarchy, medication data and a feed forward neural network architecture. METHODS: We conduct comprehensive experiments using the MIMIC-III clinical database, mapped to the OMOP data model. Our evaluations encompass various performance metrics, alongside investigations into multitask, hierarchical, and imbalanced learning for neural networks. RESULTS: We introduce a novel metric, , tailored to the ICD coding task, which offers interpretable insights for healthcare informatics practitioners, aiding them in assessing the quality of assisted coding systems. Our findings highlight that selectively cherry-picking ICD codes diminish retrieval performance without performance improvement over the selected subset. We show that optimizing for metrics such as NDCG and AUPRC outperforms traditional F1-based metrics in ranking performance. We observe that Neural Network training on different ICD levels simultaneously offers minor benefits for ranking and significant runtime gains. However, our models do not derive benefits from hierarchical or class imbalance correction techniques for ICD code retrieval. CONCLUSION: This study offers valuable insights for researchers and healthcare practitioners interested in developing and evaluating CAC systems. Using a straightforward sequential neural network model, we confirm that medical prescriptions are a rich data source for CAC systems, providing competitive retrieval capabilities for a fraction of the computational load compared to text-based models. Our study underscores the importance of metric selection and challenges existing practices related to ICD code sub-setting for model training and evaluation.
DO  - 10.1016/j.jbi.2024.104617
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Supervised Text Classification System Detects Fontan Patients in Electronic Records With Higher Accuracy Than 
AU  - Yuting Guo
AU  - Mohammed A Al-Garadi
AU  - Wendy M Book
AU  - Lindsey C Ivey
AU  - Fred H Rodriguez
AU  - Cheryl L Raskind-Hood
AU  - Chad Robichaux
AU  - Abeed Sarker
SN  - 2047-9980
AB  - Background The Fontan operation is associated with significant morbidity and premature mortality. Fontan cases cannot always be identified by 
DO  - 10.1161/JAHA.123.030046
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - The BioRef Infrastructure, a Framework for Real-Time, Federated, Privacy-Preserving, and Personalized Reference Intervals: Design, Development, and Application.
AU  - Tobias Ueli Blatter
AU  - Harald Witte
AU  - Jules Fasquelle-Lopez
AU  - Christos Theodoros Naka
AU  - Jean Louis Raisaro
AU  - Alexander Benedikt Leichtle
SN  - 1438-8871
AB  - BACKGROUND: Reference intervals (RIs) for patient test results are in standard use across many medical disciplines, allowing physicians to identify measurements indicating potentially pathological states with relative ease. The process of inferring cohort-specific RIs is, however, often ignored because of the high costs and cumbersome efforts associated with it. Sophisticated analysis tools are required to automatically infer relevant and locally specific RIs directly from routine laboratory data. These tools would effectively connect clinical laboratory databases to physicians and provide personalized target ranges for the respective cohort population. OBJECTIVE: This study aims to describe the BioRef infrastructure, a multicentric governance and IT framework for the estimation and assessment of patient group-specific RIs from routine clinical laboratory data using an innovative decentralized data-sharing approach and a sophisticated, clinically oriented graphical user interface for data analysis. METHODS: A common governance agreement and interoperability standards have been established, allowing the harmonization of multidimensional laboratory measurements from multiple clinical databases into a unified "big data" resource. International coding systems, such as the International Classification of Diseases, Tenth Revision (ICD-10); unique identifiers for medical devices from the Global Unique Device Identification Database; type identifiers from the Global Medical Device Nomenclature; and a universal transfer logic, such as the Resource Description Framework (RDF), are used to align the routine laboratory data of each data provider for use within the BioRef framework. With a decentralized data-sharing approach, the BioRef data can be evaluated by end users from each cohort site following a strict "no copy, no move" principle, that is, only data aggregates for the intercohort analysis of target ranges are exchanged. RESULTS: The TI4Health distributed and secure analytics system was used to implement the proposed federated and privacy-preserving approach and comply with the limitations applied to sensitive patient data. Under the BioRef interoperability consensus, clinical partners enable the computation of RIs via the TI4Health graphical user interface for query without exposing the underlying raw data. The interface was developed for use by physicians and clinical laboratory specialists and allows intuitive and interactive data stratification by patient factors (age, sex, and personal medical history) as well as laboratory analysis determinants (device, analyzer, and test kit identifier). This consolidated effort enables the creation of extremely detailed and patient group-specific queries, allowing the generation of individualized, covariate-adjusted RIs on the fly. CONCLUSIONS: With the BioRef-TI4Health infrastructure, a framework for clinical physicians and researchers to define precise RIs immediately in a convenient, privacy-preserving, and reproducible manner has been implemented, promoting a vital part of practicing precision medicine while streamlining compliance and avoiding transfers of raw patient data. This new approach can provide a crucial update on RIs and improve patient care for personalized medicine.
DO  - 10.2196/47254
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Ascertainment of Delirium Status Using Natural Language Processing From Electronic Health Records.
AU  - Sunyang Fu
AU  - Guilherme S Lopes
AU  - Sandeep R Pagali
AU  - Bjoerg Thorsteinsdottir
AU  - Nathan K LeBrasseur
AU  - Andrew Wen
AU  - Hongfang Liu
AU  - Walter A Rocca
AU  - Janet E Olson
AU  - Jennifer St Sauver
AU  - Sunghwan Sohn
SN  - 1758-535X
AB  - BACKGROUND: Delirium is underdiagnosed in clinical practice and is not routinely coded for billing. Manual chart review can be used to identify the occurrence of delirium; however, it is labor-intensive and impractical for large-scale studies. Natural language processing (NLP) has the capability to process raw text in electronic health records (EHRs) and determine the meaning of the information. We developed and validated NLP algorithms to automatically identify the occurrence of delirium from EHRs. METHODS: This study used a randomly selected cohort from the population-based Mayo Clinic Biobank (N = 300, age ≥65). We adopted the standardized evidence-based framework confusion assessment method (CAM) to develop and evaluate NLP algorithms to identify the occurrence of delirium using clinical notes in EHRs. Two NLP algorithms were developed based on CAM criteria: one based on the original CAM (NLP-CAM; delirium vs no delirium) and another based on our modified CAM (NLP-mCAM; definite, possible, and no delirium). The sensitivity, specificity, and accuracy were used for concordance in delirium status between NLP algorithms and manual chart review as the gold standard. The prevalence of delirium cases was examined using International Classification of Diseases, 9th Revision (ICD-9), NLP-CAM, and NLP-mCAM. RESULTS: NLP-CAM demonstrated a sensitivity, specificity, and accuracy of 0.919, 1.000, and 0.967, respectively. NLP-mCAM demonstrated sensitivity, specificity, and accuracy of 0.827, 0.913, and 0.827, respectively. The prevalence analysis of delirium showed that the NLP-CAM algorithm identified 12 651 (9.4%) delirium patients, the NLP-mCAM algorithm identified 20 611 (15.3%) definite delirium cases, and 10 762 (8.0%) possible cases. CONCLUSIONS: NLP algorithms based on the standardized evidence-based CAM framework demonstrated high performance in delineating delirium status in an expeditious and cost-effective manner.
DO  - 10.1093/gerona/glaa275
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Comparison of injury severity scores (ISS) obtained by manual coding versus "Two-step conversion" from ICD-9-CM.
AU  - Rebeca Abajas-Bustillo
AU  - Francisco José Amo-Setién
AU  - César Leal-Costa
AU  - María Del Carmen Ortego-Mate
AU  - María Seguí-Gómez
AU  - María Jesús Durá-Ros
AU  - Mark R Zonfrillo
SN  - 1932-6203
AB  - BACKGROUND: The International Classification of Diseases (ICD) is the standard diagnostic tool for classifying and coding diseases and injuries. The Abbreviated Injury Scale (AIS) is the most widely used injury severity scoring system. Although manual coding is considered the gold standard, it is sometimes unavailable or impractical. There have been many prior attempts to develop programs for the automated conversion of ICD rubrics into AIS codes. OBJECTIVE: To convert ICD, Ninth Revision, Clinical Modification (ICD-9-CM) codes into AIS 2005 (update 2008) codes via a derived map using a two-step process and, subsequently, to compare Injury Severity Score (ISS) resulting from said conversion with manually coded ISS values. METHODS: A cross-sectional retrospective study was designed in which medical records at the Hospital Universitario Marqués de Valdecilla of Cantabria (HUMV) and the Complejo Hospitalario of Navarra (CHN), both in Spain, were reviewed. Coding of injuries using AIS 2005 (update 2008) version was done manually by a certified AIS specialist and ISS values were calculated. ICD-9-CM codes were automatically converted into ISS values by another certified AIS specialist in a two-step process. ISS scores obtained from manual coding were compared to those obtained through this conversion process. RESULTS: The comparison of obtained through conversion versus manual ISS resulted in 396 concordant pairs (70.2%); the analysis of values according to ISS categories (ISS<9, ISS 9-15, ISS 16-24, ISS>24) showed 493 concordant pairs (87.4%). Regarding the criterion of "major trauma" patient (i.e., ISS> 15), 538 matching pairs (95.2%) were obtained. The conversion process resulted in underestimation of ISS in 112 cases (19.9%) and conversion was not possible in 136 cases (19%) for different reasons. CONCLUSIONS: The process used in this study has proven to be a useful tool for selecting patients who meet the ISS>15 criterion for "major trauma". Further research is needed to improve the conversion process.
DO  - 10.1371/journal.pone.0216206
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - CodeMapper: semiautomatic coding of case definitions. A contribution from the ADVANCE project.
AU  - Benedikt F H Becker
AU  - Paul Avillach
AU  - Silvana Romio
AU  - Erik M van Mulligen
AU  - Daniel Weibel
AU  - Miriam C J M Sturkenboom
AU  - Jan A Kors
SN  - 1099-1557
AB  - BACKGROUND: Assessment of drug and vaccine effects by combining information from different healthcare databases in the European Union requires extensive efforts in the harmonization of codes as different vocabularies are being used across countries. In this paper, we present a web application called CodeMapper, which assists in the mapping of case definitions to codes from different vocabularies, while keeping a transparent record of the complete mapping process. METHODS: CodeMapper builds upon coding vocabularies contained in the Metathesaurus of the Unified Medical Language System. The mapping approach consists of three phases. First, medical concepts are automatically identified in a free-text case definition. Second, the user revises the set of medical concepts by adding or removing concepts, or expanding them to related concepts that are more general or more specific. Finally, the selected concepts are projected to codes from the targeted coding vocabularies. We evaluated the application by comparing codes that were automatically generated from case definitions by applying CodeMapper's concept identification and successive concept expansion, with reference codes that were manually created in a previous epidemiological study. RESULTS: Automated concept identification alone had a sensitivity of 0.246 and positive predictive value (PPV) of 0.420 for reproducing the reference codes. Three successive steps of concept expansion increased sensitivity to 0.953 and PPV to 0.616. CONCLUSIONS: Automatic concept identification in the case definition alone was insufficient to reproduce the reference codes, but CodeMapper's operations for concept expansion provide an effective, efficient, and transparent way for reproducing the reference codes.
DO  - 10.1002/pds.4245
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Cardiology record multi-label classification using latent Dirichlet allocation.
AU  - Jorge Pérez
AU  - Alicia Pérez
AU  - Arantza Casillas
AU  - Koldo Gojenola
SN  - 1872-7565
AB  - BACKGROUND AND OBJECTIVES: Electronic health records (EHRs) convey vast and valuable knowledge about dynamically changing clinical practices. Indeed, clinical documentation entails the inspection of massive number of records across hospitals and hospital sections. The goal of this study is to provide an efficient framework that will help clinicians explore EHRs and attain alternative views related to both patient-segments and diseases, like clustering and statistical information about the development of heart diseases (replacement of pacemakers, valve implantation etc.) in co-occurrence with other diseases. The task is challenging, dealing with lengthy health records and a high number of classes in a multi-label setting. METHODS: LDA is a statistical procedure optimized to explain a document by multinomial distributions on their latent topics and the topics by distributions on related words. These distributions allow to represent collections of texts into a continuous space enabling distance-based associations between documents and also revealing the underlying topics. The topic models were assessed by means of four divergence metrics. In addition, we applied LDA to the task of multi-label document classification of EHRs according to the International Classification of Diseases 10th Clinical Modification (ICD-10). The set of EHRs had assigned 7 codes on average over 970 different codes corresponding to cardiology. RESULTS: First, the discriminative ability of topic models was assessed using dissimilarity metrics. Nevertheless, there was an open question regarding the interpretability of automatically discovered topics. To address this issue, we explored the connection between the latent topics and ICD-10. EHRs were represented by means of LDA and, next, supervised classifiers were inferred from those representations. Given the low-dimensional representation provided by LDA, the search was computationally efficient compared to symbolic approaches such as TF-IDF. The classifiers achieved an average AUC of 77.79. As a side contribution, with this work we released the software implemented in Python and R to both train and evaluate the models. CONCLUSIONS: Topic modeling offers a means of representing EHRs in a small dimensional continuous space. This representation conveys relevant information as hidden topics in a comprehensive manner. Moreover, in practice, this compact representation allowed to extract the ICD-10 codes associated to EHRs.
DO  - 10.1016/j.cmpb.2018.07.002
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Supervised Learning for the ICD-10 Coding of French Clinical Narratives.
AU  - Clément Dalloux
AU  - Vincent Claveau
AU  - Marc Cuggia
AU  - Guillaume Bouzillé
AU  - Natalia Grabar
SN  - 1879-8365
AB  - Automatic detection of ICD-10 codes in clinical documents has become a necessity. In this article, after a brief reminder of the existing work, we present a corpus of French clinical narratives annotated with the ICD-10 codes. Then, we propose automatic methods based on neural network approaches for the automatic detection of the ICD-10 codes. The results show that we need 1) more examples per class given the number of classes to assign, and 2) a better word/concept vector representation of documents in order to accurately assign codes.
DO  - 10.3233/SHTI200196
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Interpretable deep learning to map diagnostic texts to ICD-10 codes.
AU  - Aitziber Atutxa
AU  - Arantza Díaz de Ilarraza
AU  - Koldo Gojenola
AU  - Maite Oronoz
AU  - Olatz Perez-de-Viñaspre
SN  - 1872-8243
AB  - BACKGROUND: Automatic extraction of morbid disease or conditions contained in Death Certificates is a critical process, useful for billing, epidemiological studies and comparison across countries. The fact that these clinical documents are written in regular natural language makes the automatic coding process difficult because, often, spontaneous terms diverge strongly from standard reference terminology such as the International Classification of Diseases (ICD). OBJECTIVE: Our aim is to propose a general and multilingual approach to render Diagnostic Terms into the standard framework provided by the ICD. We have evaluated our proposal on a set of clinical texts written in French, Hungarian and Italian. METHODS: ICD-10 encoding is a multi-class classification problem with an extensive (thousands) number of classes. After considering several approaches, we tackle our objective as a sequence-to-sequence task. According to current trends, we opted to use neural networks. We tested different types of neural architectures on three datasets in which Diagnostic Terms (DTs) have their ICD-10 codes associated. RESULTS AND CONCLUSIONS: Our results give a new state-of-the art on multilingual ICD-10 coding, outperforming several alternative approaches, and showing the feasibility of automatic ICD-10 prediction obtaining an F-measure of 0.838, 0.963 and 0.952 for French, Hungarian and Italian, respectively. Additionally, the results are interpretable, providing experts with supporting evidence when confronted with coding decisions, as the model is able to show the alignments between the original text and each output code.
DO  - 10.1016/j.ijmedinf.2019.05.015
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Auto-mapping Clinical Documents to ICD-10 using SNOMED-CT.
AU  - Natthanaphop Isaradech
AU  - Piyapong Khumrin
SN  - 2153-4063
AB  - Excessive paperwork is a considerable issue that leads to additional burdens for health-care professionals. In Thai health-care systems, physicians manually review medical records to select an appropriate principle diagnosis and other co-morbidities and convert them into ICD-10s to claim financial support from the government. Accordingly, 160,000 ICD-10 codes and 46,000 in-patient discharge summaries are documented by physicians at Maharaj Nakorn Chiang Mai hospital each year. As a result, to decrease physicians' burden of manual paper-work, we created a new approach to automatically analyse discharge summary notes and map the diagnoses to ICD-10s. We combined SNOMED-CT and natural language processing techniques within the approach through 3 steps: cleaning data; extracting keywords from discharge summary notes; and matching keywords to ICD-10. In this paper, we present that mapping clinical documents by using approximate matching and SNOMED-CT shows potential to be used for automating the ICD-10 mapping process.
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automatic inference of ICD-10 codes from German ophthalmologic physicians' letters using natural language processing.
AU  - D Böhringer
AU  - P Angelova
AU  - L Fuhrmann
AU  - J Zimmermann
AU  - M Schargus
AU  - N Eter
AU  - T Reinhard
SN  - 2045-2322
AB  - Physicians' letters are the optimal source of diagnoses for registries. However, most registries demand for diagnosis codes such as ICD-10. We herein describe an algorithm that infers ICD-10 codes from German ophthalmologic physicians' letters. We assess the method in three German eye hospitals. Our algorithm is based on the nearest-neighbor method as well as on a large thesaurus for ICD-10 codes. This thesaurus was embedded into a Word2Vec space created from anonymized physicians' reports of the first hospital. For evaluation, each of the three hospitals sent all diagnoses taken from 100 letters. The inferred ICD-10 codes were evaluated for correctness by the senders. A total of 3332 natural language terms had been sent in (812 hospital one, 1473 hospital two, 1047 hospital three). A total of 526 non-diagnoses were excluded upfront. 2806 ICD-10 codes were inferred (771 hospital one, 1226 hospital two, 809 hospital three). In the first hospital, 98% were fully correct and 99% correct at the level of the superordinate disease concept. The percentages in hospital two were 69% and 86%. The respective numbers for hospital three were 69% and 91%. Our simple method is capable of inferring ICD-10 codes for German natural language diagnoses, especially when the embedding space has been built with physicians' letters from the same hospital. The method may yield sufficient accuracy for many tasks in the multi-centric setting and can easily be adapted to other languages/specialities.
DO  - 10.1038/s41598-024-59926-3
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - ICD code mapping model based on clinical text tree structure.
AU  - Jingjin Xue
AU  - Pengli Lu
SN  - 1873-2860
AB  - With the rapid development and progress of big data and artificial intelligence technology, the ICD coding problem of electronic medical records has been effectively solved. The deep learning method, which replaces the manual coding method, has improved the quality and efficiency of coding. However, it also faces some challenges, such as poor and fuzzy semantic representation of clinical record text and failure to consider the structural characteristics of clinical records. To address these problems, our study proposed an ICD Coding model (TRansformer and TRee-lstm for ICD Coding, TRIC), which enables adequate automatic ICD encoding of unstructured clinical records. In this model, the structure and features of clinical records are extracted by the constituency tree model and the transformer based model respectively, and the Tree-lstm model is used to enrich the features. Then bioBERT pre-training model is used to highlight the role of key ICD coding and improve its matching performance. Finally, it is classified by a fully connected neural network classifier to realize the many-to-many mapping between clinical records and ICD codes. On the widely used MIMIC-III full data set and sample data set, the TRIC model is compared with 12 benchmark models. The best results of 0.586, 0.109, 0.989, 0.937 and 0.758 were obtained for MiF, MaF, MiAUC, MaAUC and P@8, respectively, which verified that the TRIC model can effectively improve the quality of ICD automatic coding.
DO  - 10.1016/j.artmed.2025.103163
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automated classification of cancer morphology from Italian pathology reports using Natural Language Processing techniques: A rule-based approach.
AU  - Linda Hammami
AU  - Alessia Paglialonga
AU  - Giancarlo Pruneri
AU  - Michele Torresani
AU  - Milena Sant
AU  - Carlo Bono
AU  - Enrico Gianluca Caiani
AU  - Paolo Baili
SN  - 1532-0480
AB  - Pathology reports represent a primary source of information for cancer registries. Hospitals routinely process high volumes of free-text reports, a valuable source of information regarding cancer diagnosis for improving clinical care and supporting research. Information extraction and coding of textual unstructured data is typically a manual, labour-intensive process. There is a need to develop automated approaches to extract meaningful information from such texts in a reliable and accurate way. In this scenario, Natural Language Processing (NLP) algorithms offer a unique opportunity to automatically encode the unstructured reports into structured data, thus representing a potential powerful alternative to expensive manual processing. However, notwithstanding the increasing interest in this area, there is still limited availability of NLP approaches for pathology reports in languages other than English, including Italian, to date. The aim of our work was to develop an automated algorithm based on NLP techniques, able to identify and classify the morphological content of pathology reports in the Italian language with micro-averaged performance scores higher than 95%. Specifically, a novel, domain-specific classifier that uses linguistic rules was developed and tested on 27,239 pathology reports from a single Italian oncological centre, following the International Classification of Diseases for Oncology morphology classification standard (ICD-O-M). The proposed classification algorithm achieved successful results with a micro-F
DO  - 10.1016/j.jbi.2021.103712
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Methods for Ensuring High Quality of Coding of Cause of Death. The Mortality Register to Follow Southern Urals Populations Exposed to Radiation.
AU  - N Startsev
AU  - P Dimov
AU  - B Grosche
AU  - F Tretyakov
AU  - J Schüz
AU  - A Akleyev
SN  - 2511-705X
AB  - BACKGROUND: To follow up populations exposed to several radiation accidents in the Southern Urals, a cause-of-death registry was established at the Urals Center capturing deaths in the Chelyabinsk, Kurgan and Sverdlovsk region since 1950. OBJECTIVES: When registering deaths over such a long time period, quality measures need to be in place to maintain quality and reduce the impact of individual coders as well as quality changes in death certificates. METHODS: To ensure the uniformity of coding, a method for semi-automatic coding was developed, which is described here. Briefly, the method is based on a dynamic thesaurus, database-supported coding and parallel coding by two different individuals. RESULTS: A comparison of the proposed method for organizing the coding process with the common procedure of coding showed good agreement, with, at the end of the coding process, 70  - 90% agreement for the three-digit ICD -9 rubrics. CONCLUSIONS: The semi-automatic method ensures a sufficiently high quality of coding by at the same time providing an opportunity to reduce the labor intensity inherent in the creation of large-volume cause-of-death registries.
DO  - 10.3414/ME14-01-0101
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - How to leverage large language models for automatic ICD coding.
AU  - Youngju Yoo
AU  - Sewon Kim
SN  - 1879-0534
AB  - ICD coding, which involves assigning appropriate ICD codes to clinical notes, is essential for healthcare tasks such as health expense claims, insurance claims, and disease research. Manual ICD coding is time-consuming and prone to errors, increasing the need for automation. However, clinical notes often contain non-grammatical expressions, abbreviations, professional terms, and synonyms, making them notably noisy compared to general documents. Additionally, ICD coding faces challenges such as a broad label space and the long-tail problem, making automatic ICD coding highly challenging. Large Language Models (LLMs) have shown great potential in code extraction tasks due to their exceptional natural language understanding and information extraction capabilities. However, the unique characteristics of clinical records and ICD codes necessitate fine-tuning LLMs for optimal performance in ICD coding. In this study, we propose a novel fine-tuning framework for LLMs aimed at automatic ICD coding. Our framework introduces additional elements, including a label attention mechanism, note-relevant knowledge injection based on medical expressions, and knowledge-driven sampling to address the input token limitations of LLMs. Experiments on the MIMIC-III-50 dataset show that our framework outperforms vanilla fine-tuning in both micro and macro accuracy and F1 scores, with particularly significant improvements observed in encoder-decoder models.
DO  - 10.1016/j.compbiomed.2025.109971
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - [Comparison of ICD coding between mortality statistics and study-intern retrospective re-coding].
AU  - S J Klug
AU  - D Bardehle
AU  - M Ressing
AU  - I Schmidtmann
AU  - M Blettner
SN  - 1439-4421
AB  - OBJECTIVES: The aim of this study was to assess agreement between study-intern nosologist death certificate coding and official mortality statistics ICD codes. METHODS: During the follow-up of a historical cohort study conducted in Germany, original death certificates were obtained for deceased cohort members and ICD coded by a study-intern nosologist. Additionally, ICD codes for these study subjects were obtained from a state statistical office responsible for mortality statistics. A weighted inter-observer agreement for these two sources was calculated. RESULTS: In total, 406 ICD codes were available from both sources. 219 (53.9%) of these ICD codes completely agreed on the highest level possible (three- or four-digits). Agreement was found on the three-digit level with a difference at the fourth digit in 42 (10.3%) causes of death. Agreement within diagnosis groups or within chapters of disease was found in 21 (5.2%) and 49 (12.1%) causes of death, respectively. The weighted kappa for the overall inter-observer agreement was 0.67 [95% confidence interval (CI): 0.63-0.71]. Within chapters of disease, agreement was higher for neoplasms (kappa=0.88; 95% CI: 0.83-0.93) than for cardiovascular diseases (kappa=0.69; CI: 0.62-0.76). CONCLUSIONS: Overall level of agreement between the two coding sources was not very good. In Germany, the quality of coding has not improved substantially in the past two decades. The introduction of automatic coding systems, multicausal coding and a mortality register could improve the quality of ICD coding in Germany.
DO  - 10.1055/s-0028-1102929
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - [Exploratory development of automated coding software on the underlying causes of death].
AU  - Yi-bing Ji
AU  - Li-jun Wang
AU  - Mai-geng Zhou
SN  - 0254-6450
AB  - To develop an automated coding software related to the underlying causes of death, based on the National Registration Information System on deaths, which could improve the quality of coding on the underlying causes of death in the conventional death surveillance system. Following the coding rules of the underlying death cause of ICD-10 and the design on principles of software of underlying death cause automated coding from some other countries, as well as in accordance with the coding strategy table from the USA, we implemented the automatization of the underlying death cause coding. Based on national registration information system on cause of death, an automated coding software of underlying death cause was developed with the coding correction rate closed to 85%. The automated coding software of underlying death cause could code the death cases of underlying death cause with high rate of correction, similar to that of the same kind software developed in other countries.
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Monitoring and Prognosis System Based on the ICF for People with Traumatic Brain Injury.
AU  - Laia Subirats
AU  - Raquel Lopez-Blazquez
AU  - Luigi Ceccaroni
AU  - Mariona Gifre
AU  - Felip Miralles
AU  - Alejandro García-Rudolph
AU  - Jose María Tormos
SN  - 1660-4601
AB  - The objective of this research is to provide a standardized platform to monitor and predict indicators of people with traumatic brain injury using the International Classification of Functioning, Disability and Health, and analyze its potential benefits for people with disabilities, health centers and administrations. We developed a platform that allows automatic standardization and automatic graphical representations of indicators of the status of individuals and populations. We used data from 730 people with acquired brain injury performing periodic comprehensive evaluations in the years 2006-2013. Health professionals noted that the use of color-coded graphical representation is useful for quickly diagnose failures, limitations or restrictions in rehabilitation. The prognosis system achieves 41% of accuracy and sensitivity in the prediction of emotional functions, and 48% of accuracy and sensitivity in the prediction of executive functions. This monitoring and prognosis system has the potential to: (1) save costs and time, (2) provide more information to make decisions, (3) promote interoperability, (4) facilitate joint decision-making, and (5) improve policies of socioeconomic evaluation of the burden of disease. Professionals found the monitoring system useful because it generates a more comprehensive understanding of health oriented to the profile of the patients, instead of their diseases and injuries.
DO  - 10.3390/ijerph120809832
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Medical code prediction via capsule networks and ICD knowledge.
AU  - Weidong Bao
AU  - Hongfei Lin
AU  - Yijia Zhang
AU  - Jian Wang
AU  - Shaowu Zhang
SN  - 1472-6947
AB  - BACKGROUND: Clinical notes record the health status, clinical manifestations and other detailed information of each patient. The International Classification of Diseases (ICD) codes are important labels for electronic health records. Automatic medical codes assignment to clinical notes through the deep learning model can not only improve work efficiency and accelerate the development of medical informatization but also facilitate the resolution of many issues related to medical insurance. Recently, neural network-based methods have been proposed for the automatic medical code assignment. However, in the medical field, clinical notes are usually long documents and contain many complex sentences, most of the current methods cannot effective in learning the representation of potential features from document text. METHODS: In this paper, we propose a hybrid capsule network model. Specifically, we use bi-directional LSTM (Bi-LSTM) with forwarding and backward directions to merge the information from both sides of the sequence. The label embedding framework embeds the text and labels together to leverage the label information. We then use a dynamic routing algorithm in the capsule network to extract valuable features for medical code prediction task. RESULTS: We applied our model to the task of automatic medical codes assignment to clinical notes and conducted a series of experiments based on MIMIC-III data. The experimental results show that our method achieves a micro F1-score of 67.5% on MIMIC-III dataset, which outperforms the other state-of-the-art methods. CONCLUSIONS: The proposed model employed the dynamic routing algorithm and label embedding framework can effectively capture the important features across sentences. Both Capsule networks and domain knowledge are helpful for medical code prediction task.
DO  - 10.1186/s12911-021-01426-9
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Knowledge Injected Prompt Based Fine-tuning for Multi-label Few-shot ICD Coding.
AU  - Zhichao Yang
AU  - Shufan Wang
AU  - Bhanu Pratap Singh Rawat
AU  - Avijit Mitra
AU  - Hong Yu
AB  - Automatic International Classification of Diseases (ICD) coding aims to assign multiple ICD codes to a medical note with average length of 3,000+ tokens. This task is challenging due to a high-dimensional space of multi-label assignment (tens of thousands of ICD codes) and the long-tail challenge: only a few codes (common diseases) are frequently assigned while most codes (rare diseases) are infrequently assigned. This study addresses the long-tail challenge by adapting a prompt-based fine-tuning technique with label semantics, which has been shown to be effective under few-shot setting. To further enhance the performance in medical domain, we propose a knowledge-enhanced longformer by injecting three domain-specific knowledge: hierarchy, synonym, and abbreviation with additional pretraining using contrastive learning. Experiments on MIMIC-III-full, a benchmark dataset of code assignment, show that our proposed method outperforms previous state-of-the-art method in 14.5% in marco F1 (from 10.3 to 11.8, P<0.001). To further test our model on few-shot setting, we created a new rare diseases coding dataset, MIMIC-III-rare50, on which our model improves marco F1 from 17.1 to 30.4 and micro F1 from 17.2 to 32.6 compared to previous method.
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - LCDL: Classification of ICD codes based on disease label co-occurrence dependency and LongFormer with medical knowledge.
AU  - Yumeng Yang
AU  - Hongfei Lin
AU  - Zhihao Yang
AU  - Yijia Zhang
AU  - Di Zhao
AU  - Ling Luo
SN  - 1873-2860
AB  - Medical coding involves assigning codes to clinical free-text documents, specifically medical records that average over 3,000 markers, in order to track patient diagnoses and treatments. This is typically accomplished through manual assignments by healthcare professionals. To improve efficiency and accuracy while reducing the workload on these professionals, researchers have employed a multi-label classification approach. Since the long-tail phenomenon impacts tens of thousands of ICD codes, whereby only a few codes (representative of common diseases) are frequently assigned, while the majority of codes (representative of rare diseases) are infrequently assigned, this paper presents an LCDL model that addresses the challenge at hand by examining the LongFormer pre-trained language model and the disease label co-occurrence map. To enhance the performance of automated medical coding in the biomedical domain, hierarchies with medical knowledge, synonyms and abbreviations are introduced, improving the medical knowledge representation. Test evaluations are extensively conducted on the benchmark dataset MIMIC-III, and obtained the competitive performance compared to the previous state-of-the-art methods.
DO  - 10.1016/j.artmed.2024.103041
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - [Implementation of an automatic alarms system for early detection of patients with severe sepsis].
AU  - José María Ferreras
AU  - Diego Judez
AU  - Gabriel Tirado
AU  - Carmen Aspiroz
AU  - Rosa Martínez-Álvarez
AU  - Paloma Dorado
AU  - Ana Ezpeleta
AU  - Rafael Marrón
AU  - Begoña Gargallo
AU  - Clara Herranz
SN  - 1578-1852
AB  - OBJECTIVE: The objective of this study was to assess the usefulness of a software tool integrated into the medical electronic history at the time of emergency triage. The aim was the early detection of patients with severe sepsis, and the potential impact of this software tool on reducing the mortality rate in patients treated. METHOD: The study consisted of two comparative samples. Patient selection was performed retrospectively into two groups using ICD-9 codes from the hospital and emergency department discharge reports. The codes were 038.9, 995.9 and 995.92 for sepsis, and 785.52 for severe sepsis and septic shock. The sample called «alarms» consisted of patients studied after implementing the sepsis alarm system in the Emergency Department computer system. There were two types of alarms, a serious one and an alert one depending on the on vital signs defined. The historical sample called «no alarms» consisted of patients seen in the Emergency Department during the year before the introduction of the alarm system. RESULTS: The compliance rate of the sepsis treatment package was higher in the «alarms» sample, compared to the sample without alarms, with blood cultures, 96.3% versus 80.9% (P<.001), antibiotic treatment in less than one hour, 62.9% vs. 39.3% (P<.001), determination of lactic acid, 91.4% vs. 77.9% (P<.001), and applying appropriate volume, 57.7% vs 54.3% (P=.052), respectively. The hospital mortality was reduced in absolute terms from 25% in the sample without alarms to 13.6% in the sample with alarms. Survival at 30 days was higher in the sample with alarms (Log Rank=.004). CONCLUSIONS: There were no studies that evaluated the effectiveness of an alarm system in our literature search. An electronic identification system for patients with sepsis allows acting earlier, better compliance with basic measures, and a reduction in hospital stay and mortality.
DO  - 10.1016/j.eimc.2015.01.002
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - A keyphrase-based approach for interpretable ICD-10 code classification of Spanish medical reports.
AU  - Andres Duque
AU  - Hermenegildo Fabregat
AU  - Lourdes Araujo
AU  - Juan Martinez-Romo
SN  - 1873-2860
AB  - BACKGROUND AND OBJECTIVES: The 10th version of International Classification of Diseases (ICD-10) codification system has been widely adopted by the health systems of many countries, including Spain. However, manual code assignment of Electronic Health Records (EHR) is a complex and time-consuming task that requires a great amount of specialised human resources. Therefore, several machine learning approaches are being proposed to assist in the assignment task. In this work we present an alternative system for automatically recommending ICD-10 codes to be assigned to EHRs. METHODS: Our proposal is based on characterising ICD-10 codes by a set of keyphrases that represent them. These keyphrases do not only include those that have literally appeared in some EHR with the considered ICD-10 codes assigned, but also others that have been obtained by a statistical process able to capture expressions that have led the annotators to assign the code. RESULTS: The result is an information model that allows to efficiently recommend codes to a new EHR based on their textual content. We explore an approach that proves to be competitive with other state-of-the-art approaches and can be combined with them to optimise results. CONCLUSIONS: In addition to its effectiveness, the recommendations of this method are easily interpretable since the phrases in an EHR leading to recommend an ICD-10 code are known. Moreover, the keyphrases associated with each ICD-10 code can be a valuable additional source of information for other approaches, such as machine learning techniques.
DO  - 10.1016/j.artmed.2021.102177
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Mining peripheral arterial disease cases from narrative clinical notes using natural language processing.
AU  - Naveed Afzal
AU  - Sunghwan Sohn
AU  - Sara Abram
AU  - Christopher G Scott
AU  - Rajeev Chaudhry
AU  - Hongfang Liu
AU  - Iftikhar J Kullo
AU  - Adelaide M Arruda-Olson
SN  - 1097-6809
AB  - OBJECTIVE: Lower extremity peripheral arterial disease (PAD) is highly prevalent and affects millions of individuals worldwide. We developed a natural language processing (NLP) system for automated ascertainment of PAD cases from clinical narrative notes and compared the performance of the NLP algorithm with billing code algorithms, using ankle-brachial index test results as the gold standard. METHODS: We compared the performance of the NLP algorithm to (1) results of gold standard ankle-brachial index; (2) previously validated algorithms based on relevant International Classification of Diseases, Ninth Revision diagnostic codes (simple model); and (3) a combination of International Classification of Diseases, Ninth Revision codes with procedural codes (full model). A dataset of 1569 patients with PAD and controls was randomly divided into training (n = 935) and testing (n = 634) subsets. RESULTS: We iteratively refined the NLP algorithm in the training set including narrative note sections, note types, and service types, to maximize its accuracy. In the testing dataset, when compared with both simple and full models, the NLP algorithm had better accuracy (NLP, 91.8%; full model, 81.8%; simple model, 83%; P < .001), positive predictive value (NLP, 92.9%; full model, 74.3%; simple model, 79.9%; P < .001), and specificity (NLP, 92.5%; full model, 64.2%; simple model, 75.9%; P < .001). CONCLUSIONS: A knowledge-driven NLP algorithm for automatic ascertainment of PAD cases from clinical notes had greater accuracy than billing code algorithms. Our findings highlight the potential of NLP tools for rapid and efficient ascertainment of PAD cases from electronic health records to facilitate clinical investigation and eventually improve care by clinical decision support.
DO  - 10.1016/j.jvs.2016.11.031
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Dione: An OWL representation of ICD-10-CM for classifying patients' diseases.
AU  - María Del Mar Roldán-García
AU  - María Jesús García-Godoy
AU  - José F Aldana-Montes
SN  - 2041-1480
AB  - BACKGROUND: Systematized Nomenclature of Medicine - Clinical Terms (SNOMED CT) has been designed as standard clinical terminology for annotating Electronic Health Records (EHRs). EHRs textual information is used to classify patients' diseases into an International Classification of Diseases, Tenth Revision, Clinical Modification (ICD-10-CM) category (usually by an expert). Improving the accuracy of classification is the main purpose of using ontologies and OWL representations at the core of classification systems. In the last few years some ontologies and OWL representations for representing ICD-10-CM categories have been developed. However, they were not designed to be the basis for an automatic classification tool nor do they model ICD-10-CM inclusion terms as Web Ontology Language (OWL) axioms, which enables automatic classification. In this context we have developed Dione, an OWL representation of ICD-10-CM. RESULTS: Dione is the first OWL representation of ICD-10-CM, which is logically consistent, whose axioms define the ICD-10-CM inclusion terms by means of a methodology based on SNOMED CT/ICD-10-CM mappings. The ICD-10-CM exclusions are handled with these mappings. Dione currently contains 391,669 classes, 391,720 entity annotation axioms and 11,795 owl:equivalentClass axioms which have been constructed using 104,646 relationships extracted from the SNOMED CT/ICD-10-CM and BioPortal mappings included in Dione using the owl:intersectionOf and the owl:someValuesFrom statements. The resulting OWL representation has been classified and its consistency tested with the ELK reasoner. We have also taken three clinical records from the Virgen de la Victoria Hospital (Málaga, Spain) which have been manually annotated using SNOMED CT. These annotations have been included as instances to be classified by the reasoner. The classified instances show that Dione could be a promising ICD-10-CM OWL representation to support the classification of patients' diseases. CONCLUSIONS: Dione is a first step towards the automatic classification of patients' diseases by using SNOMED CT annotations embedded in Electronic Health Records (EHRs). The purpose of Dione is to standardise and formalise a medical terminology, thereby enabling new kinds of tools and new sets of functionalities to be developed. This in turn assists health specialists by providing classified information from EHRs and enables the automatic annotation of patients' diseases with ICD-10-CM codes.
DO  - 10.1186/s13326-016-0105-x
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - High-throughput multimodal automated phenotyping (MAP) with application to PheWAS.
AU  - Katherine P Liao
AU  - Jiehuan Sun
AU  - Tianrun A Cai
AU  - Nicholas Link
AU  - Chuan Hong
AU  - Jie Huang
AU  - Jennifer E Huffman
AU  - Jessica Gronsbell
AU  - Yichi Zhang
AU  - Yuk-Lam Ho
AU  - Victor Castro
AU  - Vivian Gainer
AU  - Shawn N Murphy
AU  - Christopher J O'Donnell
AU  - J Michael Gaziano
AU  - Kelly Cho
AU  - Peter Szolovits
AU  - Isaac S Kohane
AU  - Sheng Yu
AU  - Tianxi Cai
SN  - 1527-974X
AB  - OBJECTIVE: Electronic health records linked with biorepositories are a powerful platform for translational studies. A major bottleneck exists in the ability to phenotype patients accurately and efficiently. The objective of this study was to develop an automated high-throughput phenotyping method integrating International Classification of Diseases (ICD) codes and narrative data extracted using natural language processing (NLP). MATERIALS AND METHODS: We developed a mapping method for automatically identifying relevant ICD and NLP concepts for a specific phenotype leveraging the Unified Medical Language System. Along with health care utilization, aggregated ICD and NLP counts were jointly analyzed by fitting an ensemble of latent mixture models. The multimodal automated phenotyping (MAP) algorithm yields a predicted probability of phenotype for each patient and a threshold for classifying participants with phenotype yes/no. The algorithm was validated using labeled data for 16 phenotypes from a biorepository and further tested in an independent cohort phenome-wide association studies (PheWAS) for 2 single nucleotide polymorphisms with known associations. RESULTS: The MAP algorithm achieved higher or similar AUC and F-scores compared to the ICD code across all 16 phenotypes. The features assembled via the automated approach had comparable accuracy to those assembled via manual curation (AUCMAP 0.943, AUCmanual 0.941). The PheWAS results suggest that the MAP approach detected previously validated associations with higher power when compared to the standard PheWAS method based on ICD codes. CONCLUSION: The MAP approach increased the accuracy of phenotype definition while maintaining scalability, thereby facilitating use in studies requiring large-scale phenotyping, such as PheWAS.
DO  - 10.1093/jamia/ocz066
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Neural transfer learning for assigning diagnosis codes to EMRs.
AU  - Anthony Rios
AU  - Ramakanth Kavuluru
SN  - 1873-2860
AB  - OBJECTIVE: Electronic medical records (EMRs) are manually annotated by healthcare professionals and specialized medical coders with a standardized set of alphanumeric diagnosis and procedure codes, specifically from the International Classification of Diseases (ICD). Annotating EMRs with ICD codes is important for medical billing and downstream epidemiological studies. However, manually annotating EMRs is both time-consuming and error prone. In this paper, we explore the use of convolutional neural networks (CNNs) for automatic ICD coding. Because many codes occur infrequently, CNN performance is inhibited. Therefore, we propose supplementing EMR data with PubMed indexed biomedical research abstracts through neural transfer learning. MATERIALS AND METHODS: Transfer learning is the process of "transferring" knowledge acquired from one task (the source task) to a different (target) task. For the source task, we train a CNN to predict medical subject headings (MeSH) using 1.6 million PubMed indexed biomedical abstracts. For the target task, we train a CNN on 71,463 real-world EMRs collected from the University of Kentucky (UKY) medical center to predict ICD diagnosis codes. We introduce a simple, yet effective, transfer learning methodology which avoids forgetting knowledge gained from the source task. RESULTS: Compared to our prior work using EMRs from the UKY medical center, we improve both the micro and macro F-scores by more than 8%. Likewise, compared to other transfer learning methods, our approach results in nearly 2% improvement in macro F-score. CONCLUSION: We show that transfer learning can improve CNN performance for EMR coding in the presence of data sparsity issues. Furthermore, we find that our proposed transfer learning approach outperforms other methods with respect to macro F-score. Finally, we analyze how transfer learning impacts codes with respect to code frequency. We find that we achieve greater improvement on infrequent codes compared to improvements in most frequent codes.
DO  - 10.1016/j.artmed.2019.04.002
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Analysis of risk factors of mortality in rheumatoid arthritis patients with interstitial lung disease: a nationwide, population-based cohort study in Taiwan.
AU  - Kooi-Heng Ng
AU  - Der-Yuan Chen
AU  - Ching-Heng Lin
AU  - Wen-Cheng Chao
AU  - Hsin-Hua Chen
SN  - 2056-5933
AB  - OBJECTIVE: To examine the risk and risk factors of mortality in patients with rheumatoid arthritis (RA) with interstitial lung disease (ILD). METHODS: Using the 1997-2013 Taiwanese National Health Insurance Research Database, we identified 32 289 incident patients with RA by using International Classification of Diseases, Ninth Revision codes from 2001 to 2013, and 214 patients developed ILD subsequently. We matched (1:10) RA-ILD with controls for sex, age, time of ILD diagnosis and disease duration. In addition, we conducted propensity score matching (PSM) (1:1) for selected comorbidities to choose RA-ILD patients and controls. Using the Cox proportional hazard model, we estimated the association of mortality with ILD for the two matched populations and assessed factors associated with mortality among 214 RA-ILD patients, shown as adjusted HRs (aHRs) with 95% CIs. RESULTS: In the populations selected before and after PSM, we included 164 and 155 patients with RA-ILD and 1640 and 155 controls, respectively. ILD was associated with mortality in the population before PSM (aHR, 1.73; 95% CI 1.19 to 2.52) and in the PSM population (HR 4.38; 95% CI 2.03 to 9.43). Among 214 patients with RA-ILD, age (aHR 1.04; 95% CI 1.03 to 1.08), chronic obstructive pulmonary disease (COPD) (aHR 2.12; 95% CI 1.25 to 3.58), diabetes mellitus (DM) with end-organ damage and corticosteroid dose (prednisolone equivalent, mg/day) (aHR 1.09; 95% CI 1.07 to 1.11) were associated with mortality in RA-ILD. CONCLUSION: This population-based cohort study showed that ILD was associated with risk of mortality in patients with RA, and risk factors associated with mortality in patients with RA-ILD included age, COPD, DM with end-organ damage and average daily prednisolone dose.
DO  - 10.1136/rmdopen-2022-002343
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Development of a database of health insurance claims: standardization of disease classifications and anonymous record linkage.
AU  - Shinya Kimura
AU  - Toshihiko Sato
AU  - Shunya Ikeda
AU  - Mitsuhiko Noda
AU  - Takeo Nakayama
SN  - 1349-9092
AB  - BACKGROUND: Health insurance claims (ie, receipts) record patient health care treatments and expenses and, although created for the health care payment system, are potentially useful for research. Combining different types of receipts generated for the same patient would dramatically increase the utility of these receipts. However, technical problems, including standardization of disease names and classifications, and anonymous linkage of individual receipts, must be addressed. METHODS: In collaboration with health insurance societies, all information from receipts (inpatient, outpatient, and pharmacy) was collected. To standardize disease names and classifications, we developed a computer-aided post-entry standardization method using a disease name dictionary based on International Classification of Diseases (ICD)-10 classifications. We also developed an anonymous linkage system by using an encryption code generated from a combination of hash values and stream ciphers. Using different sets of the original data (data set 1: insurance certificate number, name, and sex; data set 2: insurance certificate number, date of birth, and relationship status), we compared the percentage of successful record matches obtained by using data set 1 to generate key codes with the percentage obtained when both data sets were used. RESULTS: The dictionary's automatic conversion of disease names successfully standardized 98.1% of approximately 2 million new receipts entered into the database. The percentage of anonymous matches was higher for the combined data sets (98.0%) than for data set 1 (88.5%). CONCLUSIONS: The use of standardized disease classifications and anonymous record linkage substantially contributed to the construction of a large, chronologically organized database of receipts. This database is expected to aid in epidemiologic and health services research using receipt information.
DO  - 10.2188/jea.je20090066
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automated identification and quality measurement for pediatric convulsive status epilepticus.
AU  - David L Hess-Homeier
AU  - Karishma Parikh
AU  - Natasha Basma
AU  - Adam E Vella
AU  - Zachary M Grinspan
SN  - 1528-1167
AB  - OBJECTIVE: Treatment delays for refractory convulsive status epilepticus (RCSE) are associated with worse outcomes. In the United States, treatment for pediatric RCSE is slower than guidelines recommend. To address this gap, the American Academy of Neurology and Child Neurology Society (AAN/CNS) developed a quality measure: the percentage of RCSE patients that receive third-line treatment within 60 minutes. We aimed to develop computable phenotypes for convulsive status epilepticus (CSE) and RCSE to automate calculation of the quality measure. METHODS: From an observational cohort of children presenting to the emergency department for seizures or epilepsy, we identified presentations of RCSE and its precursors: CSE and benzodiazepine-resistant status epilepticus (BRSE). These served as a gold standard for computable phenotype development. Using multivariate analyses, we constructed and evaluated statistical models for case identification. We then evaluated adherence to the AAN/CNS RCSE quality measure. RESULTS: From 664 charts, we identified 56 patients with CSE, 36 with BRSE, and 18 with RCSE. Four predictors were used: International Classification of Diseases (ICD) codes, and receiving first-, second-, or third-line agents shortly after presentation to the emergency department (ED). Combinations of these predictors identified CSE with 84% sensitivity and 81% positive predictive value (PPV), BRSE with 67% sensitivity and 89% PPV, and RCSE with 94% sensitivity and 85% PPV. Median (interquartile range [IQR]) time to treatment for first-line agent was 13 (5-27) minutes for CSE, second-line for BRSE was 24 (9.5-43.5) minutes, and third-line for RCSE was 52 (27-87) minutes. Sixty percent of RCSE patients received a third-line agent within 60 minutes of ED arrival. SIGNIFICANCE: RCSE and its precursors can be identified automatically with high fidelity allowing automated calculation of time to treatment and the RCSE quality measure. This has the potential to facilitate quality improvement work and improve care for RCSE.
DO  - 10.1111/epi.16795
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - OphthaBERT: Automated Glaucoma Diagnosis from Clinical Notes.
AU  - Rishi Shah
AU  - Mousa Moradi
AU  - Sedigheh Eslami
AU  - Asahi Fujita
AU  - Kanza Aziz
AU  - Niloufar Bineshfar
AU  - Tobias Elze
AU  - Mohammad Eslami
AU  - Saber Kazeminasab
AU  - Daniel Liebman
AU  - Saeid Rasouli
AU  - Daniel Vu
AU  - Mengyu Wang
AU  - Jithin Yohannan
AU  - Nazlee Zebardast
AB  - Glaucoma is a leading cause of irreversible blindness worldwide, with early intervention often being crucial. Research into the underpinnings of glaucoma often relies on electronic health records (EHRs) to identify patients with glaucoma and their subtypes. However, current methods for identifying glaucoma patients from EHRs are often inaccurate or infeasible at scale, relying on International Classification of Diseases (ICD) codes or manual chart reviews. To address this limitation, we introduce (1) OphthaBERT, a powerful general clinical ophthalmology language model trained on over 2 million diverse clinical notes, and (2) a fine-tuned variant of OphthaBERT that automatically extracts binary and subtype glaucoma diagnoses from clinical notes. The base OphthaBERT model is a robust encoder, outperforming state-of-the-art clinical encoders in masked token prediction on out-of-distribution ophthalmology clinical notes and binary glaucoma classification with limited data. We report significant binary classification performance improvements in low-data regimes (p < 0.001, Bonferroni corrected). OphthaBERT is also able to achieve superior classification performance for both binary and subtype diagnosis, outperforming even fine-tuned large decoder-only language models at a fraction of the computational cost. We demonstrate a 0.23-point increase in macro-F1 for subtype diagnosis over ICD codes and strong binary classification performance when externally validated at Wilmer Eye Institute. OphthaBERT provides an interpretable, equitable framework for general ophthalmology language modeling and automated glaucoma diagnosis.
DO  - 10.1101/2025.06.08.25329151
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Construction of a semi-automated ICD-10 coding help system to optimize medical and economic coding.
AU  - Suzanne Pereira
AU  - Aurélie Névéol
AU  - Philippe Massari
AU  - Michel Joubert
AU  - Stefan Darmoni
SN  - 0926-9630
AB  - INTRODUCTION: In order to measure the medical activity in hospitals, physicians are required to code manually information concerning a patient's stay using ICD-10. This requires trained staff and a lot of time. We propose to help speed up and facilitate the tedious task of coding patient information. METHODS: we show two methods. First, we propose an automated ICD-10-based coding help system using an automated MeSH-based indexing system and a mapping between MeSH and ICD-10 extracted from the UMLS metathesaurus. Secondly, we propose the use of drug prescriptions to complete the previous coding with the use of a mapping between a given prescription drug and the relevant ICD-10 codes (in compliance with the drug approval). RESULTS: the results of a preliminary experiment indicate that the precision of the indexing system is 40% and the recall is 30% when we compare to an economic rules-based coding and to a descriptive coding. DISCUSSION: moreover, we show that the use of prescription coding is relevant as the recall reaches 68% when the Vidal tool is used. CONCLUSION: Then, it is very interesting to complete the coding obtained automatically by the indexing/mapping system by the coding obtained from the prescriptions.
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Developing and Validating an Automatic Support System for Tumor Coding in Pathology Reports in Spanish.
AU  - Fabián Villena
AU  - Pablo Báez
AU  - Sergio Peñafiel
AU  - Matías Rojas
AU  - Inti Paredes
AU  - Jocelyn Dunstan
SN  - 2473-4276
AB  - PURPOSE: Pathology reports provide valuable information for cancer registries to understand, plan, and implement strategies to mitigate the impact of cancer. However, coding essential information from unstructured reports is performed by experts in a time-consuming manual process. We developed and validated a novel two-step automatic coding system that first recognizes tumor morphology and topography mentions from free text and then suggests codes from the International Classification of Diseases for Oncology (ICD-O) in Spanish. MATERIALS AND METHODS: We created an annotated corpus of tumor morphology and topography mentions consisting of 1,101 documents. We combined it with the CANTEMIST corpus (Cancer Text Mining Shared Task). Specifically, we implemented a named entity recognition (NER) model using the bidirectional long short-term memory network-conditional random field architecture enhanced with a stacked embedding layer. We applied transfer learning from state-of-the-art pretrained language models to obtain high-quality contextual representations, thus improving the detection of entities. The mentions found using this model were subsequently coded using a search engine tailored to the ICD-O codes. RESULTS: Our NER models achieved an F1 score of 0.86 and 0.90 for tumor morphology and topography, respectively. The overall performance of our automatic coding system achieved an accuracy at five suggestions of 0.72 and 0.65 for tumor morphology and topography, respectively. CONCLUSION: These results demonstrate the feasibility of implementing natural language processing tools in the routine of a cancer center to extract and code valuable information from pathology reports. Our recommender system allows reliable and transparent coding at the moment of consultation. This publication shares the annotated corpus in Spanish, annotation guidelines, and source code to reproduce our experiments.
DO  - 10.1200/CCI.24.00124
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - [Death certificate data in France: Production process and main types of analyses].
AU  - G Rey
SN  - 1768-3122
AB  - Mortality data, by the unambiguity of their definition and understanding by all stakeholders, and completeness of registration, are a cornerstone of public health statistics in France and in most industrialized countries. This article describes the data production process, and the main types of possible analyses. Data production is composed of different stages: death certification by a medical doctor on paper or electronic (using a web application) format, data transmission to Inserm, capture and coding of information. The encoding of the information follows the WHO recommendations of the International Classification of Diseases ([ICD], 10th revision used since 2000). It is carried out using an automatic coding software, called Iris, developed in an international consortium. The coding aims, first, at assigning an ICD code to all nosologic entities encountered on the certificate, and then at selecting the underlying cause of death. The latter is the main information used for statistical analyses. Three main types of analysis emerge in the literature: the exploitation of data on the death certificate only, ecological analyses (studies of associations between variables measured across groups) and analysis from data individually linked to other databases. Many public health issues can be addressed with these various analyses. Several developments in the production process are being implemented: the deployment of electronic certification, increased automation of the death certificate information processing and durable and complete record linkage with health insurance and hospitalisation data. They could soon be deeply expanding the scope of possible uses of causes of death data.
DO  - 10.1016/j.revmed.2016.01.011
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Leveraging Clinical Informatics Tools to Extract Cumulative Anthracycline Exposure, Measure Cardiovascular Outcomes, and Assess Guideline Adherence for Children With Cancer.
AU  - David H Noyd
AU  - Amy Berkman
AU  - Claire Howell
AU  - Steve Power
AU  - Susan G Kreissman
AU  - Andrew P Landstrom
AU  - Michel Khouri
AU  - Kevin C Oeffinger
AU  - Warren A Kibbe
SN  - 2473-4276
AB  - PURPOSE: Cardiovascular disease is a significant cause of late morbidity and mortality in survivors of childhood cancer. Clinical informatics tools could enhance provider adherence to echocardiogram guidelines for early detection of late-onset cardiomyopathy. METHODS: Cancer registry data were linked to electronic health record data. Structured query language facilitated the construction of anthracycline-exposed cohorts at a single institution. Primary outcomes included the data quality from automatic anthracycline extraction, sensitivity of International Classification of Disease coding for heart failure, and adherence to echocardiogram guideline recommendations. RESULTS: The final analytic cohort included 385 pediatric oncology patients diagnosed between July 1, 2013, and December 31, 2018, among whom 194 were classified as no anthracycline exposure, 143 had low anthracycline exposure (< 250 mg/m CONCLUSION: Extraction of treatment exposures from the electronic health record through clinical informatics and integration with cancer registry data represents a feasible approach to assess cardiovascular disease outcomes and adherence to guideline recommendations for survivors.
DO  - 10.1200/CCI.21.00099
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Neural Translation and Automated Recognition of ICD-10 Medical Entities From Natural Language: Model Development and Performance Assessment.
AU  - Louis Falissard
AU  - Claire Morgand
AU  - Walid Ghosn
AU  - Claire Imbaud
AU  - Karim Bounebache
AU  - Grégoire Rey
SN  - 2291-9694
AB  - BACKGROUND: The recognition of medical entities from natural language is a ubiquitous problem in the medical field, with applications ranging from medical coding to the analysis of electronic health data for public health. It is, however, a complex task usually requiring human expert intervention, thus making it expansive and time-consuming. Recent advances in artificial intelligence, specifically the rise of deep learning methods, have enabled computers to make efficient decisions on a number of complex problems, with the notable example of neural sequence models and their powerful applications in natural language processing. However, they require a considerable amount of data to learn from, which is typically their main limiting factor. The Centre for Epidemiology on Medical Causes of Death (CépiDc) stores an exhaustive database of death certificates at the French national scale, amounting to several millions of natural language examples provided with their associated human-coded medical entities available to the machine learning practitioner. OBJECTIVE: The aim of this paper was to investigate the application of deep neural sequence models to the problem of medical entity recognition from natural language. METHODS: The investigated data set included every French death certificate from 2011 to 2016. These certificates contain information such as the subject's age, the subject's gender, and the chain of events leading to his or her death, both in French and encoded as International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10) medical entities, for a total of around 3 million observations in the data set. The task of automatically recognizing ICD-10 medical entities from the French natural language-based chain of events leading to death was then formulated as a type of predictive modeling problem known as a sequence-to-sequence modeling problem. A deep neural network-based model, known as the Transformer, was then slightly adapted and fit to the data set. Its performance was then assessed on an external data set and compared to the current state-of-the-art approach. CIs for derived measurements were estimated via bootstrapping. RESULTS: The proposed approach resulted in an F-measure value of 0.952 (95% CI 0.946-0.957), which constitutes a significant improvement over the current state-of-the-art approach and its previously reported F-measure value of 0.825 as assessed on a comparable data set. Such an improvement makes possible a whole field of new applications, from nosologist-level automated coding to temporal harmonization of death statistics. CONCLUSIONS: This paper shows that a deep artificial neural network can directly learn from voluminous data sets in order to identify complex relationships between natural language and medical entities, without any explicit prior knowledge. Although not entirely free from mistakes, the derived model constitutes a powerful tool for automated coding of medical entities from medical language with promising potential applications.
DO  - 10.2196/26353
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Comparative evaluation of underlying causes of death processed by the Automated Classification of Medical Entities and the Underlying Cause of Death Selection Systems.
AU  - A H Santo
AU  - C E Pinheiro
AU  - E M Rodrigues
SN  - 0034-8910
AB  - INTRODUCTION: The correct identification of the underlying cause of death and its precise assignment to a code from the International Classification of Diseases are important issues to achieve accurate and universally comparable mortality statistics. These factors, among other ones, led to the development of computer software programs in order to automatically identify the underlying cause of death. OBJECTIVE: This work was conceived to compare the underlying causes of death processed respectively by the Automated Classification of Medical Entities (ACME) and the "Sistema de Seleção de Causa Básica de Morte" (SCB) programs. MATERIAL AND METHOD: The comparative evaluation of the underlying causes of death processed respectively by ACME and SCB systems was performed using the input data file for the ACME system that included deaths which occurred in the State of S. Paulo from June to December 1993, totalling 129,104 records of the corresponding death certificates. The differences between underlying causes selected by ACME and SCB systems verified in the month of June, when considered as SCB errors, were used to correct and improve SCB processing logic and its decision tables. RESULTS: The processing of the underlying causes of death by the ACME and SCB systems resulted in 3,278 differences, that were analysed and ascribed to lack of answer to dialogue boxes during processing, to deaths due to human immunodeficiency virus [HIV] disease for which there was no specific provision in any of the systems, to coding and/or keying errors and to actual problems. The detailed analysis of these latter disclosed that the majority of the underlying causes of death processed by the SCB system were correct and that different interpretations were given to the mortality coding rules by each system, that some particular problems could not be explained with the available documentation and that a smaller proportion of problems were identified as SCB errors. CONCLUSION: These results, disclosing a very low and insignificant number of actual problems, guarantees the use of the version of the SCB system for the Ninth Revision of the International Classification of Diseases and assures the continuity of the work which is being undertaken for the Tenth Revision version.
DO  - 10.1590/s0034-89101998000100001
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Using Medical Named Entity Recognition in Automatic ICD Prediction.
AU  - Mohamad Kawas
AU  - Bassel Alkhatib
AU  - Khaled Omar
AU  - Khaled Tofelia
AU  - Mayssoon Dashash
AU  - Dorota Formanowicz
SN  - 2314-6141
AB  - The International Classification of Diseases (ICD) serves as a standard in medical coding. Researchers in artificial intelligence, including those focused on natural language processing and machine learning, have made a significant effort to build and develop automatic ICD encoding systems and algorithms. Many algorithms have been developed to implement automatic ICD encoding, but almost all of these algorithms depended on the raw text input without taking into consideration the important medical entities in this input. In this paper, we propose an algorithm for automatically predicting ICD codes based on patient claims. Our algorithm contains several steps for finding the most relevant ICD codes. Primarily, our proposed algorithm employs medical named entity recognition (NER) to find the most important medical entities in a patient claim. For this purpose, the Medical NER model was used based on the BERT model. Next, the algorithm generates embeddings for the extracted entities using the ClinicalBERT model. To identify the most relevant ICD code, the algorithm creates embeddings for an ICD catalog, which contains various information such as chapter descriptions, long descriptions, short descriptions, and ICD codes. The embedding process is primarily based on the long descriptions, and the results are stored in a local database that contains embedding vectors and corresponding mapped ICD codes. The final step of the algorithm calculates the cosine similarity between the embedding vector generated from the patient complaint and the ICD long description vectors. The strength of this new algorithm is that it first detects the medical entities in the textual input and then predicts the most similar ICD codes. Also, our developed algorithm does not need such huge data for training. We tested the developed algorithm on a medical dataset, and the results indicate that the proposed method is highly efficient, achieving a precision rate of approximately 90%.
DO  - 10.1155/bmri/6117755
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - JLAN: medical code prediction via joint learning attention networks and denoising mechanism.
AU  - Xingwang Li
AU  - Yijia Zhang
AU  - Faiz Ul Islam
AU  - Deshi Dong
AU  - Hao Wei
AU  - Mingyu Lu
SN  - 1471-2105
AB  - BACKGROUND: Clinical notes are documents that contain detailed information about the health status of patients. Medical codes generally accompany them. However, the manual diagnosis is costly and error-prone. Moreover, large datasets in clinical diagnosis are susceptible to noise labels because of erroneous manual annotation. Therefore, machine learning has been utilized to perform automatic diagnoses. Previous state-of-the-art (SOTA) models used convolutional neural networks to build document representations for predicting medical codes. However, the clinical notes are usually long-tailed. Moreover, most models fail to deal with the noise during code allocation. Therefore, denoising mechanism and long-tailed classification are the keys to automated coding at scale. RESULTS: In this paper, a new joint learning model is proposed to extend our attention model for predicting medical codes from clinical notes. On the MIMIC-III-50 dataset, our model outperforms all the baselines and SOTA models in all quantitative metrics. On the MIMIC-III-full dataset, our model outperforms in the macro-F1, micro-F1, macro-AUC, and precision at eight compared to the most advanced models. In addition, after introducing the denoising mechanism, the convergence speed of the model becomes faster, and the loss of the model is reduced overall. CONCLUSIONS: The innovations of our model are threefold: firstly, the code-specific representation can be identified by adopted the self-attention mechanism and the label attention mechanism. Secondly, the performance of the long-tailed distributions can be boosted by introducing the joint learning mechanism. Thirdly, the denoising mechanism is suitable for reducing the noise effects in medical code prediction. Finally, we evaluate the effectiveness of our model on the widely-used MIMIC-III datasets and achieve new SOTA results.
DO  - 10.1186/s12859-021-04520-x
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - A Question-and-Answer System to Extract Data From Free-Text Oncological Pathology Reports (CancerBERT Network): Development Study.
AU  - Joseph Ross Mitchell
AU  - Phillip Szepietowski
AU  - Rachel Howard
AU  - Phillip Reisman
AU  - Jennie D Jones
AU  - Patricia Lewis
AU  - Brooke L Fridley
AU  - Dana E Rollison
SN  - 1438-8871
AB  - BACKGROUND: Information in pathology reports is critical for cancer care. Natural language processing (NLP) systems used to extract information from pathology reports are often narrow in scope or require extensive tuning. Consequently, there is growing interest in automated deep learning approaches. A powerful new NLP algorithm, bidirectional encoder representations from transformers (BERT), was published in late 2018. BERT set new performance standards on tasks as diverse as question answering, named entity recognition, speech recognition, and more. OBJECTIVE: The aim of this study is to develop a BERT-based system to automatically extract detailed tumor site and histology information from free-text oncological pathology reports. METHODS: We pursued three specific aims: extract accurate tumor site and histology descriptions from free-text pathology reports, accommodate the diverse terminology used to indicate the same pathology, and provide accurate standardized tumor site and histology codes for use by downstream applications. We first trained a base language model to comprehend the technical language in pathology reports. This involved unsupervised learning on a training corpus of 275,605 electronic pathology reports from 164,531 unique patients that included 121 million words. Next, we trained a question-and-answer (Q&A) model that connects a Q&A layer to the base pathology language model to answer pathology questions. Our Q&A system was designed to search for the answers to two predefined questions in each pathology report: What organ contains the tumor? and What is the kind of tumor or carcinoma? This involved supervised training on 8197 pathology reports, each with ground truth answers to these 2 questions determined by certified tumor registrars. The data set included 214 tumor sites and 193 histologies. The tumor site and histology phrases extracted by the Q&A model were used to predict International Classification of Diseases for Oncology, Third Edition (ICD-O-3), site and histology codes. This involved fine-tuning two additional BERT models: one to predict site codes and another to predict histology codes. Our final system includes a network of 3 BERT-based models. We call this CancerBERT network (caBERTnet). We evaluated caBERTnet using a sequestered test data set of 2050 pathology reports with ground truth answers determined by certified tumor registrars. RESULTS: caBERTnet's accuracies for predicting group-level site and histology codes were 93.53% (1895/2026) and 97.6% (1993/2042), respectively. The top 5 accuracies for predicting fine-grained ICD-O-3 site and histology codes with 5 or more samples each in the training data set were 92.95% (1794/1930) and 96.01% (1853/1930), respectively. CONCLUSIONS: We have developed an NLP system that outperforms existing algorithms at predicting ICD-O-3 codes across an extensive range of tumor sites and histologies. Our new system could help reduce treatment delays, increase enrollment in clinical trials of new therapies, and improve patient outcomes.
DO  - 10.2196/27210
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - The role of standardized data and terminological systems in computerized clinical decision support systems: literature review and survey.
AU  - Leila Ahmadian
AU  - Mariette van Engen-Verheul
AU  - Ferishta Bakhshi-Raiez
AU  - Niels Peek
AU  - Ronald Cornet
AU  - Nicolette F de Keizer
SN  - 1872-8243
AB  - INTRODUCTION: Clinical decision support systems (CDSSs) should be seamlessly integrated with existing clinical information systems to enable automatic provision of advice at the time and place where decisions are made. It has been suggested that a lack of agreed data standards frequently hampers this integration. We performed a literature review to investigate whether CDSSs used standardized (i.e. coded or numerical) data and which terminological systems have been used to code data. We also investigated whether a lack of standardized data was considered an impediment for CDSS implementation. METHODS: Articles reporting an evaluation of a CDSS that provided a computerized advice based on patient-specific data items were identified based on a former literature review on CDSS and on CDSS studies identified in AMIA's 'Year in Review'. Authors of these articles were contacted to check and complete the extracted data. A questionnaire among the authors of included studies was used to determine the obstacles in CDSS implementation. RESULTS: We identified 77 articles published between 1995 and 2008. Twenty-two percent of the evaluated CDSSs used only numerical data. Fifty one percent of the CDSSs that used coded data applied an international terminology. The most frequently used international terminology were the ICD (International Classification of Diseases), used in 68% of the cases and LOINC (Logical Observation Identifiers Names and Codes) in 12% of the cases. More than half of the authors experienced barriers in CDSS implementation. In most cases these barriers were related to the lack of electronically available standardized data required to invoke or activate the CDSS. CONCLUSION: Many CDSSs applied different terminological systems to code data. This diversity hampers the possibility of sharing and reasoning with data within different systems. The results of the survey confirm the hypothesis that data standardization is a critical success factor for CDSS development.
DO  - 10.1016/j.ijmedinf.2010.11.006
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - A method for modeling co-occurrence propensity of clinical codes with application to ICD-10-PCS auto-coding.
AU  - Michael Subotin
AU  - Anthony R Davis
SN  - 1527-974X
AB  - OBJECTIVE: Natural language processing methods for medical auto-coding, or automatic generation of medical billing codes from electronic health records, generally assign each code independently of the others. They may thus assign codes for closely related procedures or diagnoses to the same document, even when they do not tend to occur together in practice, simply because the right choice can be difficult to infer from the clinical narrative. METHODS: We propose a method that injects awareness of the propensities for code co-occurrence into this process. First, a model is trained to estimate the conditional probability that one code is assigned by a human coder, given than another code is known to have been assigned to the same document. Then, at runtime, an iterative algorithm is used to apply this model to the output of an existing statistical auto-coder to modify the confidence scores of the codes. RESULTS: We tested this method in combination with a primary auto-coder for International Statistical Classification of Diseases-10 procedure codes, achieving a 12% relative improvement in F-score over the primary auto-coder baseline. The proposed method can be used, with appropriate features, in combination with any auto-coder that generates codes with different levels of confidence. CONCLUSIONS: The promising results obtained for International Statistical Classification of Diseases-10 procedure codes suggest that the proposed method may have wider applications in auto-coding.
DO  - 10.1093/jamia/ocv201
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Artificial Intelligence Learning Semantics via External Resources for Classifying Diagnosis Codes in Discharge Notes.
AU  - Chin Lin
AU  - Chia-Jung Hsu
AU  - Yu-Sheng Lou
AU  - Shih-Jen Yeh
AU  - Chia-Cheng Lee
AU  - Sui-Lung Su
AU  - Hsiang-Cheng Chen
SN  - 1438-8871
AB  - BACKGROUND: Automated disease code classification using free-text medical information is important for public health surveillance. However, traditional natural language processing (NLP) pipelines are limited, so we propose a method combining word embedding with a convolutional neural network (CNN). OBJECTIVE: Our objective was to compare the performance of traditional pipelines (NLP plus supervised machine learning models) with that of word embedding combined with a CNN in conducting a classification task identifying International Classification of Diseases, Tenth Revision, Clinical Modification (ICD-10-CM) diagnosis codes in discharge notes. METHODS: We used 2 classification methods: (1) extracting from discharge notes some features (terms, n-gram phrases, and SNOMED CT categories) that we used to train a set of supervised machine learning models (support vector machine, random forests, and gradient boosting machine), and (2) building a feature matrix, by a pretrained word embedding model, that we used to train a CNN. We used these methods to identify the chapter-level ICD-10-CM diagnosis codes in a set of discharge notes. We conducted the evaluation using 103,390 discharge notes covering patients hospitalized from June 1, 2015 to January 31, 2017 in the Tri-Service General Hospital in Taipei, Taiwan. We used the receiver operating characteristic curve as an evaluation measure, and calculated the area under the curve (AUC) and F-measure as the global measure of effectiveness. RESULTS: In 5-fold cross-validation tests, our method had a higher testing accuracy (mean AUC 0.9696; mean F-measure 0.9086) than traditional NLP-based approaches (mean AUC range 0.8183-0.9571; mean F-measure range 0.5050-0.8739). A real-world simulation that split the training sample and the testing sample by date verified this result (mean AUC 0.9645; mean F-measure 0.9003 using the proposed method). Further analysis showed that the convolutional layers of the CNN effectively identified a large number of keywords and automatically extracted enough concepts to predict the diagnosis codes. CONCLUSIONS: Word embedding combined with a CNN showed outstanding performance compared with traditional methods, needing very little data preprocessing. This shows that future studies will not be limited by incomplete dictionaries. A large amount of unstructured information from free-text medical writing will be extracted by automated approaches in the future, and we believe that the health care field is about to enter the age of big data.
DO  - 10.2196/jmir.8344
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Multiparameter Intelligent Monitoring in Intensive Care II: a public-access intensive care unit database.
AU  - Mohammed Saeed
AU  - Mauricio Villarroel
AU  - Andrew T Reisner
AU  - Gari Clifford
AU  - Li-Wei Lehman
AU  - George Moody
AU  - Thomas Heldt
AU  - Tin H Kyaw
AU  - Benjamin Moody
AU  - Roger G Mark
SN  - 1530-0293
AB  - OBJECTIVE: We sought to develop an intensive care unit research database applying automated techniques to aggregate high-resolution diagnostic and therapeutic data from a large, diverse population of adult intensive care unit patients. This freely available database is intended to support epidemiologic research in critical care medicine and serve as a resource to evaluate new clinical decision support and monitoring algorithms. DESIGN: Data collection and retrospective analysis. SETTING: All adult intensive care units (medical intensive care unit, surgical intensive care unit, cardiac care unit, cardiac surgery recovery unit) at a tertiary care hospital. PATIENTS: Adult patients admitted to intensive care units between 2001 and 2007. INTERVENTIONS: None. MEASUREMENTS AND MAIN RESULTS: The Multiparameter Intelligent Monitoring in Intensive Care II (MIMIC-II) database consists of 25,328 intensive care unit stays. The investigators collected detailed information about intensive care unit patient stays, including laboratory data, therapeutic intervention profiles such as vasoactive medication drip rates and ventilator settings, nursing progress notes, discharge summaries, radiology reports, provider order entry data, International Classification of Diseases, 9th Revision codes, and, for a subset of patients, high-resolution vital sign trends and waveforms. Data were automatically deidentified to comply with Health Insurance Portability and Accountability Act standards and integrated with relational database software to create electronic intensive care unit records for each patient stay. The data were made freely available in February 2010 through the Internet along with a detailed user's guide and an assortment of data processing tools. The overall hospital mortality rate was 11.7%, which varied by critical care unit. The median intensive care unit length of stay was 2.2 days (interquartile range, 1.1-4.4 days). According to the primary International Classification of Diseases, 9th Revision codes, the following disease categories each comprised at least 5% of the case records: diseases of the circulatory system (39.1%); trauma (10.2%); diseases of the digestive system (9.7%); pulmonary diseases (9.0%); infectious diseases (7.0%); and neoplasms (6.8%). CONCLUSIONS: MIMIC-II documents a diverse and very large population of intensive care unit patient stays and contains comprehensive and detailed clinical data, including physiological waveforms and minute-by-minute trends for a subset of records. It establishes a new public-access resource for critical care research, supporting a diverse range of analytic studies spanning epidemiology, clinical decision-rule development, and electronic tool development.
DO  - 10.1097/CCM.0b013e31820a92c6
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Nonfatal Injuries Sustained in Mass Shootings in the US, 2012-2019: Injury Diagnosis Matrix, Incident Context, and Public Health Considerations.
AU  - Matthew P Czaja
AU  - Chadd K Kraus
AU  - Su Phyo
AU  - Patrick Olivieri
AU  - Dalier R Mederos
AU  - Ivan Puente
AU  - Salman Mohammed
AU  - Ross P Berkeley
AU  - David Slattery
AU  - Thomas H Gildea
AU  - Claire Hardman
AU  - Brandi Palmer
AU  - Melissa L Whitmill
AU  - Una Aluyen
AU  - Jeffery M Pinnow
AU  - Amanda Young
AU  - Carly D Eastin
AU  - Nurani M Kester
AU  - Kaitlyn R Works
AU  - Andrew N Pfeffer
AU  - Aleksander W Keller
AU  - Adam Tobias
AU  - Benjamin Li
AU  - Brian Yorkgitis
AU  - Soheil Saadat
AU  - Mark I Langdorf
SN  - 1936-9018
AB  - INTRODUCTION: The epidemic of gun violence in the United States (US) is exacerbated by frequent mass shootings. In 2021, there were 698 mass shootings in the US, resulting in 705 deaths and 2,830 injuries. This is a companion paper to a publication in JAMA Network Open, in which the nonfatal outcomes of victims of mass shootings have been only partially described. METHODS: We gathered clinical and logistic information from 31 hospitals in the US about 403 survivors of 13 mass shootings, each event involving greater than 10 injuries, from 2012-19. Local champions in emergency medicine and trauma surgery provided clinical data from electronic health records within 24 hours of a mass shooting. We organized descriptive statistics of individual-level diagnoses recorded in medical records using International Classification of Diseases codes, according to the Barell Injury Diagnosis Matrix (BIDM), a standardized tool that classifies 12 types of injuries within 36 body regions. RESULTS: Of the 403 patients who were evaluated at a hospital, 364 sustained physical injuries-252 by gunshot wound (GSW) and 112 by non-ballistic trauma-and 39 were uninjured. Fifty patients had 75 psychiatric diagnoses. Nearly 10% of victims came to the hospital for symptoms triggered by, but not directly related to, the shooting, or for exacerbations of underlying conditions. There were 362 gunshot wounds recorded in the Barell Matrix (1.44 per patient). The Emergency Severity Index (ESI) distribution was skewed toward higher acuity than typical for an emergency department (ED), with 15.1% ESI 1 and 17.6% ESI 2 patients. Semi-automatic firearms were used in 100% of these civilian public mass shootings, with 50 total weapons for 13 shootings (Route 91 Harvest Festival, Las Vegas. 24). Assailant motivations were reported to be associated with hate crimes in 23.1%. CONCLUSION: Survivors of mass shootings have substantial morbidity and characteristic injury distribution, but 37% of victims had no GSW. Law enforcement, emergency medical systems, and hospital and ED disaster planners can use this information for injury mitigation and public policy planning. The BIDM is useful to organize data regarding gun violence injuries. We call for additional research funding to prevent and mitigate interpersonal firearm injuries, and for the National Violent Death Reporting System to expand tracking of injuries, their sequelae, complications, and societal costs.
DO  - 10.5811/westjem.58395
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Identification of Gender Differences in Acute Myocardial Infarction Presentation and Management at Aga Khan University Hospital-Pakistan: Natural Language Processing Application in a Dataset of Patients With Cardiovascular Disease.
AU  - Christine Ngaruiya
AU  - Zainab Samad
AU  - Salma Tajuddin
AU  - Zarmeen Nasim
AU  - Rebecca Leff
AU  - Awais Farhad
AU  - Kyle Pires
AU  - Muhammad Alamgir Khan
AU  - Lauren Hartz
AU  - Basmah Safdar
SN  - 2561-326X
AB  - BACKGROUND: Ischemic heart disease is a leading cause of death globally with a disproportionate burden in low- and middle-income countries (LMICs). Natural language processing (NLP) allows for data enrichment in large datasets to facilitate key clinical research. We used NLP to assess gender differences in symptoms and management of patients hospitalized with acute myocardial infarction (AMI) at Aga Khan University Hospital-Pakistan. OBJECTIVE: The primary objective of this study was to use NLP to assess gender differences in the symptoms and management of patients hospitalized with AMI at a tertiary care hospital in Pakistan. METHODS: We developed an NLP-based methodology to extract AMI symptoms and medications from 5358 discharge summaries spanning the years 1988 to 2018. This dataset included patients admitted and discharged between January 1, 1988, and December 31, 2018, who were older than 18 years with a primary discharge diagnosis of AMI (using ICD-9 [International Classification of Diseases, Ninth Revision], diagnostic codes). The methodology used a fuzzy keyword-matching algorithm to extract AMI symptoms from the discharge summaries automatically. It first preprocesses the free text within the discharge summaries to extract passages indicating the presenting symptoms. Then, it applies fuzzy matching techniques to identify relevant keywords or phrases indicative of AMI symptoms, incorporating negation handling to minimize false positives. After manually reviewing the quality of extracted symptoms in a subset of discharge summaries through preliminary experiments, a similarity threshold of 80% was determined. RESULTS: Among 1769 women and 3589 men with AMI, women had higher odds of presenting with shortness of breath (odds ratio [OR] 1.46, 95% CI 1.26-1.70) and lower odds of presenting with chest pain (OR 0.65, 95% CI 0.55-0.75), even after adjustment for diabetes and age. Presentation with abdominal pain, nausea, or vomiting was much less frequent but consistently more common in women (P<.001). "Ghabrahat," a culturally distinct term for a feeling of impending doom was used by 5.09% of women and 3.69% of men as presenting symptom for AMI (P=.06). First-line medication prescription (statin and β-blockers) was lower in women: women had nearly 30% lower odds (OR 0.71, 95% CI 0.57-0.90) of being prescribed statins, and they had 40% lower odds (OR 0.67, 95% CI 0.57-0.78) of being prescribed β-blockers. CONCLUSIONS: Gender-based differences in clinical presentation and medication management were demonstrated in patients with AMI at a tertiary care hospital in Pakistan. The use of NLP for the identification of culturally nuanced clinical characteristics and management is feasible in LMICs and could be used as a tool to understand gender disparities and address key clinical priorities in LMICs.
DO  - 10.2196/42774
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - [Automatic calculation and visualization of comorbidity scores for decision-making in tumor boards].
AU  - Theresa Wald
AU  - Klemens Birnbaum
AU  - Susanne Wiegand
AU  - Andreas Dietz
AU  - Veit Zebralla
AU  - Gunnar Wichmann
SN  - 1438-8685
AB  - OBJECTIVE: Comorbidity reduces treatment options for patients with head and neck cancer (HNC). Utilization of ICD-10 codes instead of manual research may facilitate estimation of comorbidity relevant for decision-making in the interdisciplinary tumor board (TB). Providing this information immediately in an intuitively ascertainable way whenever registering a patient for the TB would trigger awareness for comorbidities and shows potentially missing information. MATERIAL AND METHODS: Administrative data was extracted of four databases at our clinic (hospital information system (HIS*-MED), the clinic's tumor database, OncoFlow RESULTS: 29 073 ICD-10 codes of 2087 HNC patients were extracted. Matched data are immediately made available whenever registering a patient for the TB and are visualized in a pictogram within OncoFlow CONCLUSIONS: The high prevalence of comorbidities in HNC patients with impact on their eligibility for particular treatment indicates the usefulness of our algorithm for providing automatic comorbidity assessment from administrative data for clinical routine and requires high quality of coding diagnoses.
DO  - 10.1055/a-1058-0171
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - High-dimensional Iterative Causal Forest (hdiCF) for Subgroup Identification Using Health Care Claims Data.
AU  - Tiansheng Wang
AU  - Virginia Pate
AU  - Richard Wyss
AU  - John B Buse
AU  - Michael R Kosorok
AU  - Til Stürmer
SN  - 1476-6256
AB  - We recently developed a machine-learning subgrouping algorithm, iterative causal forest (iCF), to identify subgroups with heterogeneous treatment effects (HTEs) using predefined covariates. However, such predefined covariates may miss or poorly define important features leading to inaccurate subgrouping. To address such limitations, we developed a new semi-automatic subgrouping algorithm, hdiCF, which adapts methodology from high-dimensional propensity score for feature recognition in claims data. The hdiCF algorithm has 3 steps: 1) high-dimensional feature identification by International Classification of Diseases, Current Procedural Terminology, and Anatomical Therapeutic Chemical codes (in/outpatient diagnoses, procedures, prescriptions) and creation of ordinal variables by frequency of occurrence; 2) propensity score trimming and high-dimensional feature preparation; 3) iCF implementation to identify subgroups. We applied hdiCF in a 20% random sample of fee-for-service Medicare beneficiaries who initiated sodium-glucose cotransporter-2 inhibitors (SGLT2i) or glucagon-like peptide-1 receptor agonists to identify subgroups with HTEs for incidence of hospitalized heart failure. HdiCF findings were consistent with studies suggesting SGLT2i to be more beneficial for patients with pre-existing heart failure or chronic kidney disease. HdiCF is not dependent on prior hypotheses about HTEs and identifies subgroups with markers for potential HTEs in real-world evidence studies where active-comparator, new-user study designs limit the potential for unmeasured confounding.
DO  - 10.1093/aje/kwae322
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automatic Medical Code Assignment via Deep Learning Approach for Intelligent Healthcare.
AU  - Fei Teng
AU  - Zheng Ma
AU  - Jie Chen
AU  - Ming Xiao
AU  - Lufei Huang
SN  - 2168-2208
AB  - With the development of healthcare 4.0, there has been an explosion in the amount of data such as image, medical text, physiological signals, lab tests, etc. Among them, medical records provide a complete picture of the associated clinical events. However, the processing of medical texts is difficult because they are structurally free, diverse in style, and have subjective factors. Assigning metadata codes from the International Classification of Diseases (ICD) presents a standardized way of indicating diagnoses and procedures, so it becomes a mandatory process for understanding medical records to make better clinical and financial decisions. Such a manual encoding task is time-consuming, error-prone and expensive. In this paper, we proposed a deep learning approach and a medical topic mining method to automatically predict ICD codes from text-free medical records. The result of the F1 score on Medical Information Mart for Intensive Care (MIMIC-III) dataset increases by 5% over the state of art. It also suitable for multiple ICD versions and languages. For the specific disease, atrial fibrillation, the F1 score is up to 96% and 93.3% using in-house ICD-10 datasets and MIMIC-III datasets, respectively. We developed an Artificial Intelligence based coding system, which can greatly improve the efficiency and accuracy of human coders, and meanwhile accelerate the secondary use for clinical informatics.
DO  - 10.1109/JBHI.2020.2996937
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Sequential Mapping - A Novel Approach to Map from ICD-10-CM to ICD-11.
AU  - Julia Xu
AU  - Kin Wah Fung
AU  - Olivier Bodenreider
SN  - 1879-8365
AB  - BACKGROUND: ICD-11 will be used to report mortality statistics by WHO member countries starting in 2022. In the US, ICD-10-CM will likely continue to be used for morbidity coding for a long period of time. A map between ICD-10-CM and ICD-11 will therefore be useful for interoperability purpose between datasets coded with ICD-10-CM and ICD-11. OBJECTIVES: The objective of this study is to explore novel approaches to automatically derive a map between ICD-10-CM and ICD-11 through the sequential use of existing maps. METHODS AND RESULTS: Sequential mapping through ICD-10 yielded better coverage and accuracy compared to mapping through SNOMED CT. CONCLUSIONS: Sequential mapping is useful in automatically creating a draft map from ICD-10-CM to ICD-11 and would reduce manual curation efforts in creating the final map. The various approaches offer different trade-offs among coverage, recall and precision.
DO  - 10.3233/SHTI220039
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - An empirical evaluation of deep learning for ICD-9 code assignment using MIMIC-III clinical notes.
AU  - Jinmiao Huang
AU  - Cesar Osorio
AU  - Luke Wicent Sy
SN  - 1872-7565
AB  - BACKGROUND AND OBJECTIVE: Code assignment is of paramount importance in many levels in modern hospitals, from ensuring accurate billing process to creating a valid record of patient care history. However, the coding process is tedious and subjective, and it requires medical coders with extensive training. This study aims to evaluate the performance of deep-learning-based systems to automatically map clinical notes to ICD-9 medical codes. METHODS: The evaluations of this research are focused on end-to-end learning methods without manually defined rules. Traditional machine learning algorithms, as well as state-of-the-art deep learning methods such as Recurrent Neural Networks and Convolution Neural Networks, were applied to the Medical Information Mart for Intensive Care (MIMIC-III) dataset. An extensive number of experiments was applied to different settings of the tested algorithm. RESULTS: Findings showed that the deep learning-based methods outperformed other conventional machine learning methods. From our assessment, the best models could predict the top 10 ICD-9 codes with 0.6957 F CONCLUSION: A set of standard metrics was utilized in assessing the performance of ICD-9 code assignment on MIMIC-III dataset. All the developed evaluation tools and resources are available online, which can be used as a baseline for further research.
DO  - 10.1016/j.cmpb.2019.05.024
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Identifying Acute Low Back Pain Episodes in Primary Care Practice From Clinical Notes: Observational Study.
AU  - Riccardo Miotto
AU  - Bethany L Percha
AU  - Benjamin S Glicksberg
AU  - Hao-Chih Lee
AU  - Lisanne Cruz
AU  - Joel T Dudley
AU  - Ismail Nabeel
SN  - 2291-9694
AB  - BACKGROUND: Acute and chronic low back pain (LBP) are different conditions with different treatments. However, they are coded in electronic health records with the same International Classification of Diseases, 10th revision (ICD-10) code (M54.5) and can be differentiated only by retrospective chart reviews. This prevents an efficient definition of data-driven guidelines for billing and therapy recommendations, such as return-to-work options. OBJECTIVE: The objective of this study was to evaluate the feasibility of automatically distinguishing acute LBP episodes by analyzing free-text clinical notes. METHODS: We used a dataset of 17,409 clinical notes from different primary care practices; of these, 891 documents were manually annotated as acute LBP and 2973 were generally associated with LBP via the recorded ICD-10 code. We compared different supervised and unsupervised strategies for automated identification: keyword search, topic modeling, logistic regression with bag of n-grams and manual features, and deep learning (a convolutional neural network-based architecture [ConvNet]). We trained the supervised models using either manual annotations or ICD-10 codes as positive labels. RESULTS: ConvNet trained using manual annotations obtained the best results with an area under the receiver operating characteristic curve of 0.98 and an F score of 0.70. ConvNet's results were also robust to reduction of the number of manually annotated documents. In the absence of manual annotations, topic models performed better than methods trained using ICD-10 codes, which were unsatisfactory for identifying LBP acuity. CONCLUSIONS: This study uses clinical notes to delineate a potential path toward systematic learning of therapeutic strategies, billing guidelines, and management options for acute LBP at the point of care.
DO  - 10.2196/16878
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Selecting relevant features from the electronic health record for clinical code prediction.
AU  - Elyne Scheurwegs
AU  - Boris Cule
AU  - Kim Luyckx
AU  - Léon Luyten
AU  - Walter Daelemans
SN  - 1532-0480
AB  - A multitude of information sources is present in the electronic health record (EHR), each of which can contain clues to automatically assign diagnosis and procedure codes. These sources however show information overlap and quality differences, which complicates the retrieval of these clues. Through feature selection, a denser representation with a consistent quality and less information overlap can be obtained. We introduce and compare coverage-based feature selection methods, based on confidence and information gain. These approaches were evaluated over a range of medical specialties, with seven different medical specialties for ICD-9-CM code prediction (six at the Antwerp University Hospital and one in the MIMIC-III dataset) and two different medical specialties for ICD-10-CM code prediction. Using confidence coverage to integrate all sources in an EHR shows a consistent improvement in F-measure (49.83% for diagnosis codes on average), both compared with the baseline (44.25% for diagnosis codes on average) and with using the best standalone source (44.41% for diagnosis codes on average). Confidence coverage creates a concise patient stay representation independent of a rigid framework such as UMLS, and contains easily interpretable features. Confidence coverage has several advantages to a baseline setup. In our baseline setup, feature selection was limited to a filter removing features with less than five total occurrences in the trainingset. Prediction results improved consistently when using multiple heterogeneous sources to predict clinical codes, while reducing the number of features and the processing time.
DO  - 10.1016/j.jbi.2017.09.004
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Use of Computational Phenotypes for Predicting Genetic Subgroups of Cerebral Palsy.
AU  - Imen Alkuraya
AU  - Alexandra Santana Almansa
AU  - Azubuike Eleonu
AU  - Paul Avillach
AU  - Annapurna Poduri
AU  - Siddharth Srivastava
SN  - 1873-5150
AB  - BACKGROUND: Emerging evidence suggests that 20%-30% of cases of cerebral palsy (CP) may have a genetic cause. Our group previously identified subsets of patients with CP or CP-masquerading conditions who warrant genetic testing, including those with regression or progressive neurological symptoms (CP masqueraders) and those without any known risk factors for CP (cryptogenic CP). Recognition of these subgroups in clinical settings remains challenging. METHODS: To address this challenge, we developed and evaluated a computational phenotyping approach using international classification of diseases (ICD)-9/ICD-10 billing codes to automatically identify patients with unexplained CP or CP-masquerading conditions who may benefit from genetic testing. We applied this computational phenotyping approach to a cohort of 250 participants from the Boston Children's Hospital CP Sequencing Study, aimed at identifying genetic causes in CP and CP-masquerading conditions. RESULTS: Manual review served as the gold standard, identifying 8% as CP masqueraders, 42% as cryptogenic CP, and 50% as noncryptogenic CP. Computational phenotyping based on ICD-9/ICD-10 codes achieved a sensitivity of 95%, specificity of 72%, positive predictive value of 77%, and negative predictive value of 94% in identifying cases warranting genetic testing. CONCLUSIONS: Our findings demonstrate the feasibility of using computational phenotyping to identify patients with CP or CP-masquerading conditions who warrant genetic testing. Further studies are needed to evaluate the effectiveness and real-world application of this tool in larger health care systems. Nevertheless, the computational phenotyping approach holds promise as a possible clinical decision support that could be integrated into electronic health record systems, enhancing clinical workflows and facilitating actionable genetic diagnoses.
DO  - 10.1016/j.pediatrneurol.2025.09.016
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automatic ICD-10 coding algorithm using an improved longest common subsequence based on semantic similarity.
AU  - YunZhi Chen
AU  - HuiJuan Lu
AU  - LanJuan Li
SN  - 1932-6203
AB  - ICD-10(International Classification of Diseases 10th revision) is a classification of a disease, symptom, procedure, or injury. Diseases are often described in patients' medical records with free texts, such as terms, phrases and paraphrases, which differ significantly from those used in ICD-10 classification. This paper presents an improved approach based on the Longest Common Subsequence (LCS) and semantic similarity for automatic Chinese diagnoses, mapping from the disease names given by clinician to the disease names in ICD-10. LCS refers to the longest string that is a subsequence of every member of a given set of strings. The proposed method of improved LCS in this paper can increase the accuracy of processing in Chinese disease mapping.
DO  - 10.1371/journal.pone.0173410
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Mamba-enhanced disease semantic knowledge graph for interpretable automatic ICD coding.
AU  - Pengli Lu
AU  - Chao Dong
AU  - Jingjin Xue
AU  - Fentang Gao
SN  - 1532-0480
AB  - Automatic ICD coding refers to the process of using artificial intelligence methods to automatically extract information related to diseases, symptoms, diagnoses, treatments, and other relevant details from electronic health records, and convert it into codes that comply with the International Classification of Diseases (ICD) standard. Automatic ICD coding technology has been gradually improved with the advancement of deep learning, but in practical deployment, it still faces challenges such as inconsistent semantics, ambiguous labels, and limited interpretability. To address these issues, we propose a novel automatic ICD coding framework MKHCNet (Mamba-Knowledge-HPLA-ContraNorm Network) which integrates unstructured clinical knowledge representation, long-range dependency modeling, and contrastive normalization techniques to enhance coding performance. Specifically, we construct a disease semantic knowledge graph to enrich ICD label representations, employ the Mamba network to capture cross-domain dependencies, apply the ContraNorm module to enhance label separability, and propose the Hierarchical Position Label Attention (HPLA) mechanism to achieve fine-grained, attention-based interpretability. Finally, with the purpose of capturing complex nonlinear relationships more effectively and better adapting to complex patterns in EHR data, FastKAN acts as a classifier and utilizes radial basis function (RBF) for feature transformation. We conducted systematic experiments on the benchmark datasets MIMIC-FULL and MIMIC-50. The experimental results show that MKHCNet improves MaAUC and P@8 by 2.1% and 0.3% on MIMIC-FULL respectively compared with the best existing mainstream model. Furthermore, case studies demonstrate that the model is able to effectively identify complex semantic cues and provide strong clinical interpretability.
DO  - 10.1016/j.jbi.2025.104973
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automatic generation of case-detection algorithms to identify children with asthma from large electronic health record databases.
AU  - Zubair Afzal
AU  - Marjolein Engelkes
AU  - Katia M C Verhamme
AU  - Hettie M Janssens
AU  - Miriam C J M Sturkenboom
AU  - Jan A Kors
AU  - Martijn J Schuemie
SN  - 1099-1557
AB  - PURPOSE: Most electronic health record databases contain unstructured free-text narratives, which cannot be easily analyzed. Case-detection algorithms are usually created manually and often rely only on using coded information such as International Classification of Diseases version 9 codes. We applied a machine-learning approach to generate and evaluate an automated case-detection algorithm that uses both free-text and coded information to identify asthma cases. METHODS: The Integrated Primary Care Information (IPCI) database was searched for potential asthma patients aged 5-18 years using a broad query on asthma-related codes, drugs, and free text. A training set of 5032 patients was created by manually annotating the potential patients as definite, probable, or doubtful asthma cases or non-asthma cases. The rule-learning program RIPPER was then used to generate algorithms to distinguish cases from non-cases. An over-sampling method was used to balance the performance of the automated algorithm to meet our study requirements. Performance of the automated algorithm was evaluated against the manually annotated set. RESULTS: The selected algorithm yielded a positive predictive value (PPV) of 0.66, sensitivity of 0.98, and specificity of 0.95 when identifying only definite asthma cases; a PPV of 0.82, sensitivity of 0.96, and specificity of 0.90 when identifying both definite and probable asthma cases; and a PPV of 0.57, sensitivity of 0.95, and specificity of 0.67 for the scenario identifying definite, probable, and doubtful asthma cases. CONCLUSIONS: The automated algorithm shows good performance in detecting cases of asthma utilizing both free-text and coded data. This algorithm will facilitate large-scale studies of asthma in the IPCI database.
DO  - 10.1002/pds.3438
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Quality of generated diagnosis related groups in Italian Respiratory Intermediate Care Units.
AU  - A Potena
AU  - L Ballerin
AU  - S Putinati
AU  - M Piattella
AU  - M Cellini
AU  - C Buniolo
AU  - A Cavalli
AU  - C Rampulla
AU  - M Gorini
AU  - A Corrado
AU  - M Confalonieri
SN  - 1122-0643
AB  - BACKGROUND: To date we lack official data on tipology of Diagnosis Related Groups (DRGs) and their quality in Italian Respiratory Intermediate Care Units (RICUs). AIM: The objective of the study was to collect data on the activity of 26 Italian RICUs and to evaluate the quality of the DRGs generated. METHODS: The primary and secondary diseases, the procedures carried out and their coding using the ICD9 system (valid Italy until 2000) were collected from the discharge forms of patients admitted to RICUs. To obtain the DRG, these codes were automatically recoded in the ICD9-CM classification system by Grouper 10. Afterwards, the same diseases and procedures were directly processed by the ICD9-CM classification system. Finally, in order to evaluate the quality of care, the DRGs generated by the ICD9 classification system were compared to DRGs generated by the ICD9-CM classification system. RESULTS: The average weight of the patients cared for in an Italian RICU was 2.05 using the ICD9 classification system and 2.53 using the ICD9-CM classification system. Some non-complicated DRGs (80-97) or non specific DRGs (101-102) were set to zero; others, like DRG 87 appear due to the ability of the ICD9-CM classification system to recognise and accept the fifth digit of the Respiratory Failure code (518.81). The difference in terms of DRG scores generated by the two codification systems was 360.5 DRG points in favour of ICD9-CM. More than 1 million Euro of reimbursements have been lost, as the average national reimbursement for each DRG score is Euro 2,943.80. CONCLUSION: Severe pulmonary diseases determined the case mix of patients cared for in the Italian RICUs during the observed period. The Italian RICUs offer high quality assistance and are characterised by high mean weight per treated patient. However, the activity has been under-estimated due to the low sensitivity of the ICD9 classification system used in the recognition of the real disease and in the correct generation of relative DRG. The ICD9 classification system penalised the recognition of respiratory failure in particular.
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Comparison of Automated Posttonsillectomy Bleed Capture With Self-report.
AU  - D Ryan Phillips
AU  - Susan E Ellsperman
AU  - Bruce H Matt
AU  - Ben L Zarzaur
SN  - 2168-619X
AB  - IMPORTANCE: Tonsillectomy is one of the most common procedures performed by otolaryngologists and is associated with postoperative bleeding. Bleed rates are usually monitored by self-report. OBJECTIVE: To evaluate whether using automated capture and reporting of pediatric posttonsillectomy bleeding is feasible and accurate compared with traditional self-reporting by the surgical team. DESIGN, SETTING, AND PARTICIPANTS: An automated complication-reporting algorithm was designed to query the local health information exchange and then tested against self-reported tonsillectomy complication data collected from January 1, 2014, through December 31, 2015, at a tertiary pediatric hospital. The algorithm identified patients undergoing tonsillectomy and searched their postoperative encounters for a hand-selected set of diagnosis codes from the International Classification of Diseases, Ninth Revision and International Statistical Classification of Diseases and Related Health Problems, Tenth Revision and free-text words to identify complication events. Five months of the 2014-2015 data set were used to help design the algorithm. Data from the remaining 19 months were compared with self-reported complications. MAIN OUTCOMES AND MEASURES: Automated system findings compared with self-reported bleeding events. RESULTS: During the 19-month period, 1017 tonsillectomies were performed. We compared the algorithm's effectiveness in finding tonsillectomy and adenotonsillectomy procedures for the evaluated surgeons with the hand-reviewed master tonsillectomy list. The algorithm reported 51 false-positive (5.01% missed) and 74 false-negative (7.28% misidentified) procedures. The algorithm agreed with self-report for 986 tonsillectomies and disagreed on 31 cases (3.05%) (κ = 0.69; 95% CI, 0.66-0.73). The algorithm was found to be sensitive to correctly identifying 60.53% (95% CI, 48.63%-71.34%) of tonsillectomies as having bleeding complications, with a specificity of 98.30% (95% CI, 97.19%-98.99%). CONCLUSIONS AND RELEVANCE: Capture of posttonsillectomy bleeding is possible through an automatic search of the medical record, although the algorithm will require continued refinement. Leveraging health information exchange data increases the possibilities of capturing complications at hospitals outside the local health system. Use of these algorithms will allow repeatable automated feedback to be provided to surgeons on a cyclical basis.
DO  - 10.1001/jamaoto.2017.0148
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontology-Enhanced Large Language Models: Development Study.
AU  - Lang Cao
AU  - Jimeng Sun
AU  - Adam Cross
SN  - 2291-9694
AB  - BACKGROUND: Rare diseases affect millions worldwide but sometimes face limited research focus individually due to low prevalence. Many rare diseases do not have specific International Classification of Diseases, Ninth Edition (ICD-9) and Tenth Edition (ICD-10), codes and therefore cannot be reliably extracted from granular fields like "Diagnosis" and "Problem List" entries, which complicates tasks that require identification of patients with these conditions, including clinical trial recruitment and research efforts. Recent advancements in large language models (LLMs) have shown promise in automating the extraction of medical information, offering the potential to improve medical research, diagnosis, and management. However, most LLMs lack professional medical knowledge, especially concerning specific rare diseases, and cannot effectively manage rare disease data in its various ontological forms, making it unsuitable for these tasks. OBJECTIVE: Our aim is to create an end-to-end system called automated rare disease mining (AutoRD), which automates the extraction of rare disease-related information from medical text, focusing on entities and their relations to other medical concepts, such as signs and symptoms. AutoRD integrates up-to-date ontologies with other structured knowledge and demonstrates superior performance in rare disease extraction tasks. We conducted various experiments to evaluate AutoRD's performance, aiming to surpass common LLMs and traditional methods. METHODS: AutoRD is a pipeline system that involves data preprocessing, entity extraction, relation extraction, entity calibration, and knowledge graph construction. We implemented this system using GPT-4 and medical knowledge graphs developed from the open-source Human Phenotype and Orphanet ontologies, using techniques such as chain-of-thought reasoning and prompt engineering. We quantitatively evaluated our system's performance in entity extraction, relation extraction, and knowledge graph construction. The experiment used the well-curated dataset RareDis2023, which contains medical literature focused on rare disease entities and their relations, making it an ideal dataset for training and testing our methodology. RESULTS: On the RareDis2023 dataset, AutoRD achieved an overall entity extraction F1-score of 56.1% and a relation extraction F1-score of 38.6%, marking a 14.4% improvement over the baseline LLM. Notably, the F1-score for rare disease entity extraction reached 83.5%, indicating high precision and recall in identifying rare disease mentions. These results demonstrate the effectiveness of integrating LLMs with medical ontologies in extracting complex rare disease information. CONCLUSIONS: AutoRD is an automated end-to-end system for extracting rare disease information from text to build knowledge graphs, addressing critical limitations of existing LLMs by improving identification of these diseases and connecting them to related clinical features. This work underscores the significant potential of LLMs in transforming health care, particularly in the rare disease domain. By leveraging ontology-enhanced LLMs, AutoRD constructs a robust medical knowledge base that incorporates up-to-date rare disease information, facilitating improved identification of patients and resulting in more inclusive research and trial candidacy efforts.
DO  - 10.2196/60665
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - The ngram chief complaint classifier: a novel method of automatically creating chief complaint classifiers based on international classification of diseases groupings.
AU  - Philip Brown
AU  - Sylvia Halász
AU  - Colin Goodall
AU  - Dennis G Cochrane
AU  - Peter Milano
AU  - John R Allegra
SN  - 1532-0480
AB  - INTRODUCTION: The ngram classifier is created by using text fragments to measure associations between chief complaints (CC) and a syndromic grouping of ICD-9-CM codes. OBJECTIVES: For gastrointestinal (GI) syndrome to determine: (1) ngram CC classifier sensitivity/specificity. (2) Daily volumes for ngram CC and ICD-9-CM classifiers. DESIGN: Retrospective cohort. SETTING: 19 Emergency Departments. PARTICIPANTS: Consecutive visits (1/1/2000-12/31/2005). PROTOCOL: (1) Used an existing ICD-9-CM filter for "lower GI" to create the ngram CC classifier from a training set and then measured sensitivity/specificity in a test set using an ICD-9-CM classifier as criterion. (2) Compare daily volumes based on ICD-9-CM with that predicted by the ngram classifier. RESULTS: For a specificity of 0.96, sensitivity was 0.70. The daily volume correlation for ngram vs. ICD-9-CM was R=0.92. CONCLUSION: The ngram CC classifier performed similarly to manually developed CC classifiers and has advantages of rapid automated creation and updating, and may be used independent of language or dialect.
DO  - 10.1016/j.jbi.2009.08.015
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Evaluating alignment quality between iconic language and reference terminologies using similarity metrics.
AU  - Nicolas Griffon
AU  - Gaetan Kerdelhué
AU  - Lina F Soualmia
AU  - Tayeb Merabti
AU  - Julien Grosjean
AU  - Jean-Baptiste Lamy
AU  - Alain Venot
AU  - Catherine Duclos
AU  - Stefan J Darmoni
SN  - 1472-6947
AB  - BACKGROUND: Visualization of Concepts in Medicine (VCM) is a compositional iconic language that aims to ease information retrieval in Electronic Health Records (EHR), clinical guidelines or other medical documents. Using VCM language in medical applications requires alignment with medical reference terminologies. Alignment from Medical Subject Headings (MeSH) thesaurus and International Classification of Diseases - tenth revision (ICD10) to VCM are presented here. This study aim was to evaluate alignment quality between VCM and other terminologies using different measures of inter-alignment agreement before integration in EHR. METHODS: For medical literature retrieval purposes and EHR browsing, the MeSH thesaurus and the ICD10, both organized hierarchically, were aligned to VCM language. Some MeSH to VCM alignments were performed automatically but others were performed manually and validated. ICD10 to VCM alignment was entirely manually performed. Inter-alignment agreement was assessed on ICD10 codes and MeSH descriptors, sharing the same Concept Unique Identifiers in the Unified Medical Language System (UMLS). Three metrics were used to compare two VCM icons: binary comparison, crude Dice Similarity Coefficient (DSCcrude), and semantic Dice Similarity Coefficient (DSCsemantic), based on Lin similarity. An analysis of discrepancies was performed. RESULTS: MeSH to VCM alignment resulted in 10,783 relations: 1,830 of which were manually performed and 8,953 were automatically inherited. ICD10 to VCM alignment led to 19,852 relations. UMLS gathered 1,887 alignments between ICD10 and MeSH. Only 1,606 of them were used for this study. Inter-alignment agreement using only validated MeSH to VCM alignment was 74.2% [70.5-78.0]CI95%, DSCcrude was 0.93 [0.91-0.94]CI95%, and DSCsemantic was 0.96 [0.95-0.96]CI95%. Discrepancy analysis revealed that even if two thirds of errors came from the reviewers, UMLS was nevertheless responsible for one third. CONCLUSIONS: This study has shown strong overall inter-alignment agreement between MeSH to VCM and ICD10 to VCM manual alignments. VCM icons have now been integrated into a guideline search engine (http://www.cismef.org) and a health terminologies portal (http://www.hetop.eu).
DO  - 10.1186/1472-6947-14-17
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - The reliability of the ICD-AIS map in identifying serious road traffic injuries from the Helsinki Trauma Registry.
AU  - Noora K Airaksinen
AU  - Mikko T Heinänen
AU  - Lauri E Handolin
SN  - 1879-0267
AB  - OBJECTIVE: The EU has recommended that its member countries compile statistics on the number of serious road traffic injuries. In Finland, the number of seriously injured road traffic patients is assessed using the International Classification of Diseases, 10 METHODS: Data was derived from the Helsinki Trauma Registry (HTR) and included 215 severe (New Injury Severity Score >15) trauma patients injured in road traffic accidents from the years 2016 and 2017. The severity ratings of injuries (Abbreviated Injury Scale, AIS 3+) and patients (Maximum Abbreviated Injury Scale, MAIS 3+) were determined by direct AIS coding of the HTR and were also generated by the ICD-AIS map based on ICD-10 injury codes. These two ratings were compared by injury mechanism and Injury Severity Score (ISS) body regions. The strength of agreement was described using Cohen's κ. The most common injury codes with errors in severity rating by the ICD-AIS map were presented. RESULTS: The number of seriously injured patients by the ICD-AIS map was 21% lower, and the number of serious injuries was 36% lower than the corresponding numbers by direct coding. The exact agreement of the injury ratings was 72% (κ = 0.44, 95% CI 0.42-0.46). Most of the conversion errors were due to the simplicity of the ICD-10 codes used in Finland compared to those used in the ICD-AIS map (ICD-10-CM) and the missing codes from the ICD-AIS map. The most frequent misclassifications were due to multiple rib fractures, visceral organ injuries, some open fractures of extremities, and specific head injuries. Missing codes were most common in face, chest, and limb injuries. CONCLUSIONS: The ICD-10 injury codes presently used in Finland should be more specific to permit reliable conversion results by the ICD-AIS map. The problem with missing codes should be considered more closely. When implementing the ICD-11, all detailed injury codes should be introduced.
DO  - 10.1016/j.injury.2019.07.030
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automated comparison of last hospital main diagnosis and underlying cause of death ICD10 codes, France, 2008-2009.
AU  - Agathe Lamarche-Vadel
AU  - Gérard Pavillon
AU  - Albertine Aouba
AU  - Lars Age Johansson
AU  - Laurence Meyer
AU  - Eric Jougla
AU  - Grégoire Rey
SN  - 1472-6947
AB  - BACKGROUND: In the age of big data in healthcare, automated comparison of medical diagnoses in large scale databases is a key issue. Our objectives were: 1) to formally define and identify cases of independence between last hospitalization main diagnosis (MD) and death registry underlying cause of death (UCD) for deceased subjects hospitalized in their last year of life; 2) to study their distribution according to socio-demographic and medico-administrative variables; 3) to discuss the interest of this method in the specific context of hospital quality of care assessment. METHODS: 1) Elaboration of an algorithm comparing MD and UCD, relying on Iris, a coding system based on international standards. 2) Application to 421,460 beneficiaries of the general health insurance regime (which covers 70% of French population) hospitalized and deceased in 2008-2009. RESULTS: 1) Independence, was defined as MD and UCD belonging to different trains of events leading to death 2) Among the deaths analyzed automatically (91.7%), 8.5% of in-hospital deaths and 19.5% of out-of-hospital deaths were classified as independent. Independence was more frequent in elder patients, as well as when the discharge-death time interval grew (14.3% when death occurred within 30 days after discharge and 27.7% within 6 to 12 months) and for UCDs other than neoplasms. CONCLUSION: Our algorithm can identify cases where death can be considered independent from the pathology treated in hospital. Excluding these deaths from the ones allocated to the hospitalization process could contribute to improve post-hospital mortality indicators. More generally, this method has the potential of being developed and used for other diagnoses comparisons across time periods or databases.
DO  - 10.1186/1472-6947-14-44
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - From data collection to downstream data use: Malaysia's experience with ICD-11.
AU  - Erwyn Chin Wei Ooi
AU  - Zaleha Md Isa
AU  - Mohd Rizal Abdul Manaf
AU  - Ahmad Soufi Ahmad Fuad
AU  - Hammad Fahli Sidek
AU  - Mimi Nurakmal Mustapa
AU  - Azman Ahmad
AU  - Fawzi Zaidan Ali
AU  - Mohamad Fadli Kharie
AU  - Shahidah Adilah Shith
AU  - Nuraidah Mohd Marzuki
SN  - 1833-3575
AB  - BACKGROUND: The transition of systems to the  OBJECTIVE: To demonstrate Malaysia's experience in implementing ICD-11, from data collection to downstream data use applications.Method and implementation:We describe improvements to existing data source systems and downstream data applications. For non-HIS and HIS (ICD-10) systems, data were manually entered into the health management information system equipped with ICD-11 or automatically mapped from ICD-10 to ICD-11. Following these system improvements, we collected and reported ICD-11 data from all hospitals nationwide, regardless of the individual systems' status in ICD-11 use. DISCUSSION: Lessons learnt related to legacy systems; ICD-11 releases and system updates; mapping; reporting; human resources and related applications. CONCLUSION: With careful planning, standardisation of the collection and use of ICD-11 data can be accomplished with limited resources and in a complex environment with heterogeneous systems. IMPLICATIONS: Use of ICD-11 data in downstream data applications improves data quality to answer specific business or research questions.
DO  - 10.1177/18333583241295717
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - PheWAS: demonstrating the feasibility of a phenome-wide scan to discover gene-disease associations.
AU  - Joshua C Denny
AU  - Marylyn D Ritchie
AU  - Melissa A Basford
AU  - Jill M Pulley
AU  - Lisa Bastarache
AU  - Kristin Brown-Gentry
AU  - Deede Wang
AU  - Dan R Masys
AU  - Dan M Roden
AU  - Dana C Crawford
SN  - 1367-4811
AB  - MOTIVATION: Emergence of genetic data coupled to longitudinal electronic medical records (EMRs) offers the possibility of phenome-wide association scans (PheWAS) for disease-gene associations. We propose a novel method to scan phenomic data for genetic associations using International Classification of Disease (ICD9) billing codes, which are available in most EMR systems. We have developed a code translation table to automatically define 776 different disease populations and their controls using prevalent ICD9 codes derived from EMR data. As a proof of concept of this algorithm, we genotyped the first 6005 European-Americans accrued into BioVU, Vanderbilt's DNA biobank, at five single nucleotide polymorphisms (SNPs) with previously reported disease associations: atrial fibrillation, Crohn's disease, carotid artery stenosis, coronary artery disease, multiple sclerosis, systemic lupus erythematosus and rheumatoid arthritis. The PheWAS software generated cases and control populations across all ICD9 code groups for each of these five SNPs, and disease-SNP associations were analyzed. The primary outcome of this study was replication of seven previously known SNP-disease associations for these SNPs. RESULTS: Four of seven known SNP-disease associations using the PheWAS algorithm were replicated with P-values between 2.8 x 10(-6) and 0.011. The PheWAS algorithm also identified 19 previously unknown statistical associations between these SNPs and diseases at P < 0.01. This study indicates that PheWAS analysis is a feasible method to investigate SNP-disease associations. Further evaluation is needed to determine the validity of these associations and the appropriate statistical thresholds for clinical significance. AVAILABILITY: The PheWAS software and code translation table are freely available at http://knowledgemap.mc.vanderbilt.edu/research.
DO  - 10.1093/bioinformatics/btq126
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - From episodes of care to diagnosis codes: automatic text categorization for medico-economic encoding.
AU  - Patrick Ruch
AU  - Julien Gobeilla
AU  - Imad Tbahritia
AU  - Antoine Geissbühlera
SN  - 1942-597X
AB  - We report on the design and evaluation of an original system to help assignment ICD (International Classification of Disease) codes to clinical narratives. The task is defined as a multi-class multi-document classification task. We combine a set of machine learning and data-poor methods to generate a single automatic text categorizer, which returns a ranked list of ICD codes. The combined ranking system currently obtains a precision of 75% at high ranks and a recall of about 63% for the top twenty returned codes for a theoretical upper bound of about 79% (inter-coder agreement). The performance of the data-poor classifier is weak, whereas the use of tempo-rally-typed contents such as anamnesis and prescription free text sections results in a statistically significant improvement.
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - An empirical evaluation of supervised learning approaches in assigning diagnosis codes to electronic medical records.
AU  - Ramakanth Kavuluru
AU  - Anthony Rios
AU  - Yuan Lu
SN  - 1873-2860
AB  - BACKGROUND: Diagnosis codes are assigned to medical records in healthcare facilities by trained coders by reviewing all physician authored documents associated with a patient's visit. This is a necessary and complex task involving coders adhering to coding guidelines and coding all assignable codes. With the popularity of electronic medical records (EMRs), computational approaches to code assignment have been proposed in the recent years. However, most efforts have focused on single and often short clinical narratives, while realistic scenarios warrant full EMR level analysis for code assignment. OBJECTIVE: We evaluate supervised learning approaches to automatically assign international classification of diseases (ninth revision) - clinical modification (ICD-9-CM) codes to EMRs by experimenting with a large realistic EMR dataset. The overall goal is to identify methods that offer superior performance in this task when considering such datasets. METHODS: We use a dataset of 71,463 EMRs corresponding to in-patient visits with discharge date falling in a two year period (2011-2012) from the University of Kentucky (UKY) Medical Center. We curate a smaller subset of this dataset and also use a third gold standard dataset of radiology reports. We conduct experiments using different problem transformation approaches with feature and data selection components and employing suitable label calibration and ranking methods with novel features involving code co-occurrence frequencies and latent code associations. RESULTS: Over all codes with at least 50 training examples we obtain a micro F-score of 0.48. On the set of codes that occur at least in 1% of the two year dataset, we achieve a micro F-score of 0.54. For the smaller radiology report dataset, the classifier chaining approach yields best results. For the smaller subset of the UKY dataset, feature selection, data selection, and label calibration offer best performance. CONCLUSIONS: We show that datasets at different scale (size of the EMRs, number of distinct codes) and with different characteristics warrant different learning approaches. For shorter narratives pertaining to a particular medical subdomain (e.g., radiology, pathology), classifier chaining is ideal given the codes are highly related with each other. For realistic in-patient full EMRs, feature and data selection methods offer high performance for smaller datasets. However, for large EMR datasets, we observe that the binary relevance approach with learning-to-rank based code reranking offers the best performance. Regardless of the training dataset size, for general EMRs, label calibration to select the optimal number of labels is an indispensable final step.
DO  - 10.1016/j.artmed.2015.04.007
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Transforming the German ICD-10 (ICD-10-GM) into Injury Severity Score (ISS)-Introducing a new method for automated re-coding.
AU  - Marcel Niemann
AU  - Sven Märdian
AU  - Pascal Niemann
AU  - Liv Tetteh
AU  - Serafeim Tsitsilonis
AU  - Karl F Braun
AU  - Ulrich Stöckle
AU  - Frank Graef
SN  - 1932-6203
AB  - BACKGROUND: While potentially timesaving, there is no program to automatically transform diagnosis codes of the ICD-10 German modification (ICD-10-GM) into the injury severity score (ISS). OBJECTIVE: To develop a mapping method from ICD-10-GM into ICD-10 clinical modification (ICD-10-CM) to calculate the abbreviated injury scale (AIS) and ISS of each patient using the ICDPIC-R and to compare the manually and automatically calculated scores. METHODS: Between January 2019 and June 2021, the most severe AIS of each body region and the ISS were manually calculated using medical documentation and radiology reports of all major trauma patients of a German level I trauma centre. The ICD-10-GM codes of these patients were exported from the electronic medical data system SAP, and a Java program was written to transform these into ICD-10-CM codes. Afterwards, the ICDPIC-R was used to automatically generate the most severe AIS of each body region and the ISS. The automatically and manually determined ISS and AIS scores were then tested for equivalence. RESULTS: Statistical analysis revealed that the manually and automatically calculated ISS were significantly equivalent over the entire patient cohort. Further sub-group analysis, however, showed that equivalence could only be demonstrated for patients with an ISS between 16 and 24. Likewise, the highest AIS scores of each body region were not equal in the manually and automatically calculated group. CONCLUSION: Though achieving mapping results highly comparable to previous mapping methods of ICD-10-CM diagnosis codes, it is not unrestrictedly possible to automatically calculate the AIS and ISS using ICD-10-GM codes.
DO  - 10.1371/journal.pone.0257183
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Verification is All You Need: Prompting Large Language Models for Zero-Shot Clinical Coding.
AU  - Shaoxin Li
AU  - Can Zheng
AU  - Jiaxiang Wu
AU  - Qinwei Xu
AU  - Xingkun Xu
AU  - Hanyang Wang
AU  - Yingkai Sun
AU  - Zhian Bai
AU  - Yuchen Xu
AU  - Lifeng Zhu
AU  - Weiguo Hu
AU  - Feiyue Huang
SN  - 2168-2208
AB  - Clinical coding translates medical information from Electronic Health Records (EHRs) into structured codes such as ICD-10, which are essential for healthcare applications. Advances in deep learning and natural language processing have enabled automatic ICD coding models to achieve notable accuracy metrics on in-domain datasets when adequately trained. However, the scarcity of clinical medical texts and the variability across different datasets pose significant challenges, making it difficult for current state-of-the-art models to ensure robust generalization performance across diverse data distributions. Recent advances in Large Language Models (LLMs), such as GPT-4o, have shown great generalization capabilities across general domains and potential in medical information processing tasks. However, their performance in generating clinical codes remains suboptimal. In this study, we propose a novel ICD coding paradigm based on code verification to leverage the capabilities of LLMs. Instead of directly generating accurate codes from a vast code space, we simplify the task by verifying the code assignment from a given candidate set. Through extensive experiments, we demonstrate that LLMs function more effectively as code verifiers rather than code generators, with GPT-4o achieving the best performance on the CodiEsp dataset under zero-shot settings. Furthermore, our results indicate that LLM-based systems can perform on par with state-of-the-art clinical coding systems while offering superior generalizability across institutions, languages, and ICD versions.
DO  - 10.1109/JBHI.2025.3593028
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Burden of migraine in Finland: multimorbidity and phenotypic disease networks in occupational healthcare.
AU  - Minna A Korolainen
AU  - Samuli Tuominen
AU  - Samu Kurki
AU  - Mariann I Lassenius
AU  - Iiro Toppila
AU  - Timo Purmonen
AU  - Jaana Santaholma
AU  - Markku Nissilä
SN  - 1129-2377
AB  - BACKGROUND: Migraine is a complex neurological disorder with high co-existing morbidity burden. The aim of our study was to examine the overall morbidity and phenotypic diseasome for migraine among people of working age using real world data collected as a part of routine clinical practice. METHODS: Electronic medical records (EMR) of patients with migraine (n = 17,623) and age- and gender matched controls (n = 17,623) were included in this retrospective analysis. EMRs were assessed for the prevalence of ICD-10 codes, those with at least two significant phi correlations, and a prevalence >2.5% in migraine patients were included to phenotypic disease networks (PDN) for further analysis. An automatic subnetwork detection algorithm was applied in order to cluster the diagnoses within the PDNs. The diagnosis-wise connectivity based on the PDNs was compared between migraine patients and controls to assess differences in morbidity patterns. RESULTS: The mean number of diagnoses per patient was increased 1.7-fold in migraine compared to controls. Altogether 1337 different ICD-10 codes were detected in EMRs of migraine patients. Monodiagnosis was present in 1% and 13%, and the median number of diagnoses was 12 and 6 in migraine patients and controls. The number of significant phi-correlations was 2.3-fold increased, and cluster analysis showed more clusters in those with migraine vs. controls (9 vs. 6). For migraine, the PDN was larger and denser and exhibited one large cluster containing fatigue, respiratory, sympathetic nervous system, gastrointestinal, infection, mental and mood disorder diagnoses. Migraine patients were more likely affected by multiple conditions compared to controls, even if no notable differences in morbidity patterns were identified through connectivity measures. Frequencies of ICD-10 codes on a three character and block level were increased across the whole diagnostic spectrum in migraine. CONCLUSIONS: Migraine was associated with an increased multimorbidity, evidenced by multiple different approaches in the study. A systematic increase in the morbidity across the whole spectrum of ICD-10 coded diagnoses, and when interpreting PDNs, were detected in migraine patients. However, no specific diagnoses explained the morbidity. The results reflect clinical praxis, but also undoubtedly, the pathophysiological phenotypes related to migraine, and emphasize the importance of better understanding migraine-related morbidity.
DO  - 10.1186/s10194-020-1077-x
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Machine learning application for incident prostate adenocarcinomas automatic registration in a French regional cancer registry.
AU  - Thibaut Fabacher
AU  - Julien Godet
AU  - Delphine Klein
AU  - Michel Velten
AU  - Jérémie Jegu
SN  - 1872-8243
AB  - UNLABELLED: Cancer registries are collections of curated data about malignant tumor diseases. The amount of data processed by cancer registries increases every year, making manual registration more and more tedious. OBJECTIVE: We sought to develop an automatic analysis pipeline that would be able to identify and preprocess registry input for incident prostate adenocarcinomas in a French regional cancer registry. METHODS: Notifications from different sources submitted to the Bas-Rhin cancer registry were used here: pathology data and, ICD 10 diagnosis codes from hospital discharge data and healthcare insurance data. We trained a Support Vector Machine model (machine learning) to predict whether patient's data must be considered or not as a prostate adenocarcinoma incident case that should therefore be registered. The final registration of all identified cases was manually confirmed by a specialized technician. Text mining tools (regular expressions) were used to extract clinical and biological data from non-structured pathology reports. RESULTS: We performed two successive analyses. First, we used 982 cases manually labeled by registrars from the 2014 dataset to predict the registration of 785 cases submitted in 2015. Then, we repeated the procedure using the 2089 cases labeled by registrars from the 2014 and 2015 datasets to predict the registration of 926 cases submitted in the 2016 data. The algorithm identified 663 cases of prostate adenocarcinoma in 2015, and 610 in 2016. From these findings, 663 and 531 cases were respectively added to the registry; and 641 and 512 cases were confirmed by the specialized technician. This registration process has achieved a precision level above 96 %. The algorithm obtained an overall precision of 99 % (99.5 % in 2015 and 98.5 % in 2016) and a recall of 97 % (97.8 % in 2015 and 96.9 % in 2016). When the information was found in pathology report, text mining was more than 90 % accuracy for major indicators: PSA test, Gleason score, and incidence date). For both PSA and tumor side, information was not detected in the majority of cases." CONCLUSION: Machine learning was able to identify new cases of prostate cancer, and text mining was able to prefill the data about incident cases. Machine-learning-based automation of the registration process could reduce delays in data production and allow investigators to devote more time to complex tasks and analysis.
DO  - 10.1016/j.ijmedinf.2020.104139
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Identifying vulnerable older adult populations by contextualizing geriatric syndrome information in clinical notes of electronic health records.
AU  - Tao Chen
AU  - Mark Dredze
AU  - Jonathan P Weiner
AU  - Hadi Kharrazi
SN  - 1527-974X
AB  - OBJECTIVE: Geriatric syndromes such as functional disability and lack of social support are often not encoded in electronic health records (EHRs), thus obscuring the identification of vulnerable older adults in need of additional medical and social services. In this study, we automatically identify vulnerable older adult patients with geriatric syndrome based on clinical notes extracted from an EHR system, and demonstrate how contextual information can improve the process. MATERIALS AND METHODS: We propose a novel end-to-end neural architecture to identify sentences that contain geriatric syndromes. Our model learns a representation of the sentence and augments it with contextual information: surrounding sentences, the entire clinical document, and the diagnosis codes associated with the document. We trained our system on annotated notes from 85 patients, tuned the model on another 50 patients, and evaluated its performance on the rest, 50 patients. RESULTS: Contextual information improved classification, with the most effective context coming from the surrounding sentences. At sentence level, our best performing model achieved a micro-F1 of 0.605, significantly outperforming context-free baselines. At patient level, our best model achieved a micro-F1 of 0.843. DISCUSSION: Our solution can be used to expand the identification of vulnerable older adults with geriatric syndromes. Since functional and social factors are often not captured by diagnosis codes in EHRs, the automatic identification of the geriatric syndrome can reduce disparities by ensuring consistent care across the older adult population. CONCLUSION: EHR free-text can be used to identify vulnerable older adults with a range of geriatric syndromes.
DO  - 10.1093/jamia/ocz093
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Neutrons and sudden cardiac death (SCD) codes 121-125 ICD 10.
AU  - E Stoupel
AU  - S Domarkiene
AU  - R Radishauskas
AU  - E Abramson
AU  - P Israelevich
AU  - J Sulkes
SN  - 0792-6855
AB  - Recent studies have shown that (1) monthly neutron activity (NA) (imp/min) correlates with monthly number of acute myocardial infarction (AMI); (2) NA is higher on days of automatic implantable cardioverter defibrillators (AICD) discharges for VT, VF. Here we checked the level of NA in relation to timing and type of sudden cardiac death (SCD) patients [n=848 (579, 68.28% male)] obtained from the Kaunas registry for the years 2002-2004. All underwent Forensic Medicine post mortem examination and classification according to ICD10 by code 121-125. Daily NA data were obtained from Oulu U-ty, Finland and Moscow Monitoring Station of the Russian Academy of Sciences. No difference in NA was found on days with or without SCD. In men < 65, SCD occurred on days with higher NA than in women of the same age (p = 0.01) or in > 65 y old men (p = 0.045). Days of SCD with myocardial ruptures showed the highest level of NA, significantly higher than on all days (n = 669) of SCD (p = 0.037) and all 1096 days of the study (p = 0.0048). Three groups were accompanied by significantly higher NA: repeated AMI, myocardial ruptures (codes122, 123), and coronary atherothrombosis without AMI, related to electrical heart instability. The mechanism of possible neutron role in pathophysiology needs special studies.
DO  - 10.1515/jbcpp.2006.17.1.45
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - [Ambulatory care of patients with somatically unexplained complaints : A comparative qualitative study].
AU  - S Döpfmer
AU  - M C Münchmeyer
AU  - T Natschke
AU  - W Herrmann
AU  - F Holzinger
AU  - R Burian
AU  - A Berghöfer
AU  - C Heintze
SN  - 1433-0407
AB  - BACKGROUND: The aim of this study was to compare the approach of general practitioners (GP) and outpatient specialists for psychiatry, neurology or psychosomatic medicine to patients with somatically unexplained complaints. METHODS: Qualitative interviews were conducted with general practitioners in Berlin and with outpatient specialists. Interviews were analyzed by qualitative content analysis. RESULTS: Both GPs and specialists rarely used structured diagnostic instruments. Guidelines are seen and used with reservation throughout the different specialties. Similar to the GPs, most of the specialists surveyed in this study had reservations against the necessity of a precise coding according to the International Classification of Diseases (ICD). CONCLUSION: In outpatient care the concern for the individual patient is the connecting element between different medical specialties. This results in a differential diagnostic and therapeutic approach that is not automatically in line with guidelines. The development of common concepts in ambulatory care might help to meet the demands of this complex group of patients with somatically unexplained complaints.
DO  - 10.1007/s00115-016-0226-6
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Relational machine learning for electronic health record-driven phenotyping.
AU  - Peggy L Peissig
AU  - Vitor Santos Costa
AU  - Michael D Caldwell
AU  - Carla Rottscheit
AU  - Richard L Berg
AU  - Eneida A Mendonca
AU  - David Page
SN  - 1532-0480
AB  - OBJECTIVE: Electronic health records (EHR) offer medical and pharmacogenomics research unprecedented opportunities to identify and classify patients at risk. EHRs are collections of highly inter-dependent records that include biological, anatomical, physiological, and behavioral observations. They comprise a patient's clinical phenome, where each patient has thousands of date-stamped records distributed across many relational tables. Development of EHR computer-based phenotyping algorithms require time and medical insight from clinical experts, who most often can only review a small patient subset representative of the total EHR records, to identify phenotype features. In this research we evaluate whether relational machine learning (ML) using inductive logic programming (ILP) can contribute to addressing these issues as a viable approach for EHR-based phenotyping. METHODS: Two relational learning ILP approaches and three well-known WEKA (Waikato Environment for Knowledge Analysis) implementations of non-relational approaches (PART, J48, and JRIP) were used to develop models for nine phenotypes. International Classification of Diseases, Ninth Revision (ICD-9) coded EHR data were used to select training cohorts for the development of each phenotypic model. Accuracy, precision, recall, F-Measure, and Area Under the Receiver Operating Characteristic (AUROC) curve statistics were measured for each phenotypic model based on independent manually verified test cohorts. A two-sided binomial distribution test (sign test) compared the five ML approaches across phenotypes for statistical significance. RESULTS: We developed an approach to automatically label training examples using ICD-9 diagnosis codes for the ML approaches being evaluated. Nine phenotypic models for each ML approach were evaluated, resulting in better overall model performance in AUROC using ILP when compared to PART (p=0.039), J48 (p=0.003) and JRIP (p=0.003). DISCUSSION: ILP has the potential to improve phenotyping by independently delivering clinically expert interpretable rules for phenotype definitions, or intuitive phenotypes to assist experts. CONCLUSION: Relational learning using ILP offers a viable approach to EHR-driven phenotyping.
DO  - 10.1016/j.jbi.2014.07.007
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Epidemiological aspects of biliary tree tumors in a region of northern Italy: emerging trends and sex-based differences.
AU  - Annarosa Floreani
AU  - Manola Lisiero
AU  - Tatjana Baldovin
AU  - Vincenzo Baldo
SN  - 1473-5687
AB  - BACKGROUND: Cholangiocarcinoma (CCA) and gallbladder cancer are the second cause of liver malignancy after hepatocellular carcinoma. Epidemiological data point to an increase in the incidence of CCA in both western and eastern countries; however, data on more recent years are lacking. AIMS: The aim of this study was to elucidate the more recent epidemiology of CCA and gallbladder carcinoma in north-east Italy using automatically collected regional data on hospital admissions over a 10-year period. MATERIALS AND METHODS: We performed a retrospective analysis of the Veneto region (north-east Italy) database of patients' hospital discharge records, identifying cases with the following codes: intrahepatic cholangiocarcinoma (155.1), primary gallbladder cancer (156.0), and primary extrahepatic biliary tract cancer (156.1). Hospitalizations were recorded according to the surgical or medical procedures involved (based on International Classification of Diseases-9 procedure codes), and only the first hospitalization was considered for the 2005-2009 period. RESULTS: The number of hospitalizations for biliary tumors as a whole has remained stable over the past 10 years. The hospitalization rate of intrahepatic CCA is increasing; this cancer is more frequent in males than in females. The hospitalization rate for gallbladder cancer is increasing with age. However, the figures for extrahepatic CCA have remained stable over the past 10 years. The duration of survival was significantly longer for patients who underwent radical surgery than for those who did not. CONCLUSION: Efforts are needed to prevent CCA, bearing in mind the emerging conditions associated with its onset. Secondary prevention of these tumors will substantially improve the duration of survival.
DO  - 10.1097/MEG.0b013e3283636cfb
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - A hierarchical method to automatically encode Chinese diagnoses through semantic similarity estimation.
AU  - Wenxin Ning
AU  - Ming Yu
AU  - Runtong Zhang
SN  - 1472-6947
AB  - BACKGROUND: The accumulation of medical documents in China has rapidly increased in the past years. We focus on developing a method that automatically performs ICD-10 code assignment to Chinese diagnoses from the electronic medical records to support the medical coding process in Chinese hospitals. METHODS: We propose two encoding methods: one that directly determines the desired code (flat method), and one that hierarchically determines the most suitable code until the desired code is obtained (hierarchical method). Both methods are based on instances from the standard diagnostic library, a gold standard dataset in China. For the first time, semantic similarity estimation between Chinese words are applied in the biomedical domain with the successful implementation of knowledge-based and distributional approaches. Characteristics of the Chinese language are considered in implementing distributional semantics. We test our methods against 16,330 coding instances from our partner hospital. RESULTS: The hierarchical method outperforms the flat method in terms of accuracy and time complexity. Representing distributional semantics using Chinese characters can achieve comparable performance to the use of Chinese words. The diagnoses in the test set can be encoded automatically with micro-averaged precision of 92.57 %, recall of 89.63 %, and F-score of 91.08 %. A sharp decrease in encoding performance is observed without semantic similarity estimation. CONCLUSION: The hierarchical nature of ICD-10 codes can enhance the performance of the automated code assignment. Semantic similarity estimation is demonstrated indispensable in dealing with Chinese medical text. The proposed method can greatly reduce the workload and improve the efficiency of the code assignment process in Chinese hospitals.
DO  - 10.1186/s12911-016-0269-4
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Text preprocessing for improving hypoglycemia detection from clinical notes - A case study of patients with diabetes.
AU  - Lina Zhou
AU  - Tariq Siddiqui
AU  - Stephen L Seliger
AU  - Jacob B Blumenthal
AU  - Yin Kang
AU  - Rebecca Doerfler
AU  - Jeffrey C Fink
SN  - 1872-8243
AB  - BACKGROUND AND OBJECTIVE: Hypoglycemia is a common safety event when attempting to optimize glycemic control in diabetes (DM). While electronic medical records provide a natural ground for detecting and analyzing hypoglycemia, ICD codes used in the databases may be invalid, insensitive or non-specific in detecting new hypoglycemic events. We developed text preprocessing methods to improve automatic detection of hypoglycemia from analysis of clinical encounter text notes. METHODS: We set out to improve hypoglycemia detection from clinical notes by introducing three preprocessing methods: stop word filtering, medication signaling, and ICD narrative enrichment. To test the proposed methods, we selected clinical notes from VA Maryland Healthcare System, based on various combinations of three criteria that are suggestive of hypoglycemia, including ICD-9 code of diabetes and hypoglycemia, laboratory glucose values < 70 md/dL, and text reference to a proximate hypoglycemia event. In addition, we constructed one dataset of 395 clinical notes from year 2009 and another of 460 notes from year 2014 to test the generality of the proposed methods. For each of the datasets, two physician judges manually reviewed individual clinical notes to determine whether hypoglycemia was present or absent. A third physician judge served as a final adjudicator for disagreements. RESULTS: Each of the proposed preprocessing methods contributed to the performance of hypoglycemia detection by significantly increasing the F1 score in the range of 5.3∼7.4% on one dataset (p < .01). Among the methods, stop word filtering contributed most to the performance improvement (7.4%). Combining all the preprocessing methods led to greater performance gain (p < .001) compared with using each method individually. Similar patterns were observed for the other dataset with the F1 score being increased in the range of 7.7%∼9.4% by individual methods (p < .001). Nevertheless, combining the three methods did not yield additional performance gain. CONCLUSION: The proposed text preprocessing methods improved the performance of hypoglycemia detection from clinical text notes. Stop word filtering achieved the most performance improvement. ICD narrative enrichment boosted the recall of detection. Combining the three preprocessing methods led to additional performance gains.
DO  - 10.1016/j.ijmedinf.2019.06.020
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Deaths from rhesus haemolytic disease in England and Wales in 1977: accuracy of records and assessment of anti-D prophylaxis.
AU  - C Clarke
AU  - A G Whitfield
SN  - 0007-1447
AB  - All the death certificates for deaths in 1977 where haemolytic disease of the newborn (HDN) was the principal, an antecedent, or a contributory cause were obtained from the Office of Population Censuses and Surveys (OPCS). The hospital notes of all 54 of the live-born cases and all of the 101 stillbirths were also obtained. The cause of the death indicated by the notes was compared with the cause and coding on the death certificate. In about a quarter of the cases death was not due to haemolytic disease of any type. The commonest errors arose because the International Classification of Diseases (8th edition) stipulates that hydrops without mention of cause should be coded as HDN and because stillbirths to rhesus-negative mothers tend to be attributed to rhesus HDN automatically. Though deaths from HDN may be overestimated in this way, they are also underestimated because rhesus disease, although mentioned on the certificate, is not selected as the underlying cause, which it may be. These cases were found through multiple coding of all the contributory causes of death, which OPCS performs on a 25% sample of all death certificates for research purposes. These two sources of inaccuracy tend to cancel each other out, but statistics from death certificates give a misleading picture of the efficacy of anti-D prophylaxis because anti-D can never prevent cases which are not in fact due to rhesus HDN. Most of the mothers studied had become immunised before anti-D became available, but in those who could have been treated 75% had not received prophylaxis. As this was a sample of deaths, however, it would not be accurate to extrapolate this high figure to the population at risk. Nevertheless, the organisation of prophylaxis is clearly deficient and should be remedied before providing antenatal anti-D to supplement postnatal treatment.
DO  - 10.1136/bmj.1.6179.1665
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Registry-based surveillance of influenza-associated hospitalisations during the 2009 influenza pandemic in Denmark: the hidden burden on the young.
AU  - Katarina Widgren
AU  - Jens Nielsen
AU  - Kåre Mølbak
SN  - 1932-6203
AB  - BACKGROUND: To follow the impact of the 2009 influenza pandemic in Denmark, influenza surveillance was extended with a system monitoring potentially influenza-associated hospitalisations. METHODOLOGY/PRINCIPAL FINDINGS: National administrative data from 2004-2010 from the automatic reporting of all hospital visits and admissions in Denmark (population 5.5 million) were used. In-patient hospitalisations linked to ICD-10 codes for potentially influenza-associated conditions (influenza, viral and bacterial pneumonia, respiratory distress, and febrile convulsion) were aggregated by week and age groups; <5 years, 5-24 years, 25-64 years and ≥65 years. Weekly numbers of influenza-associated hospitalisations were plotted to follow the course of the pandemic. We calculated the total numbers of influenza-associated hospitalisations in each influenza season (week 30 to week 15, the following year). Risk ratios of being admitted with an influenza-associated condition in this season (2009/2010) compared to the previous five seasons (2004/2005-2008/2009) were calculated using binary regression. During the pandemic season, influenza-associated hospitalisations peaked in week 47, 2009. The total number of influenza-associated hospitalisations was 38,273 compared to the median of previous seasons of 35,662 (p = 0.28). The risk ratio of influenza-associated hospitalisations during the pandemic season compared to previous seasons was 1.63 (95%CI 1.49-1.78) for 5-24 year-olds and ranged between 0.98 and 1.08 for the other three age groups. CONCLUSIONS: The 2009 pandemic influenza did not lead to an overall increase in the number of influenza-associated hospitalisations in Denmark in the 2009/2010 season and could be managed within existing hospital capacity. However, there was a disproportionally large impact on the age group 5-24 years. The influenza-associated hospitalisations during the 2009/2010 pandemic influenza season bore the signature features of historical pandemics: A skewed age-pattern and early out of season transmission.
DO  - 10.1371/journal.pone.0013939
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Development and validation of a model to identify polycystic ovary syndrome in the French national administrative health database.
AU  - Eugénie Micolon
AU  - Sandrine Loubiere
AU  - Appoline Zimmermann
AU  - Julie Berbis
AU  - Pascal Auquier
AU  - Blandine Courbiere
SN  - 1471-2288
AB  - BACKGROUND: We aimed to develop and validate an algorithm for identifying women with polycystic ovary syndrome (PCOS) in the French national health data system. METHODS: Using data from the French national health data system, we applied the International Classification of Diseases (ICD-10) related diagnoses E28.2 for PCOS among women aged 18 to 43 years in 2021. Then, we developed an algorithm to identify PCOS using combinations of clinical criteria related to specific drugs claims, biological exams, international classification of Diseases (ICD-10) related diagnoses during hospitalization, and/or registration for long-term conditions. The sensitivity, specificity and positive predictive value (PPV) of different combinations of algorithm criteria were estimated by reviewing the medical records of the Department of Reproductive Medicine at a university hospital for the year 2022, comparing potential women identified as experiencing PCOS by the algorithms with a list of clinically registered women with or without PCOS. RESULTS: We identified 2,807 (0.01%) women aged 18 to 43 who received PCOS-related care in 2021 using the ICD-10 code for PCOS in the French National health database. By applying the PCOS algorithm to 349 women, the positive and negative predictive values were 0.90 (95%CI (83-95) and 0.93 (95%CI 0.90-0.96) respectively. The sensitivity of the PCOS algorithm was estimated at 0.85 (95%CI 0.77-0.91) and the specificity at 0.96 (95%CI 0.92-0.98). CONCLUSION: The validity of the PCOS diagnostic algorithm in women undergoing reproductive health care was acceptable. Our findings may be useful for future studies on PCOS using administrative data on a national scale, or even on an international scale given the similarity of coding in this field.
DO  - 10.1186/s12874-024-02447-4
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Detection of pediatric respiratory and gastrointestinal outbreaks from free-text chief complaints.
AU  - Oleg Ivanov
AU  - Per H Gesteland
AU  - William Hogan
AU  - Michael B Mundorff
AU  - Michael M Wagner
SN  - 1942-597X
AB  - We conducted a retrospective study to ascertain the potential of free-text chief complaints collected in pediatric emergency departments to serve as surveillance data for early detection of outbreaks. We determined that automatically coded chief complaint data provide a signal that reflects outbreaks in a population of children less than five years of age. Using the Exponentially Weighted Moving Average (EWMA) detection algorithm, we measured the timeliness, sensitivity, and specificity of free-text chief complaints for predicting outbreaks of pediatric respiratory and gastrointestinal illness. We found that time series of automatically coded free text-chief complaints in pediatric patients correlate well with hospital admissions and precede them by the mean of 10.3 days (95% CI -15.15, 35.5) for respiratory outbreaks and 29 days (95% CI 4.23, 53.7) for gastrointestinal outbreaks. We conclude that free-text chief complaints may play an important role as an early, sensitive and specific indicator of outbreaks of respiratory and gastrointestinal illness in children less than five years of age.
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - The ability of the ICD-AIS map to identify seriously injured patients in road traffic accidents-A study from Finland.
AU  - Noora Airaksinen
AU  - Ilona Nurmi-Lüthje
AU  - Heikki Kröger
AU  - Peter Lüthje
SN  - 1538-957X
AB  - OBJECTIVE: In Finland, the severity of road traffic injuries is determined using the International Classification of Diseases, 10th Revision, Finnish Modification (ICD-10-FM) injury codes from Finnish Hospital Discharge data and the automatic conversion tool (ICD-AIS map) developed by the Association for the Advancement of Automotive Medicine (AAAM). The aim of this study was to evaluate the ability of the ICD-AIS map to identify seriously injured patients due to traffic accidents in Finnish injury data by comparing the severity rating generated by an expert and by the ICD-AIS map. METHODS: Our data came from the North Kymi Hospital (level 2 trauma center at the time of the study). The data included 574 patients who were injured in traffic accidents during 2 years. The severity rating (Maximum Abbreviated Injury Scale [MAIS] 3+) of each patient was recorded retrospectively by an expert based on information from patient records. In addition, the rating was generated from ICD-10 injury codes by the ICD-AIS map conversion tool. These 2 ratings were compared by road user categories and the strength of agreement was described using Cohen's kappa. RESULTS: The proportion of seriously injured patients was 10.1% as defined by the expert and 6.6% as generated by the ICD-AIS map; exact agreement was 65.5%. The highest concordance was for pedestrians (exact agreement 100%) and the weakest for moped drivers and motorcyclists (46.7%). Furthermore, the overall strength of agreement of the severity ratings (slightly or seriously injured) between the expert and the ICD-AIS map was good (κ = 0.70). Most (65%) of the conversion problems were misclassifications caused by the simplicity of the Finnish ICD-10 injury codes compared to the injury codes used in the ICD-AIS map. In Finland, the injuries are recorded mainly with 4-digit codes and, infrequently, with 5-digit codes, whereas the ICD-AIS map defines up to 6-digit codes. CONCLUSIONS: For this sample of simplified ICD-10-FM codes, the ICD-AIS map underestimated the number of seriously injured patients. The mapping result could be improved if at least open and closed fractures of extremities and visceral contusions and ruptures had separate codes. In addition, there were a few injury codes that should be considered for inclusion in the map.
DO  - 10.1080/15389588.2018.1520985
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Defining a Patient Population With Cirrhosis: An Automated Algorithm With Natural Language Processing.
AU  - Edward K Chang
AU  - Christine Y Yu
AU  - Robin Clarke
AU  - Andrew Hackbarth
AU  - Timothy Sanders
AU  - Eric Esrailian
AU  - Daniel W Hommes
AU  - Bruce A Runyon
SN  - 1539-2031
AB  - OBJECTIVES: The objective of this study was to use natural language processing (NLP) as a supplement to International Classification of Diseases, Ninth Revision (ICD-9) and laboratory values in an automated algorithm to better define and risk-stratify patients with cirrhosis. BACKGROUND: Identification of patients with cirrhosis by manual data collection is time-intensive and laborious, whereas using ICD-9 codes can be inaccurate. NLP, a novel computerized approach to analyzing electronic free text, has been used to automatically identify patient cohorts with gastrointestinal pathologies such as inflammatory bowel disease. This methodology has not yet been used in cirrhosis. STUDY DESIGN: This retrospective cohort study was conducted at the University of California, Los Angeles Health, an academic medical center. A total of 5343 University of California, Los Angeles primary care patients with ICD-9 codes for chronic liver disease were identified during March 2013 to January 2015. An algorithm incorporating NLP of radiology reports, ICD-9 codes, and laboratory data determined whether these patients had cirrhosis. Of the 5343 patients, 168 patient charts were manually reviewed at random as a gold standard comparison. Positive predictive value (PPV), negative predictive value (NPV), sensitivity, and specificity of the algorithm and each of its steps were calculated. RESULTS: The algorithm's PPV, NPV, sensitivity, and specificity were 91.78%, 96.84%, 95.71%, and 93.88%, respectively. The NLP portion was the most important component of the algorithm with PPV, NPV, sensitivity, and specificity of 98.44%, 93.27%, 90.00%, and 98.98%, respectively. CONCLUSIONS: NLP is a powerful tool that can be combined with administrative and laboratory data to identify patients with cirrhosis within a population.
DO  - 10.1097/MCG.0000000000000583
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automatic ICD Code Assignment based on ICD's Hierarchy Structure for Chinese Electronic Medical Records.
AU  - Lingyu Cao
AU  - Dazhong Gu
AU  - Yuan Ni
AU  - Guotong Xie
SN  - 2153-4063
AB  - Medical records are text documents recording diagnoses, symptoms, examinations, etc. They are accompanied by ICD codes (International Classification of Diseases). ICD is the bedrock for health statistics, which maps human condition, injury, disease etc. to codes. It has enormous financial importance from public health investment to health insurance billing. However, assigning codes to medical records normally needs a lot of human labour and is error-prone due to its complexity. We present a 3-layer attentional convolutional network based on the hierarchy structure of ICD code that predicts ICD codes from medical records automatically. The method shows high performance, with Hit@1 of 0.6969, and Hit@5 of 0.8903, which is better than state-of-the-art method.
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Handling age specification in the SNOMED CT to ICD-10-CM cross-map.
AU  - Junchuan Xu
AU  - Kin Wah Fung
SN  - 1942-597X
AB  - A SNOMED CT-encoded problem list will be required to satisfy the Certification Criteria for Stage 2 "Meaningful Use" of the EHR incentive program. ICD-10-CM will be replacing ICD-9-CM as the reimbursement code set in the near future. Having a cross-map from SNOMED CT to ICD-10-CM will promote the use of SNOMED CT as the primary problem list terminology, while easing the transition to ICD-10-CM. This rule-based map will support semi-automatic generation of ICD-10-CM codes from SNOMED CT-encoded data. Among the different types of rules, the age rule is used to handle age-specific code assignment in ICD-10-CM. To supplement the manual process of creation of age rules, a special QA process was implemented to flag maps that were potentially missing age rules. The QA flagged 342 concepts for review (out of 7,277), of which 172 concepts (50.3%) were true positives. Without the special QA, many of the age rules would have been missed.
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Circles of Health: towards an advanced social network about disabilities of neurological origin.
AU  - Laia Subirats
AU  - Luigi Ceccaroni
AU  - Raquel Lopez-Blazquez
AU  - Felip Miralles
AU  - Alejandro García-Rudolph
AU  - Jose M Tormos
SN  - 1532-0480
AB  - OBJECTIVES: This research is concerned with the study of a new social-network platform, which (1) provides people with disabilities of neurological origin, their relatives, health professionals, therapists, carers and institutions with an interoperable platform that supports standard indicators, (2) promotes knowledge democratization and user empowerment, and (3) allows making decisions with a more informed opinion. METHODS: A new social network, Circles of Health, has been designed, developed and tested by end-users. To allow monitoring the evolution of people's health status and comparing it with other users and with their cohort, anonymized data of 2675 people from comprehensive and multidimensional medical evaluations, carried out yearly from 2006 to 2010, have been standardized to the International Classification of Functioning, Disability and Health, integrated into the corresponding medical health records and then used to automatically generate and graphically represent multidimensional indicators. These indicators have been integrated into Circles of Health's social environment, which has been then evaluated via expert and user-experience analyses. RESULTS: Patients used Circles of Health to exchange bio-psycho-social information (medical and otherwise) about their everyday lives. Health professionals remarked that the use of color-coding in graphical representations is useful to quickly diagnose deficiencies, difficulties or barriers in rehabilitation. Most people with disabilities complained about the excessive amount of information and the difficulty in interpreting graphical representations. CONCLUSIONS: Health professionals found Circles of Health useful to generate a more integrative understanding of health based on a comprehensive profile of individuals instead of being focused on patient's diseases and injuries. People with disabilities found enriching personal knowledge with the experiences of other users helpful. The number of descriptors used at the same time in the graphical interface should be reduced in future versions of the social-network platform.
DO  - 10.1016/j.jbi.2013.09.001
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Validity of registration of ICD codes and prescriptions in a research database in Swedish primary care: a cross-sectional study in Skaraborg primary care database.
AU  - Per Hjerpe
AU  - Juan Merlo
AU  - Henrik Ohlsson
AU  - Kristina Bengtsson Boström
AU  - Ulf Lindblad
SN  - 1472-6947
AB  - BACKGROUND: In recent years, several primary care databases recording information from computerized medical records have been established and used for quality assessment of medical care and research. However, to be useful for research purposes, the data generated routinely from every day practice require registration of high quality. In this study we aimed to investigate (i) the frequency and validity of ICD code and drug prescription registration in the new Skaraborg primary care database (SPCD) and (ii) to investigate the sources of variation in this registration. METHODS: SPCD contains anonymous electronic medical records (ProfDoc III) automatically retrieved from all 24 public health care centres (HCC) in Skaraborg, Sweden. The frequencies of ICD code registration for the selected diagnoses diabetes mellitus, hypertension and chronic cardiovascular disease and the relevant drug prescriptions in the time period between May 2002 and October 2003 were analysed. The validity of data registration in the SPCD was assessed in a random sample of 50 medical records from each HCC (n = 1200 records) using the medical record text as gold standard. The variance of ICD code registration was studied with multi-level logistic regression analysis and expressed as median odds ratio (MOR). RESULTS: For diabetes mellitus and hypertension ICD codes were registered in 80-90% of cases, while for congestive heart failure and ischemic heart disease ICD codes were registered more seldom (60-70%). Drug prescription registration was overall high (88%). A correlation between the frequency of ICD coded visits and the sensitivity of the ICD code registration was found for hypertension and congestive heart failure but not for diabetes or ischemic heart disease.The frequency of ICD code registration varied from 42 to 90% between HCCs, and the greatest variation was found at the physician level (MORPHYSICIAN = 4.2 and MORHCC = 2.3). CONCLUSIONS: Since the frequency of ICD code registration varies between different diagnoses, each diagnosis must be separately validated. Improved frequency and quality of ICD code registration might be achieved by interventions directed towards the physicians where the greatest amount of variation was found.
DO  - 10.1186/1472-6947-10-23
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Patient Electronic Health Records Score for Preoperative Risk Assessment Before Total Knee Arthroplasty.
AU  - Thomas F Osborne
AU  - Paola Suarez
AU  - Donna Edwards
AU  - Tina Hernandez-Boussard
AU  - Catherine Curtin
SN  - 2472-7245
AB  - BACKGROUND: Current preoperative risk assessment tools are often cumbersome, have limited accuracy, and are poorly adopted. The Care Assessment Need (CAN) score, an existing tool developed for primary care providers in the U.S. Veterans Administration health-care system (VA), is automatically calculated for individual patients using electronic health record data. Therefore, it could present an efficient preoperative risk assessment tool. The aim of this project was to determine if the CAN score can be repurposed as a preoperative risk assessment tool for patients undergoing total knee arthroplasty (TKA). METHODS: A multicenter retrospective observational study was conducted using national VA data from 2013 to 2016. The cohort included veterans who underwent TKA identified through ICD-9 (International Classification of Diseases, Ninth Revision), ICD-10, and CPT (Current Procedural Terminology) codes. The focus of the study was the preoperative patient CAN score, a single numerical value ranging from 0 to 99 (with a higher score representing greater risk) that is automatically calculated each week using multiple data points in the VA electronic health record. Study outcomes of interest were 90-day readmission, prolonged hospital stay (>5 days), 1-year mortality, and non-routine patient discharge. RESULTS: The study included 17,210 veterans. Their median preoperative CAN score was 75, although there was substantial variability in patient CAN scores among different facilities. A preoperative CAN score of >75 was significantly associated with mortality (odds ratio [OR] = 3.54), prolonged length of stay (OR = 1.97), 90-day readmission (OR = 1.65), and non-routine discharge (OR = 1.57). The CAN score had good accuracy with a receiver operating characteristic (ROC) curve value of >0.7 for all outcomes except 90-day readmission. CONCLUSIONS: The CAN score can be leveraged as an extremely efficient way to risk-stratify patients before TKA, with results that surpass other commonly available and labor-intensive alternatives. As a result, this simple and efficient solution is well positioned for broad adoption as a standardized decision support tool. LEVEL OF EVIDENCE: Prognostic Level IV. See Instructions for Authors for a complete description of levels of evidence.
DO  - 10.2106/JBJS.OA.19.00061
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Does quality control of death certificates in hospitals have an impact on cause of death statistics?
AU  - G Cecilie Alfsen
AU  - Lars Gustav Lyckander
SN  - 0807-7096
AB  - BACKGROUND: The effects of inaccurate death certificates on cause of death statistics are uncertain. Since 2008, Akershus University Hospital has systematically corrected all death certificates. The effects of these corrections on the total cause of death statistics from the hospital were studied. MATERIAL AND METHOD: ICD-10 codes for the underlying cause of death on the original and the corrected death certificates issued by Akershus University Hospital were retrieved from the Cause of Death Registry for the period 1 May 2008-31 December 2009, once the Cause of Death Registry had processed the death certificates with the aid of the computer program ACME (Automatic Classification of Medical Entities). RESULTS: Altogether 1,001 deaths were investigated (547 men and 454 women). A total of 223 death certificates were corrected. This entailed changing the underlying cause of death in 176 cases. Death certificates for women were corrected most frequently. In 121 cases, the changes entailed a change of disease chapter in ICD-10. The corrections caused a significant reduction in the number of unspecific diagnoses, such as sepsis, cardiac arrest, pneumonia with no further specification, renal failure and fractures without any specific cause. There was a significant exchange of individuals within all the large diagnostic groups, with the exception of cancer. Because of the balancing effect of exchanges within and between the disease chapters, this generated only minor effects on general statistics on causes of death. INTERPRETATION: The continuous correction of death certificates in the hospital was important for adjustments at the individual level and as a quality control of cause of death statistics, but had only minor effects on the general statistics from the hospital.
DO  - 10.4045/tidsskr.12.0943
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Evaluation of an Automated Software Method Versus a Delphi Process to Translate Emergency General Surgery ICD Diagnosis Codes: Lost in Translation.
AU  - Van Christian Sanderfer
AU  - Sullivan A Ayuso
AU  - Mary M Jordan
AU  - Kyle W Cunningham
AU  - Susan Evans
AU  - Pooja Palmer
AU  - Marc Kowalkowski
AU  - Huaping Wang
AU  - A Britton Christmas
AU  - Michael Houston
AU  - Brent D Matthews
AU  - Addison K May
AU  - Caroline E Reinke
AU  - Samuel W Ross
SN  - 2691-3593
AB  - OBJECTIVE: This study provides an up-to-date diagnosis framework for the study of emergency general surgery (EGS) patients. A final list of International Classification of Diseases, Tenth Revision (ICD-10) codes was the main outcome for the study. Codes were compared with the number codes generated by MapIT alone. BACKGROUND: Since transition to ICD-10, a Delphi process to define EGS diagnoses, as originally described for the ICD, Ninth Revision (ICD-9) codeset, has not been performed. Automated mapping software (MapIT) has been utilized, with a few studies verifying the translation. METHODS: Using previously defined ICD-9 EGS codes, MapIT was used to identify ICD-10 EGS codes. Review of adjacent codes in a Delphi process resulted in a finalized list of ICD-10 codes. Delphi and MapIT codes were quantified in the Nationwide Inpatient Sample to compare rates to the ICD-9 era. RESULTS: MapIT identified 935 ICD-10 codes from 485 ICD-9 codes. Manual review identified an additional 1907 adjacent codes. In total, after the modified Delphi process, 1579 (55.6%) of manually and MapIT-identified codes were included in the final codeset. After initial mapping, 880 (55.7%) of the final codes did not automatically map through the software. MapIT codes resulted in a significantly decreased number of patient encounters in the Nationwide Inpatient Sample compared with Delphi codes in the ICD-10 era. CONCLUSIONS: The Delphi-created ICD-10 EGS codeset provides a more robust, accurate translation of the ICD-9 codes than MapIT software. This codeset can be used to inform EGS research to study and improve EGS patients' care.
DO  - 10.1097/AS9.0000000000000606
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - [csapAIH: a function to classify ambulatory care sensitive conditions in the statistical software R].
AU  - Fúlvio Borges Nedel
SN  - 2237-9622
AB  - Hospitalizations due to ambulatory care sensitive conditions (ACSC) are an indirect indicator of primary health care. A package in the R program was developed in order to automatize the classification of codes of the International Statistical Classification of Diseases and Related Health Problems - 10th Revision (ICD-10), according to the Brazilian list of ACSC, and provide functionalities for the management of the "reduced files" of the inpatient hospital authorization (AIH). The csapAIH package contains a homonym function, which reads the data according to its nature (file or data frame with AIH structure, or a factor with ICD-10 codes) and returns, according to defined options, a databank or vector containing the classification for the hospitalization. This article presents the package and the function csapAIH, its installation mode and use, and examples of its functionalities, which may add quickness, precision and validity to the research of ACSC in Brazil.
DO  - 10.5123/S1679-49742017000100021
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Cardiac device implantation in the United States from 1997 through 2004: a population-based analysis.
AU  - Chunliu Zhan
AU  - William B Baine
AU  - Artyom Sedrakyan
AU  - Claudia Steiner
SN  - 1525-1497
AB  - OBJECTIVE: Use of cardiac devices has been increasing rapidly along with concerns over their safety and effectiveness. This study used hospital administrative data to assess cardiac device implantations in the United States, selected perioperative outcomes, and associated patient and hospital characteristics. METHODS: We screened hospital discharge abstracts from the 1997-2004 Healthcare Cost and Utilization Project Nationwide Inpatient Samples. Patients who underwent implantation of pacemaker (PM), automatic cardioverter/defibrillator (AICD), or cardiac resynchronization therapy pacemaker (CRT-P) or defibrillator (CRT-D) were identified using ICD-9-CM procedure codes. Outcomes ascertainable from these data and associated hospital and patient characteristics were analyzed. MEASUREMENTS AND MAIN RESULTS: Approximately 67,000 AICDs and 178,000 PMs were implanted in 2004 in the United States, increasing 60% and 19%, respectively, since 1997. After FDA approval in 2001, CRT-D and CRT-P reached 33,000 and 7,000 units per year in the United States in 2004. About 70% of the patients were aged 65 years or older, and more than 75% of the patients had 1 or more comorbid diseases. There were substantial decreases in length of stay, but marked increases in charges, for example, the length of stay of AICD implantations halved (from 9.9 days in 1997 to 5.2 days in 2004), whereas charges nearly doubled (from $66,000 in 1997 to $117,000 in 2004). Rates of in-hospital mortality and complications fluctuated slightly during the period. Overall, adverse outcomes were associated with advanced age, comorbid conditions, and emergency admissions, and there was no consistent volume-outcome relationship across different outcome measures and patient groups. CONCLUSIONS: The numbers of cardiac device implantations in the United States steadily increased from 1997 to 2004, with substantial reductions in length of stay and increases in charges. Rates of in-hospital mortality and complications changed slightly over the years and were associated primarily with patient frailty.
DO  - 10.1007/s11606-007-0392-0
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Using n-Grams for Syndromic Surveillance in a Turkish Emergency Department Without English Translation: A Feasibility Study.
AU  - Sylvia Halász
AU  - Philip Brown
AU  - Cem Oktay
AU  - Arif Alper Cevik
AU  - Isa Kılıçaslan
AU  - Colin Goodall
AU  - Dennis G Cochrane
AU  - Thomas R Fowler
AU  - Guy Jacobson
AU  - Simon Tse
AU  - John R Allegra
SN  - 1178-2226
AB  - INTRODUCTION: Syndromic surveillance is designed for early detection of disease outbreaks. An important data source for syndromic surveillance is free-text chief complaints (CCs), which are generally recorded in the local language. For automated syndromic surveillance, CCs must be classified into predefined syndromic categories. The n-gram classifier is created by using text fragments to measure associations between chief complaints (CC) and a syndromic grouping of ICD codes. OBJECTIVES: The objective was to create a Turkish n-gram CC classifier for the respiratory syndrome and then compare daily volumes between the n-gram CC classifier and a respiratory ICD-10 code grouping on a test set of data. METHODS: The design was a feasibility study based on retrospective cohort data. The setting was a university hospital emergency department (ED) in Turkey. Included were all ED visits in the 2002 database of this hospital. Two of the authors created a respiratory grouping of International Classification of Diseases, 10th Revision ICD-10-CM codes by consensus, chosen to be similar to a standard respiratory (RESP) grouping of ICD codes created by the Electronic Surveillance System for Early Notification of Community-based Epidemics (ESSENCE), a project of the Centers for Disease Control and Prevention. An n-gram method adapted from AT&T Labs' technologies was applied to the first 10 months of data as a training set to create a Turkish CC RESP classifier. The classifier was then tested on the subsequent 2 months of visits to generate a time series graph and determine the correlation with daily volumes measured by the CC classifier versus the RESP ICD-10 grouping. RESULTS: The Turkish ED database contained 30,157 visits. The correlation (R (2)) of n-gram versus ICD-10 for the test set was 0.78. CONCLUSION: The n-gram method automatically created a CC RESP classifier of the Turkish CCs that performed similarly to the ICD-10 RESP grouping. The n-gram technique has the advantage of systematic, consistent, and rapid deployment as well as language independence.
DO  - 10.4137/BII.S11334
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - UMLS mapping and Word embeddings for ICD code assignment using the MIMIC-III intensive care database.
AU  - Henning Schafer
AU  - Christoph M Friedrich
SN  - 2694-0604
AB  - Diagnosis codes are used as a billing mechanism in the Electronic Health Record and have the capability to benefit decision support systems, which aim to assist coders by suggesting a relevant subset of potential codes to choose from. Due to the large set of possible labels and length of patient records, automatic ICD code assignment is considered to be a challenging task within the field of multi-label classification. This paper introduces a baseline for automatic ICD code assignment using Support Vector Machines (SVM) and FastText with Unified Medical Language System (UMLS) metathesaurus mappings into word embedding models. Training data is obtained from the Medical Information Mart for Intensive Care (MIMIC-III) database and extended with 'is-a' relationships from ICD-9 hierarchy. FastText is evaluated with different label count estimations, of which an approach based on label cardinality yields a F1-Score of 62.2%. FastText achieves high recall results and mentionable performance improvements over previous models. Reported values are obtained through 10-fold cross-validation.
DO  - 10.1109/EMBC.2019.8856442
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Generating Medical Assessments Using a Neural Network Model: Algorithm Development and Validation.
AU  - Baotian Hu
AU  - Adarsha Bajracharya
AU  - Hong Yu
SN  - 2291-9694
AB  - BACKGROUND: Since its inception, artificial intelligence has aimed to use computers to help make clinical diagnoses. Evidence-based medical reasoning is important for patient care. Inferring clinical diagnoses is a crucial step during the patient encounter. Previous works mainly used expert systems or machine learning-based methods to predict the International Classification of Diseases - Clinical Modification codes based on electronic health records. We report an alternative approach: inference of clinical diagnoses from patients' reported symptoms and physicians' clinical observations. OBJECTIVE: We aimed to report a natural language processing system for generating medical assessments based on patient information described in the electronic health record (EHR) notes. METHODS: We processed EHR notes into the Subjective, Objective, Assessment, and Plan sections. We trained a neural network model for medical assessment generation (N2MAG). Our N2MAG is an innovative deep neural model that uses the Subjective and Objective sections of an EHR note to automatically generate an "expert-like" assessment of the patient. N2MAG can be trained in an end-to-end fashion and does not require feature engineering and external knowledge resources. RESULTS: We evaluated N2MAG and the baseline models both quantitatively and qualitatively. Evaluated by both the Recall-Oriented Understudy for Gisting Evaluation metrics and domain experts, our results show that N2MAG outperformed the existing state-of-the-art baseline models. CONCLUSIONS: N2MAG could generate a medical assessment from the Subject and Objective section descriptions in EHR notes. Future work will assess its potential for providing clinical decision support.
DO  - 10.2196/14971
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Covhisto: A Web Application for Cross-Version Visualization and Analysis of ICD-10-GM and OPS.
AU  - Tessa Ohlsen
AU  - Simon Müller
AU  - Josef Ingenerf
SN  - 1879-8365
AB  - INTRODUCTION: The ongoing development of medical coding systems such as ICD-10-GM and OPS presents challenges in ensuring compatibility across versions. This paper introduces Covhisto, a web application for visualizing and analysing changes across multiple versions. METHODS: Covhisto uses crosswalk tables published by the German Federal Institute for Drugs and Medical Devices (BfArM) and data processing pipeline to track changes between ICD-10-GM and OPS versions. Key features include methods for following individual code histories and analyzing structural changes in the coding systems. RESULTS: Covhisto allows users to trace code evolution and identify changes not automatically captured. Unlike existing solutions, Covhisto creates a ConceptMap across all versions, offering a comprehensive view of changes over time. CONCLUSION: Finally, Covhisto complements existing solutions by making complex code changes more transparent and easier to understand, supporting healthcare professionals and researchers in their analyses and promoting interoperability of healthcare data.
DO  - 10.3233/SHTI251394
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - The ligurian human immunodeficiency virus clinical network: a web tool to manage patients with human immunodeficiency virus in primary care and multicenter clinical trials.
AU  - Paolo Fraccaro
AU  - Valeria Pupella
AU  - Roberta Gazzarata
AU  - Chiara Dentone
AU  - Giovanni Cenderello
AU  - Pasqualina De Leo
AU  - Federica Bozzano
AU  - Giorgetta Casalino Finocchio
AU  - Andrea De Maria
AU  - Daniela Fenoglio
AU  - Gilberto Filaci
AU  - Michele Guerra
AU  - Antonio Di Biagio
AU  - Eugenio Mantia
AU  - Giancarlo Orofino
AU  - Giuseppe Ferrea
AU  - Claudio Viscoli
AU  - Mauro Giacomini
SN  - 1923-2195
AB  - BACKGROUND: In recent years, Highly-Active Anti-Retroviral Therapies (HAARTs) have modified the Human Immunodeficiency Virus (HIV) life-cycle and the disease is now considered chronic. Consequently, a longitudinal and complex follow-up is now required for HIV positive patients during their lifetime. Moreover, patients often encounter various complications due to comorbidities, related to the immunodeficiency state and HAARTs' side effects. Thus, HIV positive patients are involved in multicenter clinical trials (MCTs) to improve treatments and discover a preventive vaccine. Therefore, physicians require proper instruments to access comprehensive patient data for managing patients during follow-ups, and tools for data collection and analysis in MCTs. OBJECTIVE: The Ligurian HIV Clinical Network aims to provide physicians with a Web-tool to administrate HIV positive patients' data within primary-care and to reuse the collected clinical information to perform MCTs in Northern Italy. METHODS: The key aspect of the system is a relational database which allows the storage of various types of clinical information (eg, related to HIV, cardiovascular, or hepatic diseases) in multiple formats. The modular design of the database permits a rapid insertion of new parameters without requiring any changes in the database structure. Furthermore, codes from biomedical ontologies controlled vocabularies ("Logical Observation Identifier Names and Codes", and "International Classification of Diseases 9") and ontologies ("Systematized Nomenclature of Medicine Clinical Terms"), units and normality ranges used by all partners participating in the project were collected to achieve a complete semantic interoperability. Accordingly, data can be automatically normalized through the z score formula and physicians can extract and correctly compare information with external statistical tools. Moreover, to respect patients' privacy and legal issues, a local identifier, determined through an HASH cryptography algorithm, is assigned to each patient during the registration process. The database is managed by a user-friendly Web-platform which allows quick access to information during medical examinations and the reusing of the collected data for present and future MCTs. Furthermore, a bidirectional middleware was created in order to import/export information through HL7 messaging. Hence, data can be manually entered by physicians or automatically collected within HL7-compliant Hospital Information systems. RESULTS: Presently, the direct storage of patients' information from the San Paolo Hospital (Savona, Italy), and San Martino and Galliera hospitals in Genoa is in a test phase. Currently, 8 centers of Infectious Diseases (located in Liguria and Piedmont) are participating in the project and almost 400 HIV positive patients have been recorded in the system. Patient data has been used for primary care and research purposes. Currently, there are 4 on-going MCTs and preliminary results have already been presented at International HIV congresses. CONCLUSIONS: The Web-platform allows effective management, sharing and reuse of information within primary care and clinical research. In the future it is planned to share the clinical information from this network with other HL7-compliant workgroups and to extend the platform to other infective diseases (eg, hepatitis).
DO  - 10.2196/med20.2712
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automating the assignment of diagnosis codes to patient encounters using example-based and machine learning techniques.
AU  - Serguei V S Pakhomov
AU  - James D Buntrock
AU  - Christopher G Chute
SN  - 1067-5027
AB  - OBJECTIVE: Human classification of diagnoses is a labor intensive process that consumes significant resources. Most medical practices use specially trained medical coders to categorize diagnoses for billing and research purposes. METHODS: We have developed an automated coding system designed to assign codes to clinical diagnoses. The system uses the notion of certainty to recommend subsequent processing. Codes with the highest certainty are generated by matching the diagnostic text to frequent examples in a database of 22 million manually coded entries. These code assignments are not subject to subsequent manual review. Codes at a lower certainty level are assigned by matching to previously infrequently coded examples. The least certain codes are generated by a naïve Bayes classifier. The latter two types of codes are subsequently manually reviewed. MEASUREMENTS: Standard information retrieval accuracy measurements of precision, recall and f-measure were used. Micro- and macro-averaged results were computed. RESULTS At least 48% of all EMR problem list entries at the Mayo Clinic can be automatically classified with macro-averaged 98.0% precision, 98.3% recall and an f-score of 98.2%. An additional 34% of the entries are classified with macro-averaged 90.1% precision, 95.6% recall and 93.1% f-score. The remaining 18% of the entries are classified with macro-averaged 58.5%. CONCLUSION: Over two thirds of all diagnoses are coded automatically with high accuracy. The system has been successfully implemented at the Mayo Clinic, which resulted in a reduction of staff engaged in manual coding from thirty-four coders to seven verifiers.
DO  - 10.1197/jamia.M2077
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Extraction and Standardization of Patient Complaints from Electronic Medication Histories for Pharmacovigilance: Natural Language Processing Analysis in Japanese.
AU  - Misa Usui
AU  - Eiji Aramaki
AU  - Tomohide Iwao
AU  - Shoko Wakamiya
AU  - Tohru Sakamoto
AU  - Mayumi Mochizuki
SN  - 2291-9694
AB  - BACKGROUND: Despite the growing number of studies using natural language processing for pharmacovigilance, there are few reports on manipulating free text patient information in Japanese. OBJECTIVE: This study aimed to establish a method of extracting and standardizing patient complaints from electronic medication histories accumulated in a Japanese community pharmacy for the detection of possible adverse drug event (ADE) signals. METHODS: Subjective information included in electronic medication history data provided by a Japanese pharmacy operating in Hiroshima, Japan from September 1, 2015 to August 31, 2016, was used as patients' complaints. We formulated search rules based on morphological analysis and daily (nonmedical) speech and developed a system that automatically executes the search rules and annotates free text data with International Classification of Diseases, Tenth Revision (ICD-10) codes. The performance of the system was evaluated through comparisons with data manually annotated by health care workers for a data set of 5000 complaints. RESULTS: Of 5000 complaints, the system annotated 2236 complaints with ICD-10 codes, whereas health care workers annotated 2348 statements. There was a match in the annotation of 1480 complaints between the system and manual work. System performance was .66 regarding precision, .63 in recall, and .65 for the F-measure. CONCLUSIONS: Our results suggest that the system may be helpful in extracting and standardizing patients' speech related to symptoms from massive amounts of free text data, replacing manual work. After improving the extraction accuracy, we expect to utilize this system to detect signals of possible ADEs from patients' complaints in the future.
DO  - 10.2196/11021
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - The FORTA (Fit fOR The Aged)-EPI (Epidemiological) Algorithm: Application of an Information Technology Tool for the Epidemiological Assessment of Drug Treatment in Older People.
AU  - Andree Rabenberg
AU  - Timo Schulte
AU  - Helmut Hildebrandt
AU  - Martin Wehling
SN  - 1179-1969
AB  - BACKGROUND: To improve drug treatment in older people, who often present with multimorbidity and related polypharmacy, the FORTA (Fit fOR The Aged) List was developed via a Delphi consensus procedure. As a patient-in-focus listing approach (PILA), it has been clinically validated (VALFORTA trial). Unlike drug-oriented listing approaches (DOLAs), its application requires knowledge of patients' characteristics, including diagnoses and other details. As a drug list with discrete labels, application of FORTA seems particularly amenable to electronic support. METHODS: An information technology (IT) algorithm was developed to analyze bulk data on International Classification of Diseases (ICD)-coded diseases and Anatomical Therapeutic Chemical (ATC)-coded drugs. FORTA-labeled diagnoses and drugs were used to compute the FORTA score, an automatically generated score that describes medication quality by adding up points assigned for errors related to over- and under-treatment. The algorithm detects mismatches between diagnoses and drugs, suboptimal drugs, omitted drugs, and deficient medication escalation schemes. The read-out produces explanations for each error point. RESULTS: A total of 5603 and 7954 patients ≥ 65 years were included from two claims datasets (> 30,000 patients each, public health insurance). The FORTA scores were comparable (mean ± standard deviation 4.29 ± 3.37 vs. 4.17 ± 3.16), and similar to that determined in VALFORTA (pre-intervention 3.5 ± 2.7). Under-treatment was two times more prevalent than over-treatment. The main areas of under-treatment were pain, type 2 diabetes mellitus, and depression, and the main areas of over-treatment were gastrointestinal (proton pump inhibitors), pain (non-steroidal anti-inflammatory drugs), and arterial hypertension (β-blockers). The FORTA score is positively correlated with higher age, a higher Charlson Comorbidity Index, and more frequent hospitalizations. Patients in disease management programs run by public health insurers had higher scores than comparators. CONCLUSIONS: The algorithm produces plausible analyses of medication errors in older people, pointing to established areas of therapeutic deficiencies. Though individual recommendations exist, the algorithm cannot employ the full potential of FORTA as important details (e.g., blood pressure values, pain intensity) are not (yet) included. However, it seems capable of detecting medication problems in large cohorts-FORTA-EPI (Epidemiological) is designed to support epidemiological analyses, e.g., on comparisons of large cohorts, interventional impact, or longitudinal trends.
DO  - 10.1007/s40266-019-00703-7
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - [Mortality statistics in Germany. Problems and perspectives].
AU  - T Schelhase
AU  - S Weber
SN  - 1436-9990
AB  - The causes of death statistics is widely used as a major source of data for monitoring particular health indicators and their change over time. Results of these comparisons are used for epidemiologic and medical research and as a starting point to give recommendations for prevention programs and for health policy. Nevertheless, the quality of the causes of death statistics is often criticized. Beside the quality of the medical information the critic aims in particular at the restricted comparability of the data and the limitation of the statistics on mono-causal causes of death. The latter aspects refer to steps which are performed within the scope of the data processing in the statistical offices. With the introduction of an automated coding system, which is able to code all causes of deaths on the death certificate and select the underlying cause of death automatically, it will be possible to solve these problems. Furthermore the automated coding system is the prerequisite for a routine multiple-cause coding which is demanded by several medical and statistical experts.
DO  - 10.1007/s00103-007-0287-6
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Mining high-dimensional administrative claims data to predict early hospital readmissions.
AU  - Danning He
AU  - Simon C Mathews
AU  - Anthony N Kalloo
AU  - Susan Hutfless
SN  - 1527-974X
AB  - BACKGROUND: Current readmission models use administrative data supplemented with clinical information. However, the majority of these result in poor predictive performance (area under the curve (AUC)<0.70). OBJECTIVE: To develop an administrative claim-based algorithm to predict 30-day readmission using standardized billing codes and basic admission characteristics available before discharge. MATERIALS AND METHODS: The algorithm works by exploiting high-dimensional information in administrative claims data and automatically selecting empirical risk factors. We applied the algorithm to index admissions in two types of hospitalized patient: (1) medical patients and (2) patients with chronic pancreatitis (CP). We trained the models on 26,091 medical admissions and 3218 CP admissions from The Johns Hopkins Hospital (a tertiary research medical center) and tested them on 16,194 medical admissions and 706 CP admissions from Johns Hopkins Bayview Medical Center (a hospital that serves a more general patient population), and vice versa. Performance metrics included AUC, sensitivity, specificity, positive predictive values, negative predictive values, and F-measure. RESULTS: From a pool of up to 5665 International Classification of Diseases, 9th Revision, Clinical Modification (ICD-9-CM) diagnoses, 599 ICD-9-CM procedures, and 1815 Current Procedural Terminology codes observed, the algorithm learned a model consisting of 18 attributes from the medical patient cohort and five attributes from the CP cohort. Within-site and across-site validations had an AUC≥0.75 for the medical patient cohort and an AUC≥0.65 for the CP cohort. CONCLUSIONS: We have created an algorithm that is widely applicable to various patient cohorts and portable across institutions. The algorithm performed similarly to state-of-the-art readmission models that require clinical data.
DO  - 10.1136/amiajnl-2013-002151
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - [An ophthalmologic image databank on the Internet].
AU  - B Dick
AU  - R Wagner
AU  - O Schwenn
AU  - H Wassill
AU  - H Kropp
AU  - N Pfeiffer
SN  - 0941-293X
AB  - The Internet has become a powerful, international source for information, and it has shown an exponential growth because of the ease of access and the immediate availability of information. We introduced a new ophthalmological atlas including ICD coding on the World Wide Web. So far, more than 500 lantern slides of typical and interesting ophthalmological findings have been selected and digitized. These pictures were integrated in a data base, which was arranged for ease and speed of search and retrieval. In its background, the data base contains a list of over 4700 ICD-encoded diagnoses to which the picture-documented findings are linked. Comments on pictures can be added by the author or by users. The data base contains several lists, such as a list of ICD codes and diagnoses, a list of all pictures with corresponding diagnoses, a list of all diagnoses and number of pictures, a list of those diagnoses for which the corresponding picture is available, as well as a list of comments on each picture. Special program scripts handle the user's search key words for diagnoses and extract the required information out of the data base, using Windows NT. Search results are presented on an automatically built-up webpage. To provide fast speed of search all pictures initially are shown in a small format (thumbnails) with little amount of data. The related full-size picture is retrieved by a single mouse click. Moreover, the name and institution of the author, diagnostical hints and comments on pictures by the author or by users are offered for each diagnosis available. The Giessen Ophthalmological Picture Atlas can be reached under www.med.unigiessen.de in the Internet. It allows a fast search free of charge from all over the world and, therefore, offers an additional option to obtain specific ophthalmological information for various purposes.
DO  - 10.1007/s003470050307
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Quality of the ICD-11 Beta Draft from the German Perspective: Evaluation Based on the Alphabet of ICD-10-GM 2017.
AU  - Jürgen Stausberg
SN  - 2511-705X
AB  - OBJECTIVES: The German Association for Medical Informatics, Biometry and Epidemiology implemented a field test for the ICD-11 Beta Draft. Aim was to analyze completeness and appropriateness of the ICD-11 Beta Draft in its entire breadth. METHODS: Starting point was the synonym thesaurus ("Alphabet") of the German modification of ICD-10. The Alphabet included a list of diagnoses terms that supports the coding of diagnoses with ICD-10. A sample of 60,328 diagnosis terms was drawn to be mapped to the ICD-11 Beta Draft. A subsample of 13,975 diagnosis terms was prepared for assessing reliability. First, the coders had to assign a diagnosis term from the sample to an appropriate English one. This included the automatic selection of the respective code from the ICD-11 Beta Draft. Secondly, the coders had to answer questions regarding completeness, appropriateness, and other issues. RESULTS: Finally, 49,184 results from 36 coders were available for the analysis. Problems with completeness were indicated in 4.7% of the results, problems with appropriateness in 5.3%. On the level of chapters, Cohen's kappa reached grade "fair" at a maximum. The coders agreed in 31.4% of the terms. CONCLUSIONS: Problems with the ICD-11 Beta Draft appeared to be moderate. Completeness was high, reliability was low as it is known for ICD-10. Concerns with the structure of the ICD-11 Beta Draft were noted, e. g. for neoplasms. A post processing of the ICD-11 Beta Draft seems to be sufficient with regard to the content. Methodologically, a thorough review of the structure might be advisable.
DO  - 10.3414/ME17-01-0133
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Syndromic surveillance for influenza in two hospital emergency departments. Relationships between ICD-10 codes and notified cases, before and during a pandemic.
AU  - Karen Moore
AU  - James Black
AU  - Stacey Rowe
AU  - Lucinda Franklin
SN  - 1471-2458
AB  - BACKGROUND: Interest in the use of emergency department (ED) data by syndromic surveillance systems to detect influenza outbreaks has been growing. Evaluations of these systems generally focus on events during influenza seasons. The aims of this study were to identify which emergency department disease codes best correlated with confirmed influenza cases and to determine if these same codes would be useful in the non-influenza season. The 2009 influenza pandemic in Victoria, Australia, provided further opportunity to examine the performance of the syndromic surveillance system during this event. METHODS: We undertook a retrospective analysis of data from the Victorian Department of Health's pilot syndromic surveillance programme, 'SynSurv'. SynSurv automatically captures patient information as it is entered by ED staff. This information includes patient demographics, their presenting symptoms and a preliminary diagnosis using ICD-10 coding. To determine which codes were best correlated with influenza notifications, weekly counts for each of the ICD-10 diagnosis codes ever used in the dataset were calculated and compared with the corresponding weekly count of confirmed influenza cases. Correlations between these codes and confirmed influenza cases in the non-influenza season were then undertaken. The data covered the period from July 2001 until August 2009 and included the 2009 influenza pandemic. RESULTS: There was a marked increase in weekly counts of both laboratory-confirmed influenza cases and relevant ICD-10 codes during the influenza pandemic period. The increase in laboratory confirmed cases was more than four times greater than the previous highest number reported, in 2007, even though the influenza-like-illness activity in the community was considered comparable to 2003 and 2007. We found five ICD-10 codes to be moderately and significantly correlated with influenza cases. None of these codes was correlated with laboratory confirmed influenza notifications outside the influenza season, at least in part because of the small number of influenza cases notified during that period. CONCLUSIONS: This study suggests that the choice of codes made by ED staff to record a case of influenza-like illness is influenced by their perceptions of how much influenza is circulating at the time. The ability of syndromic surveillance to detect outbreaks early may be impeded because case diagnosis is influenced by what ED staff believes to be occurring in the community.
DO  - 10.1186/1471-2458-11-338
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Unsupervised Extraction of Diagnosis Codes from EMRs Using Knowledge-Based and Extractive Text Summarization Techniques.
AU  - Ramakanth Kavuluru
AU  - Sifei Han
AU  - Daniel Harris
AB  - Diagnosis codes are extracted from medical records for billing and reimbursement and for secondary uses such as quality control and cohort identification. In the US, these codes come from the standard terminology ICD-9-CM derived from the international classification of diseases (ICD). ICD-9 codes are generally extracted by trained human coders by reading all artifacts available in a patient's medical record following specific coding guidelines. To assist coders in this manual process, this paper proposes an unsupervised ensemble approach to automatically extract ICD-9 diagnosis codes from textual narratives included in electronic medical records (EMRs). Earlier attempts on automatic extraction focused on individual documents such as radiology reports and discharge summaries. Here we use a more realistic dataset and extract ICD-9 codes from EMRs of 1000 inpatient visits at the University of Kentucky Medical Center. Using named entity recognition (NER), graph-based concept-mapping of medical concepts, and extractive text summarization techniques, we achieve an example based average recall of 0.42 with average precision 0.47; compared with a baseline of using only NER, we notice a 12% improvement in recall with the graph-based approach and a 7% improvement in precision using the extractive text summarization approach. Although diagnosis codes are complex concepts often expressed in text with significant long range non-local dependencies, our present work shows the potential of unsupervised methods in extracting a portion of codes. As such, our findings are especially relevant for code extraction tasks where obtaining large amounts of training data is difficult.
DO  - 10.1007/978-3-642-38457-8_7
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - A computational linguistics motivated mapping of ICPC-2 PLUS to SNOMED CT.
AU  - Yefeng Wang
AU  - Jon Patrick
AU  - Graeme Miller
AU  - Julie O'Hallaran
SN  - 1472-6947
AB  - BACKGROUND: A great challenge in sharing data across information systems in general practice is the lack of interoperability between different terminologies or coding schema used in the information systems. Mapping of medical vocabularies to a standardised terminology is needed to solve data interoperability problems. METHODS: We present a system to automatically map an interface terminology ICPC-2 PLUS to SNOMED CT. Three steps of mapping are proposed in this system. The UMLS metathesaurus mapping utilises explicit relationships between ICPC-2 PLUS and SNOMED CT terms in the UMLS library to perform the first stage of the mapping. Computational linguistic mapping uses natural language processing techniques and lexical similarities for the second stage of mapping between terminologies. Finally, the post-coordination mapping allows one ICPC-2 PLUS term to be mapped into an aggregation of two or more SNOMED CT terms. RESULTS: A total 5,971 of all 7,410 ICPC-2 terms (80.58%) were mapped to SNOMED CT using the three stages but with different levels of accuracy. UMLS mapping achieved the mapping of 53.0% ICPC2 PLUS terms to SNOMED CT with the precision rate of 96.46% and overall recall rate of 44.89%. Lexical mapping increased the result to 60.31% and post-coordination mapping gave an increase of 20.27% in mapped terms. A manual review of a part of the mapping shows that the precision of lexical mappings is around 90%. The accuracy of post-coordination has not been evaluated yet. Unmapped terms and mismatched terms are due to the differences in the structures between ICPC-2 PLUS and SNOMED CT. Terms contained in ICPC-2 PLUS but not in SNOMED CT caused a large proportion of the failures in the mappings. CONCLUSION: Mapping terminologies to a standard vocabulary is a way to facilitate consistent medical data exchange and achieve system interoperability and data standardisation. Broad scale mapping cannot be achieved by any single method and methods based on computational linguistics can be very useful for the task. Automating as much as is possible of this process turns the searching and mapping task into a validation task, which can effectively reduce the cost and increase the efficiency and accuracy of this task over manual methods.
DO  - 10.1186/1472-6947-8-S1-S5
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Identifying Adverse Drug Events in Clinical Text Using Fine-Tuned Clinical Language Models: Machine Learning Study.
AU  - Elizaveta Kopacheva
AU  - Aron Henriksson
AU  - Hercules Dalianis
AU  - Tora Hammar
AU  - Alisa Lincke
SN  - 2561-326X
AB  - BACKGROUND: Medications are essential for health care but can cause adverse drug events (ADEs), which are harmful and sometimes fatal. Detecting ADEs is a challenging task because they are often not documented in the structured data of electronic health records (EHRs). There is a need for automatically extracting ADE-related information from clinical notes, as manual review is labor-intensive and time-consuming. OBJECTIVE: This study aims to fine-tune the pretrained clinical language model, Swedish Deidentified Clinical Bidirectional Encoder Representations from Transformers (SweDeClin-BERT), for medical named entity recognition (NER) and relation extraction (RE) tasks, and to implement an integrated NER-RE approach to more effectively identify ADEs in clinical notes from clinical units in Sweden. The performance of this approach is compared with our previous machine learning method, which used conditional random fields (CRFs) and random forest (RF). METHODS: A subset of clinical notes from the Stockholm EPR (Electronic Patient Record) Corpus, dated 2009-2010, containing suspected ADEs based on International Classification of Diseases, 10th Revision (ICD-10) codes in the A.1 and A.2 categories was randomly sampled. These notes were annotated by a physician with ADE-related entities and relations following the ADE annotation guidelines. We fine-tuned the SweDeClin-BERT model for the NER and RE tasks and implemented an integrated NER-RE pipeline to extract entities and relationships from clinical notes. The models were evaluated using 395 clinical notes from clinical units in Sweden. The NER-RE pipeline was then applied to classify the clinical notes as containing or not containing ADEs. In addition, we conducted an error analysis to better understand the model's behavior and to identify potential areas for improvement. RESULTS: In total, 62% of notes contained an explicit description of an ADE, indicating that an ADE-related ICD-10 code alone does not ensure detailed event documentation. The fine-tuned SweDeClin-BERT model achieved an F1-score of 0.845 for NER and 0.81 for RE task, outperforming the baseline models (CRFs for NER and random forests for RE). In particular, the RE task showed a 53% improvement in macro-average F1-score compared to the baseline. The integrated NER-RE pipeline achieved an overall F1-score of 0.81. CONCLUSIONS: Using a domain-specific language model like SweDeClin-BERT for detecting ADEs in clinical notes demonstrates improved classification performance (0.77 in strict and 0.81 in relaxed mode) compared to conventional machine learning models like CRFs and RF. The proposed fine-tuned ADE model requires further refinement and evaluation on annotated clinical notes from another hospital to evaluate the model's generalizability. In addition, the annotation guidelines should be revised, as there is an overlap of words between the Finding and Disorder entity categories, which were not consistently distinguished by the annotators. Furthermore, future work should address the handling of compound words and split entities to better capture context in the Swedish language.
DO  - 10.2196/71949
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - [Unsupervised Linkage between ICD- and Alpha-ID Codes and Real-World Diagnoses from Medical Reports by Means of the "word2vec" Method].
AU  - Daniel Böhringer
AU  - Stefan J Lang
AU  - Moritz Claudius Daniel
AU  - Thabo Lapp
AU  - Thomas Reinhard
SN  - 1439-3999
AB  - BACKGROUND: Transformation into a standardised code system such as ICD-10 or Alpha-ID is required before medical reports can be scientifically analysed. This is due to the use of different terminologies and the frequent use of synonyms. The so-called "word vector embedding" seems to be suitable for the generation of the required thesaurus, because synonymous diagnoses can be identified independently of the spelling - after suitable training of the underlying neural network. METHODS: All letters from a total of 50,000 patients were extracted anonymously. Diagnoses consisting of several words were merged into single words by means of phrase recognition and the "word2vec" model was trained on the text corpus of 352 megabytes. A total of 3742 diagnoses and ophthalmological interventions were extracted semi-automatically. The ophthalmological ICD and Alpha-ID codes were downloaded together with the official descriptions from the DIMDI website and the ophthalmological diagnoses/interventions were automatically linked with the nearest ICD- and Alpha-ID codes in the "word2vec" model. RESULTS: The "word2vec" model assigned 90% of the doctor's letter diagnoses correctly to appropriate ICD-10 codes. At the finer level of Alpha-ID, the rate of correct assignments was only 76%. The interventions were assigned to the correct indication in 92% of cases. Rare diseases, unusual designations and code degeneration in the official DIMDI file were identified as sources of error for incorrect or missing allocations. DISCUSSION: A diagnostic thesaurus can be generated with the "word2vec" method from a corpus of anonymised medical reports and the official Alpha-ID file from the DIMDI website. This thesaurus could be used for automatic extraction of diagnoses from doctor's letters in the future, given appropriate manual revision.
DO  - 10.1055/a-1023-4490
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - High prevalence of unlabeled chronic kidney disease among inpatients at a tertiary-care hospital.
AU  - Maria Ferris
AU  - David A Shoham
AU  - Margareth Pierre-Louis
AU  - Lawrence Mandhelker
AU  - Randal K Detwiler
AU  - Abhijit V Kshirsagar
SN  - 0002-9629
AB  - BACKGROUND: Although awareness of chronic kidney disease (CKD) is low in outpatient settings, the prevalence of unrecognized CKD in the inpatient setting is unknown. METHODS: We examined the extent of unlabeled CKD among adults admitted to a tertiary-care hospital in North Carolina, based upon a combination of web-based medical record review, chart review, ICD-9 codes and laboratory information from 2000 to 2005. RESULTS: A total of 9772 patients had 2 or more serum creatinine measures at least 6 months apart and demographic variables for race and sex; 431 met criteria for stage 5 CKD (estimated glomerular filtration rate<15 mL/min/1.73 m2) and 6851 patients had stage 2 to 4 CKD (estimated glomerular filtration rate between 15 and 89 mL/min/1.73 m2). Within the latter groups, 3002 had stage 3 to 4 CKD, and 3849 had stage 2 CKD. Forty-three percent were male, 37% had a minority race/ethnicity. The number of patients not labeled as having CKD by ICD-9 code was 2176 (72.5%). Women and whites were less likely than men and minorities to be labeled as having CKD by ICD-9 codes. Medical record review of 600 randomly selected patients identified 399 patients with stage 3 or 4 CKD diagnosis. ICD-9 codes had a sensitivity of 0.50, specificity of 0.88, and positive predictive value of 0.39. CONCLUSIONS: A large proportion of individuals with CKD are going unrecognized in the hospital setting. Automatic laboratory reporting of GFR and education about CKD may help increase awareness in both the inpatient settings.
DO  - 10.1097/MAJ.0b013e318181288e
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Pharmacotherapy after myocardial infarction: disease management versus usual care.
AU  - Vicky Chan
AU  - Catherine E Cooke
SN  - 1936-2692
AB  - OBJECTIVE: To evaluate the effectiveness of a disease management (DM) program compared with usual care on utilization of and adherence to key evidence-based therapies (angiotensin-converting enzyme [ACE] inhibitors/angiotensin II receptor blockers [ARBs], beta-blockers, and statins) after hospital discharge for patients with myocardial infarction (MI) in a managed care organization. STUDY DESIGN: Retrospective case-control cohort. METHODS: Members were included if they were 18 years of age or older and had any medical claims for hospitalization for MI, defined as International Classification of Diseases, Ninth Revision, Clinical Modification, codes 410.xx, from January 1, 2002, to December 31, 2002. The index date was the first date of discharge for members with an MI diagnosis. Members were categorized into the active group (automatically enrolled in the DM program) or the control group (not enrolled in the program because their employer group did not purchase the benefit). Pharmacy claims were obtained for 12 months after the index date for ACE inhibitors, ARBs, beta-blockers, and statins. RESULTS: The study cohort included 250 members in the active group and 137 members in the control group. There were no statistical differences in utilization or time to first prescription fill of ACE inhibitors, ARBs, beta-blockers, and statins between the DM and usual care groups. Adherence to each of these therapies, as measured by medication possession ratio, was not statistically different between the 2 groups. CONCLUSION: Compared with usual care, participation in the DM program did not improve ACE inhibitor, ARB, statin, or beta-blocker utilization or adherence in members post-MI.
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - [Analysis of mortality in the Zilina district].
AU  - J Pavelek
AU  - G Hudáková
SN  - 0009-0689
AB  - From death certificates assemble in the Zilina district in three years (1968-1970) the authors prepared and coded questionnaires with 29 criteria. In the present article they submit some results obtained by automatic computing and biometric evaluation of these data. In the introduction they draw attention to and explain the rising trend of mortality in the Zilina district as well as in the Slovak Socialist Republic. Significant differences were revealed in the marital status of men and women with a predominance of married man and widows. The investigated variations of the number of deceased per day or week is not statistically significant; they were significant only in the course of the year with the maximum of deaths in March and the minimum in August. The specific mortality by decades revealed that men have from birth throughout life a higher death rate than women. As regards causes of death according to the 17 classes of the International Classification four classes dominate similarly an in the entire Slovak Socialist Republic, i. e. cardiovascular diseases 40.8%, tumours 17.8%, respiratory diseases 17.2% and accidents 7.5% all diagnoses. The order of diseases is the same for men and women only in the five most numerous classes and even there is a significant difference in the mortality level in three. Trichotomic classification of communities throws some light on the problem of causes of death of the rural and urban population. The last doctor attending the patient before death was in 48,3% the health community doctor, in 39,1% the hospital, in 8,9% (accidents and acute attacks) nobody whereby the percentage structure of men and women differs significantly also in this indicator. Finally the authors draw attention to the fact that the number of post mortem examinations (31,8%) is highest, as compared with the Central Slovak region (19,9%), the Slovak Socialist Republic (21,1%), the Czech Socialist Republic (29,8%) and the CSSR (27,6%).
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Building a model for disease classification integration in oncology, an approach based on the national cancer institute thesaurus.
AU  - Vianney Jouhet
AU  - Fleur Mougin
AU  - Bérénice Bréchat
AU  - Frantz Thiessard
SN  - 2041-1480
AB  - BACKGROUND: Identifying incident cancer cases within a population remains essential for scientific research in oncology. Data produced within electronic health records can be useful for this purpose. Due to the multiplicity of providers, heterogeneous terminologies such as ICD-10 and ICD-O-3 are used for oncology diagnosis recording purpose. To enable disease identification based on these diagnoses, there is a need for integrating disease classifications in oncology. Our aim was to build a model integrating concepts involved in two disease classifications, namely ICD-10 (diagnosis) and ICD-O-3 (topography and morphology), despite their structural heterogeneity. Based on the NCIt, a "derivative" model for linking diagnosis and topography-morphology combinations was defined and built. ICD-O-3 and ICD-10 codes were then used to instantiate classes of the "derivative" model. Links between terminologies obtained through the model were then compared to mappings provided by the Surveillance, Epidemiology, and End Results (SEER) program. RESULTS: The model integrated 42% of neoplasm ICD-10 codes (excluding metastasis), 98% of ICD-O-3 morphology codes (excluding metastasis) and 68% of ICD-O-3 topography codes. For every codes instantiating at least a class in the "derivative" model, comparison with SEER mappings reveals that all mappings were actually available in the model as a link between the corresponding codes. CONCLUSIONS: We have proposed a method to automatically build a model for integrating ICD-10 and ICD-O-3 based on the NCIt. The resulting "derivative" model is a machine understandable resource that enables an integrated view of these heterogeneous terminologies. The NCIt structure and the available relationships can help to bridge disease classifications taking into account their structural and granular heterogeneities. However, (i) inconsistencies exist within the NCIt leading to misclassifications in the "derivative" model, (ii) the "derivative" model only integrates a part of ICD-10 and ICD-O-3. The NCIt is not sufficient for integration purpose and further work based on other termino-ontological resources is needed in order to enrich the model and avoid identified inconsistencies.
DO  - 10.1186/s13326-017-0114-4
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Estimating a Bias in ICD Encodings for Billing Purposes.
AU  - Georg Fette
AU  - Markus Krug
AU  - Mathias Kaspar
AU  - Leon Liman
AU  - Georg Dietrich
AU  - Maximilian Ertl
AU  - Jonathan Krebs
AU  - Stefan Störk
AU  - Frank Puppe
SN  - 1879-8365
AB  - ICD encoded diagnoses are a popular criterion for eligibility algorithms for study cohort recruitment. However, "official" ICD encoded diagnoses used for billing purposes are afflicted with a bias originating from legal issues. This work presents an approach to estimate the degree of the encoding bias for the complete ICD catalogue at a German university hospital. The free text diagnoses sections of discharge letters are automatically classified using a supervised machine learning algorithm. The automatic classifications are compared with the official, manually classified codes. For selected ICD codes the approach works sufficiently well.
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Automated analysis of electronic medical record data reflects the pathophysiology of operative complications.
AU  - Joseph J Tepas
AU  - Joan M Rimar
AU  - Allen L Hsiao
AU  - Michael S Nussbaum
SN  - 1532-7361
AB  - PURPOSE: We hypothesized that a novel algorithm that uses data from the electronic medical record (EMR) from multiple clinical and biometric sources could provide early warning of organ dysfunction in patients with high risk for postoperative complications and sepsis. Operative patients undergoing colorectal procedures were evaluated. METHODS: The Rothman Index (RI) is a predictive model based on heuristic equations derived from 26 variables related to inpatient care. The RI integrates clinical nursing observations, bedside biometrics, and laboratory data into a continuously updated, numeric physiologic assessment, ranging from 100 (unimpaired) to -91. The RI can be displayed within the EMR as a graphic trend, with a decreasing trend reflecting physiologic dysfunction. Patients undergoing colorectal procedures between June and October 2011 were evaluated to determine correlation of initial RI, average inpatient RI, and lowest RI to incidence of complications and/or postoperative sepsis. Patients were stratified by color-coded RI risk group (100-65, blue; 64-40, yellow; <40 red). One-way or repeated-measures analysis of variance was used to compare groups by age, number of complications, and presence of sepsis defined by discharge International Classification of Diseases, 9(th) Revision, codes. Mean direct cost of care and duration of stay also was calculated for each group. RESULTS: The overall incidence of perioperative complications in the 124 patient cohort was 51% (n = 64 patients). The 261 complications sustained by this group represented 82 distinct diagnoses. The 10 patients with sepsis (8%) experienced a 40% mortality. Analysis of initial RI for the population stratified by number of complications and/or sepsis demonstrated a risk-related difference. With progressive onset of complications, the RI decreased, suggesting worsening physiologic dysfunction and linear increase in direct cost of care. CONCLUSION: These findings demonstrate that EMR data can be automatically compiled into an objective metric that reflects patient risk and changing physiologic state. The automated process of continuous update reflects a physiologic trajectory associated with evolving organ system dysfunction indicative of postoperative complications. Early intervention based on these trends may guide preoperative counseling, enhance pre-emptive management of adverse occurrences, and improve cost-efficiency of care.
DO  - 10.1016/j.surg.2013.07.014
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Leveraging Lexical Matching and Ontological Alignment to Map SNOMED CT Surgical Procedures to ICD-10-PCS.
AU  - Kin Wah Fung
AU  - Julia Xu
AU  - Filip Ameye
AU  - Arturo Romero Gutiérrez
AU  - Arabella D'Havé
SN  - 1942-597X
AB  - In 2015 ICD-10-PCS replaced ICD-9-CM for coding medical procedures in the U.S. We explored two methods to automatically map SNOMED CT surgical procedures to ICD-10-PCS. First, we used MetaMap to lexically map ICD-10-PCS index terms to SNOMED CT. Second, we made use of the axial structure of ICD-10-PCS and aligned them to defining attributes in SNOMED CT. Lexical mapping produced 45% of correct maps and 44% of broader maps. Ontological mappings were 40% correct and 5% broader. Both correct and broader maps will be useful in assisting mappers to create the map. When the two mapping methods agreed, the accuracy increased to 93%. Reviewing the MetaMap generated body part mappings and using additional information in the SNOMED CT names and definitions can lead to better results for the ontological map.
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Three approaches to automatic assignment of ICD-9-CM codes to radiology reports.
AU  - Ira Goldstein
AU  - Anna Arzrumtsyan
AU  - Ozlem Uzuner
SN  - 1942-597X
AB  - We describe and evaluate three systems for automatically predicting the ICD-9-CM codes of radiology reports from short excerpts of text. The first system benefits from an open source search engine, Lucene, and takes advantage of the relevance of reports to one another based on individual words. The second uses BoosTexter, a boosting algorithm based on n-grams (sequences of consecutive words) and s-grams (sequences of non-consecutive words) extracted from the reports. The third employs a set of hand-crafted rules that capture lexical elements (short, meaningful, strings of words) derived from BoosTexter's n-grams, and that are enhanced by shallow semantic information in the form of negation, synonymy, and uncertainty. Our evaluation shows that semantic information significantly contributes to ICD-9-CM coding with lexical elements. Also, a simple hand-crafted rule-based system with lexical elements and semantic information can outperform algorithmically more complex systems, such as Lucene and BoosTexter, when these systems base their ICD-9-CM predictions only upon individual words, n-grams, or s grams.
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Acceptability of Unified Medical Language System terms as substitute for natural language general medicine clinic diagnoses.
AU  - K M Rosenberg
AU  - D B Coultas
SN  - 0195-4210
AB  - The acceptability of using the Unified Medical Language System (UMLS) concept phrases to substitute for physicians' diagnosis statements was investigated. Physician diagnosis statements recorded in the University of New Mexico's General Medicine Clinic were input into a computer program that automatically finds the best matching UMLS concept phrases. The computer program written in C++ integrates UMLS searching and browsing with a graphical user interface. Five attending physicians in the Department of Internal Medicine rated the acceptability of the UMLS concept phrase as a substitute for the original physician statement. One hundred and ninety-five patients' notes were examined with 447 diagnosis statements recorded of which 271 statements were unique. Attending physicians rated their satisfaction with the automated UMLS substitutes on a scale of 1 (extremely dissatisfied) to 5 (extremely satisfied). Intrarater (mean 0.94) and interrater correlations (mean 0.75) were high. The mean rating was 4.0 (quite satisfied). Most (73%) of the substitution were satisfactory (rating of 4 or 5), 16% were neutral (rating of 3), and 21% were unsatisfactory (rating of 1 or 2). A review of the substitutions showed a frequent lack of clinical modifier terms in UMLS as has been previously described. Comparison to a previous study shows the broader term coverage of UMLS to be a more acceptable source of diagnosis codes than using International Classification of Diseases revision 9 alone. These results suggest that UMLS can be an effective tool for coding unconstrained physician diagnoses.
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Injury severity and probability of survival assessment in trauma patients using a predictive hierarchical network model derived from ICD-9 codes.
AU  - R Rutledge
SN  - 0022-5282
AB  - UNLABELLED: Accurate assessment of injury severity is critical for decision making related to the prevention, triage, and treatment of injured patients. Presently, the standard method of controlling for variations of injury severity between groups has been based upon the Injury Severity Score (ISS) and the Trauma Score and the Trauma and Injury Severity Score (TRISS) methodology. The purpose of this study was to attempt to build upon previous work using International Classification of Diseases, ninth revision (ICD-9) coded diagnosis, and procedure information available from standard hospital discharge abstracts (UB-82 Billing format) to create a hierarchical network to provide a tool for predicting injury severity and probability of survival. METHODS: Data were obtained for this analysis from the North Carolina Medical Database. Data were available on all trauma patients admitted to hospitals in North Carolina from January 1, 1988 until June 30, 1992. The dependent variable of interest was the patient's survival after injury, coded as live or die. The independent variables used in the study included the ISS derived using the technique described by MacKenzie Abbreviated Injury Score (AIS) and body system maximum AIS scores, mortality risk ratios derived from the ICD-9-DM primary, secondary, and tertiary diagnoses, primary and secondary procedures as described in previous work, age and gender. Network generation used a commercial software package, AIM (Abtech Corp., Charlottesville, Va.), which is a numeric modeling tool that automatically "learns" knowledge from a data base of examples. RESULTS: In the test data set an ISS and a prediction of survival based upon the derived network were calculated for each and every patient. The relative predictive power of these two scores were compared by calculating the overall accuracy, sensitivity, and specificity and the false positive and false negative rates. The receiver operator characteristic curves demonstrate that the network is a more effective tool in predicting the outcome of trauma patients. All the measures of predictive power show that the network was the better predictor of outcome than the ISS. CONCLUSIONS: Given the recognized limitations of the ISS, the widespread availability of the ICD-9 coded diagnoses and procedures, and the availability of many state and regional data bases that have no ISS or Trauma Score, the purpose of this study was to assess the ability of a network derived from limited but widely available hospital discharge data to predict the outcome of injured patients. The study confirms previous work showing that the ICD-9 codes were strongly associated with outcome. The study demonstrated that the network created from these data was a better predictor of outcome than the derived ISS. When the results of the network were compared with other published series, the network, created without access to physiologic information, was almost as accurate, sensitive, and specific as reported values for TRISS and A Severity Characterization of Trauma (ASCOT). Because the present study is the first of its type, further investigations are needed to validate these findings. If other studies corroborate this study, a network model based upon ICD-9 codes could become the principal method for grading injury severity. This would provide superior predictive power of injury severity with important cost savings and universal application.
DO  - 10.1097/00005373-199504000-00022
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - The Physician Quality Reporting Initiative: a practical approach to implementing quality reporting.
AU  - Ruth Wintz
AU  - Brian Rosenthal
AU  - Stephen Z Fadem
SN  - 1548-5609
AB  - The Physician Quality Reporting Initiative (PQRI) is a voluntary program in which Medicare encourages eligible physicians in the United States to report on specific quality measures. This article is a case study of the implementation of PQRI reporting by Kidney Associates, a nephrology practice in Houston, TX. After reviewing and discussing 74 potential measures, the group narrowed the selection to 5 and chose 1 office measure and 2 dialysis measures. PQRI reporting was established through an Encounter Note template that forced a required entry for whether a patient was diabetic. For each diabetic, blood pressures were entered in the template and appropriate G-codes were created, which were then selected and linked with the diabetes International Classification of Diseases, Ninth Revision code and electronically submitted for billing. The dialysis measures were automatically selected from the urea reduction rate and hematocrit (hemoglobin x 3) measures that were received for each patient on a regular basis from a large dialysis chain. Software was developed to parse these data, evaluate them, and generate the appropriate G-codes. At the end of the billing cycle, these data were exported through a standard spreadsheet formatting along with the billing G codes, and claims were submitted. The system was cost-effective to implement, required minimal education, and achieved 100% cooperation through feedback education and rapid correction of systems issues. Kidney Associates was able to show that PQRI reporting is easy to implement with minimal expense and staff labor. Sharing these methods with other practices should facilitate the implementation of efficient reporting systems.
DO  - 10.1053/j.ackd.2007.10.007
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - A tool for sharing annotated research data: the "Category 0" UMLS (Unified Medical Language System) vocabularies.
AU  - Jules J Berman
SN  - 1472-6947
AB  - BACKGROUND: Large biomedical data sets have become increasingly important resources for medical researchers. Modern biomedical data sets are annotated with standard terms to describe the data and to support data linking between databases. The largest curated listing of biomedical terms is the the National Library of Medicine's Unified Medical Language System (UMLS). The UMLS contains more than 2 million biomedical terms collected from nearly 100 medical vocabularies. Many of the vocabularies contained in the UMLS carry restrictions on their use, making it impossible to share or distribute UMLS-annotated research data. However, a subset of the UMLS vocabularies, designated Category 0 by UMLS, can be used to annotate and share data sets without violating the UMLS License Agreement. METHODS: The UMLS Category 0 vocabularies can be extracted from the parent UMLS metathesaurus using a Perl script supplied with this article. There are 43 Category 0 vocabularies that can be used freely for research purposes without violating the UMLS License Agreement. Among the Category 0 vocabularies are: MESH (Medical Subject Headings), NCBI (National Center for Bioinformatics) Taxonomy and ICD-9-CM (International Classification of Diseases-9-Clinical Modifiers). RESULTS: The extraction file containing all Category 0 terms and concepts is 72,581,138 bytes in length and contains 1,029,161 terms. The UMLS Metathesaurus MRCON file (January, 2003) is 151,048,493 bytes in length and contains 2,146,899 terms. Therefore the Category 0 vocabularies, in aggregate, are about half the size of the UMLS metathesaurus.A large publicly available listing of 567,921 different medical phrases were automatically coded using the full UMLS metatathesaurus and the Category 0 vocabularies. There were 545,321 phrases with one or more matches against UMLS terms while 468,785 phrases had one or more matches against the Category 0 terms. This indicates that when the two vocabularies are evaluated by their fitness to find at least one term for a medical phrase, the Category 0 vocabularies performed 86% as well as the complete UMLS metathesaurus. CONCLUSION: The Category 0 vocabularies of UMLS constitute a large nomenclature that can be used by biomedical researchers to annotate biomedical data. These annotated data sets can be distributed for research purposes without violating the UMLS License Agreement. These vocabularies may be of particular importance for sharing heterogeneous data from diverse biomedical data sets. The software tools to extract the Category 0 vocabularies are freely available Perl scripts entered into the public domain and distributed with this article.
DO  - 10.1186/1472-6947-3-6
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - A Framework for Identifying Genotypic Information from Clinical Records: Exploiting Integrated Ontology Structures to Transfer Annotations between ICD Codes and Gene Ontologies.
AU  - Seyedsasan Hashemikhabir
AU  - Ran Xia
AU  - Yang Xiang
AU  - Sarath Chandra Janga
SN  - 1557-9964
AB  - Although some methods are proposed for automatic ontology generation, none of them address the issue of integrating large-scale heterogeneous biomedical ontologies. We propose a novel approach for integrating various types of ontologies efficiently and apply it to integrate International Classification of Diseases, Ninth Revision, Clinical Modification (ICD9CM), and Gene Ontologies. This approach is one of the early attempts to quantify the associations among clinical terms (e.g., ICD9 codes) based on their corresponding genomic relationships. We reconstructed a merged tree for a partial set of GO and ICD9 codes and measured the performance of this tree in terms of associations' relevance by comparing them with two well-known disease-gene datasets (i.e., MalaCards and Disease Ontology). Furthermore, we compared the genomic-based ICD9 associations to temporal relationships between them from electronic health records. Our analysis shows promising associations supported by both comparisons suggesting a high reliability. We also manually analyzed several significant associations and found promising support from literature.
DO  - 10.1109/TCBB.2015.2480056
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Amiodarone is poorly effective for the acute termination of ventricular tachycardia.
AU  - Keith A Marill
AU  - Ian S deSouza
AU  - Daniel K Nishijima
AU  - Thomas O Stair
AU  - Gary S Setnik
AU  - Jeremy N Ruskin
SN  - 1097-6760
AB  - STUDY OBJECTIVE: It is hypothesized that intravenous (IV) amiodarone is poorly effective for the acute termination of sustained monomorphic ventricular tachycardia because of the relatively slow onset of its Vaughn-Williams class III effect to prolong myocardial depolarization and the refractory period. This study is designed to determine the effectiveness and safety of IV amiodarone for the termination of sustained monomorphic ventricular tachycardia. METHODS: A retrospective case series was collected at 4 urban university-affiliated hospitals from September 1996 to April 2005 after institutional review board approval with waiver of informed consent. Emergency department (ED) patients treated with IV amiodarone for ventricular tachycardia were identified by ED treatment and hospital pharmacy billing records, International Classification of Diseases, Ninth Revision discharge codes, and ECG characteristics. All consecutive patients who received at least 150 mg amiodarone in 15 minutes or less for spontaneous sustained monomorphic ventricular tachycardia were eligible for inclusion. Sustained monomorphic ventricular tachycardia was defined as a tachycardia with uninterrupted duration or rapid recurrence despite automatic internal cardiac defibrillator therapy for at least 5 minutes before amiodarone treatment, monomorphic morphology, rate greater than 120 beats/min, QRS duration greater than 120 ms, and subsequently determined to be ventricular tachycardia by ECG criteria (eg, atrioventricular dissociation), implanted device interrogation, or formal electrophysiology study. Measured outcomes included sustained termination of ventricular tachycardia within 20 minutes of initiation of amiodarone infusion and any documented adverse effects. Rates of successful termination and adverse effects and their 95% confidence intervals (CIs) were calculated. The presence or average values of potentially confounding predictors in patients with and without ventricular tachycardia termination after amiodarone were also calculated and compared. RESULTS: Thirty-three patients were identified and included. Five patients received electrical therapy within 20 minutes of initiation of amiodarone infusion, and the response to amiodarone was unknown. Twenty-seven of the remaining 28 patients received 150 mg amiodarone, and the rate of successful ventricular tachycardia termination was 8 of 28, 29% (95% CI 13 to 49). Two of 33 patients, 6% (95% CI 1 to 20), required direct current cardioversion for presyncope or hypotension temporally associated with amiodarone treatment. CONCLUSION: IV amiodarone, as currently administered, is relatively safe but ineffective for the acute termination of sustained ventricular tachycardia.
DO  - 10.1016/j.annemergmed.2005.08.022
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Could Swedish 'yellow cards' be substituted by E-coded summaries?
AU  - C Jorup-Rönström
AU  - M Keisu
AU  - B E Wiholm
SN  - 0114-5916
AB  - Case summaries of 2490 patients treated at the Department of Infectious Diseases, Danderyd Hospital, in 1986 were reviewed for discharge diagnoses where the International Classification of Disease (ICD) code indicated an adverse drug reaction (ADR) [E 939,9 in ICD 8]. Of 48 patients whose case summaries indicated an ADR, only 10 (21%) had been reported on 'yellow cards' to the Swedish Adverse Drug Reactions Advisory Committee. The Committee had also received from the same department 3 reports where the case summary lacked an ADR code. The information on drug treatment with respect to dosage, duration and treatment with concomitant drugs was not complete in the case summaries but sufficient for a preliminary evaluation of the suspected reactions in all but 4 of the cases. On the basis of these findings the authors do not reach an outright conclusion in favour of replacing the 'yellow card' system but the possible benefits of a system in which 'yellow cards' are supplemented by automatic referral of all case summaries containing an ICD code indicating an adverse drug reaction was judged sufficient to recommend and initiate a large field study.
DO  - 10.2165/00002018-199005010-00007
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Are there 16 species of brown dog ticks? Phylogenies from 60 entire mitochondrial genomes and 162 cox1 sequences reveal 16 species-level clades in the Rhipicephalus (Rhipicephalus) sanguineus group☆☆.
AU  - Samuel Kelava
AU  - Ryo Nakao
AU  - Ben J Mans
AU  - Mingeun Cho
AU  - Kynan B T Mateo
AU  - Dmitry A Apanaskevich
AU  - Renfu Shao
AU  - Alexander W Gofton
AU  - Ernest J M Teo
AU  - Takuya Ito
AU  - Dayana Barker
AU  - Stephen C Barker
SN  - 1879-0135
AB  - The Rhipicephalus sanguineus group, the brown dog ticks, are cosmopolitan and doubtless the most important ticks of domestic dogs, clinically and economically. Despite four decades of taxonomic enquiry with nucleotide sequences and morphology, the taxonomy of the R. sanguineus group is confused, even chaotic. We provide 13 new mitochondrial (mt) genomes and internal transcribed spacer 2 (ITS2) sequences from nine localities in Australia, Israel and Japan. We inferred phylogenetic trees from 10 mt protein-coding genes (9,514 bp), as well as partial cox1, ITS2, 12S, and 16S rRNA genes, to resolve to common clades the >2,000 nucleotide sequences in GenBank from the R. sanguineus group. Then we applied three species delimitation protocols to 60 entire mt genomes (ca. 15,000 bp) and 162 partial cox1 sequences (472 bp): Automatic Barcode Gap discovery, Assemble Species by Automatic Partitioning, and Poisson Tree Process. We considered pairwise genetic differences and Tamura-Nei genetic distances among 60 entire mt genomes and 162 partial cox1 sequences. We found 16 species-level clades (clades A to P) that we hypothesise represent at least 16 species in the R. sanguineus group. These clades had intra-clade differences of <3.8% (entire mt genomes) and <5.1% (partial cox1) whereas the inter-clade differences were >7.7% (entire mt genomes) and >4.5% (partial cox1). We assigned the species names Rhipicephalus linnaei (Audouin, 1826), Rhipicephalus rutilus (Koch, 1844), Rhipicephalus secundus (Feldman-Muhsam, 1952) and R. sanguineus (Latreille, 1806) to clades A, C, D, and K, respectively. And we hypothesise that the names Rhipicephalus camicasi (Morel, Mouchet & Rodhain, 1976), Rhipicephalus turanicus (Pomerantsev, 1940), Rhipicephalus guilhoni (Morel & Vassilades, 1963), Rhipicephalus sulcatus (Neumann, 1908), Rhipicephalus rossicus (Yakimov & Kol-Yakimova, 1911), Rhipicephalus pumilio (Schulze, 1935) and Rhipicephalus pusillus (Gil Collado, 1936) apply to clades B, E, H, J, M, N and O, respectively. The newly described Rhipicephalus hibericus (Millán, Rodriguez-Pastor & Estrada-Peña, 2024) was genetically indistinguishable from R. sanguineus in clade K and thus is a synonym of R. sanguineus. We could not assign names to clades F (USA, Hungary), I (India, Pakistan), L (Nigeria), G (China, Kazakhstan), and P (Cameroon): some or all of these five clades may be new species in the R. sanguineus group. Our haplotype network of partial mt genes (cox1, cytb and nad2) revealed much genetic similarity among geographically distant populations of R. linnaei. This indicates recent dispersal, likely originating in Africa or the Middle East, since African populations were more genetically diverse than populations in other parts of the world.
DO  - 10.1016/j.ijpara.2025.04.016
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Enabling claims-based decision support through non-interruptive capture of admission diagnoses and provider billing codes.
AU  - Colin G Walsh
AU  - David K Vawdrey
AU  - Peter D Stetson
AU  - Matthew R Fred
AU  - George Hripcsak
SN  - 1942-597X
AB  - The patient problem list, like administrative claims data, has become an important source of data for decision support, patient cohort identification, and alerting systems. A two-fold intervention to increase capture of problems on the problem list automatically - with minimal disruption to admitting and provider billing workflows - is described. For new patients with no prior data in the electronic health record, the intervention resulted in a statistically significant increase in the number of problems recorded to the problem list (3.8 vs 2.9 problems post-and pre-intervention respectively, p value 2×10(-16)). The majority of problems were recorded in the first 24 hours of admission. The proportion of patients with at least one problem coded to the problem list within the first 24 hours increased from 94% to 98% before and after intervention (chi square 344, p value 2×10(-16)). ICD9 "V codes" connoting circumstances beyond disease were captured at a higher rate post intervention than before. Deyo/Charlson comorbidities derived from problem list data were more similar to those derived from claims data after the intervention than before (Jaccard similarity 0.3 post- vs 0.21 pre-intervention, p value 2×10(-16)). A workflow-sensitive, non-interruptive means of capturing provider-entered codes early in admission can improve both the quantity and content of problems on the patient problem list.
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Narrative electronic patient records as source of discharge diagnoses.
AU  - Gustav Mikkelsen
AU  - Jan Aasly
SN  - 0169-2607
AB  - OBJECTIVE: To evaluate the consistency of diagnostic data extracted from narrative electronic patient record (EPR) notes compared with the data from a patient administrative system (PAS). To assess potential benefit of using EPR notes as source of diagnosis data and as basis for case identification. DESIGN: Construction of a computer algorithm to extract ICD-9 codes from narrative EPR notes. Assessment of consistency and reliability of the diagnostic codes retrieved from EPR notes and PAS. Estimation of efficiency of case identification based on data from PAS and EPR. RESULTS: Diagnosis codes were retrieved from PAS with sensitivity of 0.989 and the positive predictive value (PPV) was 0.993. Codes were retrieved from EPR with sensitivity of 0.908 and PPV of 0.990. Combining these two sources increased sensitivity to 0.999. CONCLUSION: Discharge diagnoses were easily extracted from narrative EPR notes by automatic methods. Information extracted from record notes was not significantly different from the corresponding data in PAS, but EPR was incomplete as compared with PAS. Utilizing data extracted from EPR improved case identification significantly.
DO  - 10.1016/s0169-2607(02)00093-7
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Supervised ICD Code Assignment to Short Clinical Problem List Entries.
AU  - José Antonio Vera Ramos
AU  - Markus Kreuzthaler
AU  - Stefan Schulz
SN  - 1879-8365
AB  - Clinical information systems contain free-text entries in different contexts to be used in a variety of application scenarios. In this study we investigate to what extent diagnosis codes using the disease classification system ICD-10 can be automatically post-assigned to patient-based short problem list entries, (50 characters maximum). Classifiers using random forest and Adaboost performed best with an F-measure of 0.87 and 0.85 running against an unbalanced data set, and an F-measure of 0.88 and 0.94 using a balanced data set, respectively.
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - A system for reporting gynecologic procedures. A linguistic-logical approach.
AU  - P S Gibbons
AU  - F T Pishotta
AU  - R C Stepto
SN  - 0024-7758
AB  - A system was developed for reporting gynecologic procedures at Chicago Lying-In Hospital. The system is designed to report procedures and treatments performed during both inpatient stays and outpatient visits. Key features of the system are (1) the automatic encoding of all gynecologic procedures in both the ICD (International Classification of Diseases) and CPT (Current Procedural Terminology) coding systems, (2) the use of an independent program to maintain and update a multiply referenced network of operative procedures and (3) the use of a cross-indexing system that allows each procedure to be accessed in several ways and according to several patterns of keys (billing code number, CPT category, common abbreviation and/or linguistic feature).
N1  - Document Type: Article
ER  - 

TY  - JOUR
TI  - Cohort Discovery Query Optimization via Computable Controlled Vocabulary Versioning.
AU  - Todd A Ferris
AU  - Tanya Podchiyska
SN  - 1879-8365
AB  - Self-service cohort discovery tools strive to provide intuitive interfaces to large Clinical Data Warehouses that contain extensive historic information. In those tools, controlled vocabulary (e.g., ICD-9-CM, CPT) coded clinical information is often the main search criteria used because of its ubiquity in billing processes. These tools generally require a researcher to pick specific terms from the controlled vocabulary. However, controlled vocabularies evolve over time as medical knowledge changes and can even be replaced with new versions (e.g., ICD-9 to ICD-10). These tools generally only display the current version of the controlled vocabulary. Researchers should not be expected to understand the underlying controlled vocabulary versioning issues. We propose a computable controlled vocabulary versioning system that allows cohort discovery tools to automatically expand queries to account for terminology changes.
N1  - Document Type: Article
ER  - 

